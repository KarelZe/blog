[
  {"id":"aasExplainingIndividualPredictions2021","author":[{"family":"Aas","given":"Kjersti"},{"family":"Jullum","given":"Martin"},{"family":"Løland","given":"Anders"}],"citation-key":"aasExplainingIndividualPredictions2021","container-title":"Artificial Intelligence","DOI":"10.1016/j.artint.2021.103502","issued":{"date-parts":[["2021"]]},"page":"1–24","title":"Explaining individual predictions when features are dependent: more accurate approximations to shapley values","type":"article-journal","volume":"298"},
  {"id":"abagyanOneTokenizerRule2025","abstract":"Pretraining massively multilingual Large Language Models (LLMs) for many languages at once is challenging due to limited model capacity, scarce high-quality data, and compute constraints. Moreover, the lack of language coverage of the tokenizer makes it harder to address the gap for new languages purely at the post-training stage. In this work, we study what relatively cheap interventions early on in training improve “language plasticity”, or adaptation capabilities of the model post-training to new languages. We focus on tokenizer design and propose using a universal tokenizer that is trained for more languages than the primary pretraining languages to enable efficient adaptation in expanding language coverage after pretraining. Our systematic experiments across diverse groups of languages and different training strategies show that a universal tokenizer enables significantly higher language adaptation, with up to 20.2% increase in win rates compared to tokenizers specific to pretraining languages. Furthermore, a universal tokenizer also leads to better plasticity towards languages that are completely unseen in the tokenizer and pretraining, by up to 5% win rate gain. We achieve this adaptation to an expanded set of languages with minimal compromise in performance on the majority of languages included in pretraining.","accessed":{"date-parts":[["2025",6,13]]},"author":[{"family":"Abagyan","given":"Diana"},{"family":"Salamanca","given":"Alejandro R."},{"family":"Cruz-Salinas","given":"Andres Felipe"},{"family":"Cao","given":"Kris"},{"family":"Lin","given":"Hangyu"},{"family":"Locatelli","given":"Acyr"},{"family":"Fadaee","given":"Marzieh"},{"family":"Üstün","given":"Ahmet"},{"family":"Hooker","given":"Sara"}],"citation-key":"abagyanOneTokenizerRule2025","DOI":"10.48550/arXiv.2506.10766","issued":{"date-parts":[["2025",6,12]]},"language":"en","number":"arXiv:2506.10766","publisher":"arXiv","source":"arXiv.org","title":"One Tokenizer To Rule Them All: Emergent Language Plasticity via Multilingual Tokenizers","title-short":"One Tokenizer To Rule Them All","type":"article","URL":"http://arxiv.org/abs/2506.10766"},
  {"id":"abdinPhi4TechnicalReport2024","abstract":"We present phi-4, a 14-billion parameter language model developed with a training recipe that is centrally focused on data quality. Unlike most language models, where pre-training is based primarily on organic data sources such as web content or code, phi-4 strategically incorporates synthetic data throughout the training process. While previous models in the Phi family largely distill the capabilities of a teacher model (specifically GPT-4), phi-4 substantially surpasses its teacher model on STEM-focused QA capabilities, giving evidence that our data-generation and post-training techniques go beyond distillation. Despite minimal changes to the phi-3 architecture, phi-4 achieves strong performance relative to its size – especially on reasoning-focused benchmarks – due to improved data, training curriculum, and innovations in the post-training scheme.","accessed":{"date-parts":[["2024",12,13]]},"author":[{"family":"Abdin","given":"Marah"},{"family":"Aneja","given":"Jyoti"},{"family":"Behl","given":"Harkirat"},{"family":"Bubeck","given":"Sébastien"},{"family":"Eldan","given":"Ronen"},{"family":"Gunasekar","given":"Suriya"},{"family":"Harrison","given":"Michael"},{"family":"Hewett","given":"Russell J."},{"family":"Javaheripi","given":"Mojan"},{"family":"Kauffmann","given":"Piero"},{"family":"Lee","given":"James R."},{"family":"Lee","given":"Yin Tat"},{"family":"Li","given":"Yuanzhi"},{"family":"Liu","given":"Weishung"},{"family":"Mendes","given":"Caio C. T."},{"family":"Nguyen","given":"Anh"},{"family":"Price","given":"Eric"},{"family":"Rosa","given":"Gustavo","dropping-particle":"de"},{"family":"Saarikivi","given":"Olli"},{"family":"Salim","given":"Adil"},{"family":"Shah","given":"Shital"},{"family":"Wang","given":"Xin"},{"family":"Ward","given":"Rachel"},{"family":"Wu","given":"Yue"},{"family":"Yu","given":"Dingli"},{"family":"Zhang","given":"Cyril"},{"family":"Zhang","given":"Yi"}],"citation-key":"abdinPhi4TechnicalReport2024","DOI":"10.48550/arXiv.2412.08905","issued":{"date-parts":[["2024",12,12]]},"language":"en","number":"arXiv:2412.08905","publisher":"arXiv","source":"arXiv.org","title":"Phi-4 Technical Report","type":"article","URL":"http://arxiv.org/abs/2412.08905"},
  {"id":"abeDeepLearningForecasting2018","accessed":{"date-parts":[["2021",10,26]]},"author":[{"family":"Abe","given":"Masaya"},{"family":"Nakayama","given":"Hideki"}],"citation-key":"abeDeepLearningForecasting2018","container-title":"Advances in Knowledge Discovery and Data Mining","DOI":"10.1007/978-3-319-93034-3\\_22","editor":[{"family":"Phung","given":"Dinh"},{"family":"Tseng","given":"Vincent S."},{"family":"Webb","given":"Geoffrey I."},{"family":"Ho","given":"Bao"},{"family":"Ganji","given":"Mohadeseh"},{"family":"Rashidi","given":"Lida"}],"event-place":"Cham","issued":{"date-parts":[["2018"]]},"page":"273–284","publisher":"Springer International Publishing","publisher-place":"Cham","title":"Deep learning for forecasting stock returns in the cross-section","type":"chapter","volume":"10937"},
  {"id":"abnarQuantifyingAttentionFlow2020","author":[{"family":"Abnar","given":"Samira"},{"family":"Zuidema","given":"Willem"}],"citation-key":"abnarQuantifyingAttentionFlow2020","container-title":"Proceedings of the 58th annual meeting of the association for computational linguistics","DOI":"10.18653/v1/2020.acl-main.385","event-place":"Online","issued":{"date-parts":[["2020"]]},"page":"4190–4197","publisher":"Association for Computational Linguistics","publisher-place":"Online","title":"Quantifying attention flow in transformers","type":"paper-conference"},
  {"id":"adaloglouHowPositionalEmbeddings2021","accessed":{"date-parts":[["2021",12,16]]},"author":[{"family":"Adaloglou","given":"Nikolas"}],"citation-key":"adaloglouHowPositionalEmbeddings2021","issued":{"date-parts":[["2021"]]},"title":"How positional embeddings work in self-attention (code in pytorch)","type":"document","URL":"https://theaisummer.com/positional-embeddings/"},
  {"id":"agarapImplementingAutoencoderPyTorch2020","accessed":{"date-parts":[["2021",11,3]]},"author":[{"family":"Agarap","given":"Abien Fred"}],"citation-key":"agarapImplementingAutoencoderPyTorch2020","issued":{"date-parts":[["2020"]]},"title":"Implementing an autoencoder in PyTorch","type":"document","URL":"https://medium.com/pytorch/implementing-an-autoencoder-in-pytorch-19baa22647d1"},
  {"id":"aggarwalRecommenderSystems2016","accessed":{"date-parts":[["2021",4,20]]},"author":[{"family":"Aggarwal","given":"Charu C."}],"citation-key":"aggarwalRecommenderSystems2016","DOI":"10.1007/978-3-319-29659-3","event-place":"Cham","issued":{"date-parts":[["2016"]]},"publisher":"Springer International Publishing","publisher-place":"Cham","title":"Recommender systems","type":"book"},
  {"id":"Aït-Sahalia_2009","author":[{"family":"Aït-Sahalia","given":"Yacine"},{"family":"Jacod","given":"Jean"}],"citation-key":"Aït-Sahalia_2009","container-title":"Annals of Statistics","DOI":"10.1214/08-aos640","issued":{"date-parts":[["2009"]]},"PMID":"null","title":"Estimating the degree of activity of jumps in high frequency data","type":"article-journal"},
  {"id":"Aitken_1996","author":[{"family":"Aitken","given":"Michael J."},{"family":"Frino","given":"Alex"}],"citation-key":"Aitken_1996","container-title":"Journal of Banking and Finance","DOI":"10.1016/s0378-4266(96)00008-8","issued":{"date-parts":[["1996"]]},"PMID":"null","title":"The accuracy of the tick test : evidence from the australian stock exchange","type":"article-journal"},
  {"id":"aitkenIntradayAnalysisProbability1995","author":[{"family":"Aitken","given":"Michael"},{"family":"Kua","given":"Amaryllis"},{"family":"Brown","given":"Philip"},{"family":"Watter","given":"Terry"},{"family":"Y. Izan","given":"H."}],"citation-key":"aitkenIntradayAnalysisProbability1995","container-title":"Australian Journal of Management","DOI":"10.1177/031289629502000202","issue":"2","issued":{"date-parts":[["1995"]]},"page":"115–154","title":"An intraday analysis of the probability of trading on the asx at the asking price","type":"article-journal","volume":"20"},
  {"id":"akibaOptunaNextgenerationHyperparameter2019","author":[{"family":"Akiba","given":"Takuya"},{"family":"Sano","given":"Shotaro"},{"family":"Yanase","given":"Toshihiko"},{"family":"Ohta","given":"Takeru"},{"family":"Koyama","given":"Masanori"}],"citation-key":"akibaOptunaNextgenerationHyperparameter2019","collection-title":"KDD '19","container-title":"Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining","DOI":"10.1145/3292500.3330701","event-place":"Anchorage, AK, USA","issued":{"date-parts":[["2019"]]},"page":"2623–2631","publisher":"Association for Computing Machinery","publisher-place":"Anchorage, AK, USA","title":"Optuna: a next-generation hyperparameter optimization framework","type":"paper-conference"},
  {"id":"aktasTradeClassificationAccuracy2014","author":[{"family":"Aktas","given":"Osman Ulas"},{"family":"Kryzanowski","given":"Lawrence"}],"citation-key":"aktasTradeClassificationAccuracy2014","container-title":"Journal of International Financial Markets, Institutions and Money","DOI":"10.1016/j.intfin.2014.08.003","issued":{"date-parts":[["2014"]]},"page":"259–282","title":"Trade classification accuracy for the bist","type":"article-journal","volume":"33"},
  {"id":"alaaHowFaithfulYour2022","abstract":"Devising domain- and model-agnostic evaluation metrics for generative models is an important and as yet unresolved problem. Most existing metrics, which were tailored solely to the image synthesis application, exhibit a limited capacity for diagnosing modes of failure of generative models across broader application domains. In this paper, we introduce a 3-dimensional metric, (α-Precision, β-Recall, Authenticity), that characterizes the ﬁdelity, diversity and generalization performance of any generative model in a wide variety of application domains. Our metric uniﬁes statistical divergence measures with precision-recall analysis, enabling sample- and distribution-level diagnoses of model ﬁdelity and diversity. We introduce generalization as an additional dimension for model performance that quantiﬁes the extent to which a model copies training data—a crucial performance indicator when modeling sensitive and private data. The three metric components are interpretable probabilistic quantities, and can be estimated via sample-level binary classiﬁcation. The sample-level nature of our metric inspires a novel use case which we call model auditing, wherein we judge the quality of individual samples generated by a (black-box) model, discarding low-quality samples and hence improving the overall model performance in a post-hoc manner.","accessed":{"date-parts":[["2025",4,4]]},"author":[{"family":"Alaa","given":"Ahmed M."},{"family":"Breugel","given":"Boris","dropping-particle":"van"},{"family":"Saveliev","given":"Evgeny"},{"family":"Schaar","given":"Mihaela","dropping-particle":"van der"}],"citation-key":"alaaHowFaithfulYour2022","DOI":"10.48550/arXiv.2102.08921","issued":{"date-parts":[["2022",7,13]]},"language":"en","number":"arXiv:2102.08921","publisher":"arXiv","source":"arXiv.org","title":"How Faithful is your Synthetic Data? Sample-level Metrics for Evaluating and Auditing Generative Models","title-short":"How Faithful is your Synthetic Data?","type":"article","URL":"http://arxiv.org/abs/2102.08921"},
  {"id":"alammarHandsonLargeLanguage2024","abstract":"Intro -- Copyright -- Table of Contents -- Preface -- An Intuition-First Philosophy -- Prerequisites -- Book Structure -- Part I: Understanding Language Models -- Part II: Using Pretrained Language Models -- Part III: Training and Fine-Tuning Language Models -- Hardware and Software Requirements -- API Keys -- Conventions Used in This Book -- Using Code Examples -- O'Reilly Online Learning -- How to Contact Us -- Acknowledgments -- Part I. Understanding Language Models -- Chapter 1. An Introduction to Large Language Models -- What Is Language AI? -- A Recent History of Language AI -- Representing Language as a Bag-of-Words -- Better Representations with Dense Vector Embeddings -- Types of Embeddings -- Encoding and Decoding Context with Attention -- Attention Is All You Need -- Representation Models: Encoder-Only Models -- Generative Models: Decoder-Only Models -- The Year of Generative AI -- The Moving Definition of a \"Large Language Model\" -- The Training Paradigm of Large Language Models -- Large Language Model Applications: What Makes Them So Useful? -- Responsible LLM Development and Usage -- Limited Resources Are All You Need -- Interfacing with Large Language Models -- Proprietary, Private Models -- Open Models -- Open Source Frameworks -- Generating Your First Text -- Summary -- Chapter 2. Tokens and Embeddings -- LLM Tokenization -- How Tokenizers Prepare the Inputs to the Language Model -- Downloading and Running an LLM -- How Does the Tokenizer Break Down Text? -- Word Versus Subword Versus Character Versus Byte Tokens -- Comparing Trained LLM Tokenizers -- Tokenizer Properties -- Token Embeddings -- A Language Model Holds Embeddings for the Vocabulary of Its Tokenizer -- Creating Contextualized Word Embeddings with Language Models -- Text Embeddings (for Sentences and Whole Documents) -- Word Embeddings Beyond LLMs","author":[{"family":"Alammar","given":"Jay"},{"family":"Grootendorst","given":"Maarten"}],"citation-key":"alammarHandsonLargeLanguage2024","edition":"1st edition","event-place":"Beijing Boston Farnham","ISBN":"978-1-0981-5096-9 978-1-0981-5093-8","issued":{"date-parts":[["2024"]]},"language":"eng","number-of-pages":"1","publisher":"O'Reilly","publisher-place":"Beijing Boston Farnham","source":"K10plus ISBN","title":"Hands-on large language models: language understanding and generation","title-short":"Hands-on large language models","type":"book"},
  {"id":"amel-zadehMachineLearningBasedFinancial2020","accessed":{"date-parts":[["2021",11,3]]},"author":[{"family":"Amel-Zadeh","given":"Amir"},{"family":"Calliess","given":"Jan-Peter"},{"family":"Kaiser","given":"Daniel"},{"family":"Roberts","given":"Stephen"}],"citation-key":"amel-zadehMachineLearningBasedFinancial2020","container-title":"SSRN Electronic Journal","DOI":"10.2139/ssrn.3520684","issued":{"date-parts":[["2020"]]},"title":"Machine learning-based financial statement analysis","type":"article-journal"},
  {"id":"aminiSelfTrainingSurvey2023","author":[{"family":"Amini","given":"Massih-Reza"},{"family":"Feofanov","given":"Vasilii"},{"family":"Pauletto","given":"Loic"},{"family":"Devijver","given":"Emilie"},{"family":"Maximov","given":"Yury"}],"citation-key":"aminiSelfTrainingSurvey2023","issued":{"date-parts":[["2023"]]},"title":"Self-training: a survey","type":"document"},
  {"id":"anandStealthTradingOptions2007","accessed":{"date-parts":[["2023",6,26]]},"author":[{"family":"Anand","given":"Amber"},{"family":"Chakravarty","given":"Sugato"}],"citation-key":"anandStealthTradingOptions2007","container-title":"The Journal of Financial and Quantitative Analysis","DOI":"10.1017/S0022109000002234","issue":"1","issued":{"date-parts":[["2007"]]},"page":"167–187","publisher":"Cambridge University Press","title":"Stealth Trading in Options Markets","type":"article-journal","volume":"42"},
  {"id":"antoniouLognormalDistributionStock2004","accessed":{"date-parts":[["2022",12,3]]},"author":[{"family":"Antoniou","given":"I"},{"family":"Ivanov","given":"Vi.V"},{"family":"Ivanov","given":"Va.V"},{"family":"Zrelov","given":"P.V"}],"citation-key":"antoniouLognormalDistributionStock2004","container-title":"Physica A: Statistical Mechanics and its Applications","DOI":"10.1016/j.physa.2003.09.034","issue":"3–4","issued":{"date-parts":[["2004"]]},"page":"617–638","title":"On the log-normal distribution of stock market data","type":"article-journal","volume":"331"},
  {"id":"arikTabnetAttentiveInterpretable2020","author":[{"family":"Arik","given":"Sercan O."},{"family":"Pfister","given":"Tomas"}],"citation-key":"arikTabnetAttentiveInterpretable2020","issued":{"date-parts":[["2020"]]},"title":"TabNet: attentive interpretable tabular learning","type":"document"},
  {"id":"arpitWhyRegularizedAutoEncoders2016","accessed":{"date-parts":[["2021",11,15]]},"author":[{"family":"Arpit","given":"Devansh"},{"family":"Zhou","given":"Yingbo"},{"family":"Ngo","given":"Hung"},{"family":"Govindaraju","given":"Venu"}],"citation-key":"arpitWhyRegularizedAutoEncoders2016","issued":{"date-parts":[["2016"]]},"title":"Why regularized auto-encoders learn sparse representation?","type":"document","URL":"http://arxiv.org/abs/1505.05561"},
  {"id":"Asquith_2010","author":[{"family":"Asquith","given":"Paul"},{"family":"Oman","given":"Rebecca"},{"family":"Safaya","given":"Christopher"}],"citation-key":"Asquith_2010","container-title":"Journal of Financial Markets","DOI":"10.2139/ssrn.951420","issued":{"date-parts":[["2010"]]},"PMID":"null","title":"Short sales and trade classification algorithms","type":"article-journal"},
  {"id":"auGroupedFeatureImportance2022","accessed":{"date-parts":[["2023",5,22]]},"author":[{"family":"Au","given":"Quay"},{"family":"Herbinger","given":"Julia"},{"family":"Stachl","given":"Clemens"},{"family":"Bischl","given":"Bernd"},{"family":"Casalicchio","given":"Giuseppe"}],"citation-key":"auGroupedFeatureImportance2022","container-title":"Data Mining and Knowledge Discovery","DOI":"10.1007/s10618-022-00840-5","issue":"4","issued":{"date-parts":[["2022"]]},"page":"1401–1450","title":"Grouped feature importance and combined features effect plot","type":"article-journal","volume":"36"},
  {"id":"averyRecommenderSystemsEvaluating1997","accessed":{"date-parts":[["2021",3,21]]},"author":[{"family":"Avery","given":"Christopher"},{"family":"Zeckhauser","given":"Richard"}],"citation-key":"averyRecommenderSystemsEvaluating1997","container-title":"Communications of the ACM","DOI":"10.1145/245108.245127","issue":"3","issued":{"date-parts":[["1997"]]},"page":"88–89","title":"Recommender systems for evaluating computer messages","type":"article-journal","volume":"40"},
  {"id":"badaroTransformersTabularData","author":[{"family":"Badaro","given":"Gilbert"},{"family":"Saeed","given":"Mohammed"},{"family":"Papotti","given":"Paolo"}],"citation-key":"badaroTransformersTabularData","title":"Transformers for tabular data representation: a survey of models and applications","type":"article-journal"},
  {"id":"bahdanauNeuralMachineTranslation2016","author":[{"family":"Bahdanau","given":"Dzmitry"},{"family":"Cho","given":"Kyunghyun"},{"family":"Bengio","given":"Yoshua"}],"citation-key":"bahdanauNeuralMachineTranslation2016","container-title":"Proceedings of the 3rd International Conference on Learning Representations","event-place":"San Diego, CA, USA","issued":{"date-parts":[["2015"]]},"publisher-place":"San Diego, CA, USA","title":"Neural machine translation by jointly learning to align and translate","type":"paper-conference"},
  {"id":"bahriSCARFSelfsupervisedContrastive2022","author":[{"family":"Bahri","given":"Dara"},{"family":"Jiang","given":"Heinrich"},{"family":"Tay","given":"Yi"},{"family":"Metzler","given":"Donald"}],"citation-key":"bahriSCARFSelfsupervisedContrastive2022","container-title":"Proceedings of the 10th International Conference on Learning Representations","event-place":"Online","issued":{"date-parts":[["2022"]]},"publisher-place":"Online","title":"SCARF: self-supervised contrastive learning using random feature corruption","type":"paper-conference"},
  {"id":"baLayerNormalization2016","author":[{"family":"Ba","given":"Jimmy Lei"},{"family":"Kiros","given":"Jamie Ryan"},{"family":"Hinton","given":"Geoffrey E."}],"citation-key":"baLayerNormalization2016","issued":{"date-parts":[["2016"]]},"title":"Layer normalization","type":"document"},
  {"id":"banachewiczKaggleBookData2022","author":[{"family":"Banachewicz","given":"Konrad"},{"family":"Massaron","given":"Luca"}],"citation-key":"banachewiczKaggleBookData2022","edition":"[First edition]","event-place":"Birmingham","issued":{"date-parts":[["2022"]]},"publisher":"Packt Publishing","publisher-place":"Birmingham","title":"The kaggle book: data analysis and machine learning for competitive data science","type":"book"},
  {"id":"baptistaRelationPrognosticsPredictor2022","author":[{"family":"Baptista","given":"Marcia L."},{"family":"Goebel","given":"Kai"},{"family":"Henriques","given":"Elsa M.P."}],"citation-key":"baptistaRelationPrognosticsPredictor2022","container-title":"Artificial Intelligence","DOI":"10.1016/j.artint.2022.103667","issued":{"date-parts":[["2022"]]},"page":"103667","title":"Relation between prognostics predictor evaluation metrics and local interpretability shap values","type":"article-journal","volume":"306"},
  {"id":"Barndorff-Nielsen_2005","author":[{"family":"Barndorff-Nielsen","given":"Ole E."},{"family":"Shephard","given":"Neil"}],"citation-key":"Barndorff-Nielsen_2005","container-title":"Journal of Financial Econometrics","DOI":"10.1093/jjfinec/nbi022","issued":{"date-parts":[["2005"]]},"PMID":"null","title":"Econometrics of testing for jumps in financial economics using bipower variation","type":"article-journal"},
  {"id":"barredoarrietaExplainableArtificialIntelligence2020","accessed":{"date-parts":[["2023",4,8]]},"author":[{"family":"Barredo Arrieta","given":"Alejandro"},{"family":"Díaz-Rodríguez","given":"Natalia"},{"family":"Del Ser","given":"Javier"},{"family":"Bennetot","given":"Adrien"},{"family":"Tabik","given":"Siham"},{"family":"Barbado","given":"Alberto"},{"family":"Garcia","given":"Salvador"},{"family":"Gil-Lopez","given":"Sergio"},{"family":"Molina","given":"Daniel"},{"family":"Benjamins","given":"Richard"},{"family":"Chatila","given":"Raja"},{"family":"Herrera","given":"Francisco"}],"citation-key":"barredoarrietaExplainableArtificialIntelligence2020","container-title":"Information Fusion","DOI":"10.1016/j.inffus.2019.12.012","issued":{"date-parts":[["2020"]]},"page":"82–115","title":"Explainable artificial intelligence (xai): concepts, taxonomies, opportunities and challenges toward responsible ai","type":"article-journal","volume":"58"},
  {"id":"basakPredictingDirectionStock2019","author":[{"family":"Basak","given":"Suryoday"},{"family":"Kar","given":"Saibal"},{"family":"Saha","given":"Snehanshu"},{"family":"Khaidem","given":"Luckyson"},{"family":"Dey","given":"Sudeepa Roy"}],"citation-key":"basakPredictingDirectionStock2019","container-title":"The North American Journal of Economics and Finance","DOI":"10.1016/j.najef.2018.06.013","issued":{"date-parts":[["2019"]]},"page":"552–567","title":"Predicting the direction of stock market prices using tree-based classifiers","type":"article-journal","volume":"47"},
  {"id":"bastingsElephantInterpretabilityRoom2020","accessed":{"date-parts":[["2023",1,7]]},"author":[{"family":"Bastings","given":"Jasmijn"},{"family":"Filippova","given":"Katja"}],"citation-key":"bastingsElephantInterpretabilityRoom2020","container-title":"Proceedings of the Third BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP","DOI":"10.18653/v1/2020.blackboxnlp-1.14","event-place":"Online","issued":{"date-parts":[["2020"]]},"page":"149–155","publisher":"Association for Computational Linguistics","publisher-place":"Online","title":"The elephant in the interpretability room: why use attention as explanation when we have saliency methods?","type":"paper-conference"},
  {"id":"batesCrossvalidationWhatDoes2022","author":[{"family":"Bates","given":"Stephen"},{"family":"Hastie","given":"Trevor"},{"family":"Tibshirani","given":"Robert"}],"citation-key":"batesCrossvalidationWhatDoes2022","issued":{"date-parts":[["2022"]]},"title":"Cross-validation: what does it estimate and how well does it do it?","type":"document"},
  {"id":"Battalio_2006","author":[{"family":"Battalio","given":"Robert H."},{"family":"Schultz","given":"Paul H."}],"citation-key":"Battalio_2006","container-title":"Journal of Finance","DOI":"10.2139/ssrn.558543","issued":{"date-parts":[["2006"]]},"PMID":"null","title":"Options and the bubble","type":"article-journal"},
  {"id":"benalcazarSyntheticIDCard2022","abstract":"Currently, it is ever more common to access online services for activities which formerly required physical attendance. From banking operations to visa applications, a signiﬁcant number of processes have been digitised, especially since the advent of the COVID-19 pandemic, requiring remote biometric authentication of the user. On the downside, some subjects intend to interfere with the normal operation of remote systems for personal proﬁt by using fake identity documents, such as passports and ID cards. Deep learning solutions to detect such frauds have been presented in the literature. However, due to privacy concerns and the sensitive nature of personal identity documents, developing a dataset with the necessary number of examples for training deep neural networks is challenging. This work explores three methods for synthetically generating ID card images to increase the amount of data while training frauddetection networks. These methods include computer vision algorithms and Generative Adversarial Networks. Our results indicate that databases can be supplemented with synthetic images without any loss in performance for the print/scan Presentation Attack Instrument Species (PAIS) and a loss in performance of 1% for the screen capture PAIS.","accessed":{"date-parts":[["2024",11,28]]},"author":[{"family":"Benalcazar","given":"Daniel"},{"family":"Tapia","given":"Juan E."},{"family":"Gonzalez","given":"Sebastian"},{"family":"Busch","given":"Christoph"}],"citation-key":"benalcazarSyntheticIDCard2022","DOI":"10.48550/arXiv.2211.00098","issued":{"date-parts":[["2022",10,31]]},"language":"en","number":"arXiv:2211.00098","publisher":"arXiv","source":"arXiv.org","title":"Synthetic ID Card Image Generation for Improving Presentation Attack Detection","type":"article","URL":"http://arxiv.org/abs/2211.00098"},
  {"id":"bengioNeuralProbabilisticLanguage","author":[{"family":"Bengio","given":"Yoshua"},{"family":"Ducharme","given":"Réjean"},{"family":"Vincent","given":"Pascal"},{"family":"Jauvin","given":"Christian"}],"citation-key":"bengioNeuralProbabilisticLanguage","container-title":"Journal of Machine Learning Research","issue":"6","issued":{"date-parts":[["2003"]]},"page":"1137–1155","title":"A neural probabilistic language model","type":"article-journal","volume":"3"},
  {"id":"bengioPracticalRecommendationsGradientBased2012","author":[{"family":"Bengio","given":"Yoshua"}],"citation-key":"bengioPracticalRecommendationsGradientBased2012","collection-title":"Lecture Notes in Computer Science","container-title":"Neural Networks: Tricks of the Trade: Second Edition","DOI":"10.1007/978-3-642-35289-8\\_26","editor":[{"family":"Montavon","given":"Grégoire"},{"family":"Orr","given":"Geneviève B."},{"family":"Müller","given":"Klaus-Robert"}],"event-place":"Berlin, Heidelberg","issued":{"date-parts":[["2012"]]},"page":"437–478","publisher":"Springer","publisher-place":"Berlin, Heidelberg","title":"Practical recommendations for gradient-based training of deep architectures","type":"chapter"},
  {"id":"bennettExploitingUnlabeledData2002","accessed":{"date-parts":[["2023",4,23]]},"author":[{"family":"Bennett","given":"Kristin P."},{"family":"Demiriz","given":"Ayhan"},{"family":"Maclin","given":"Richard"}],"citation-key":"bennettExploitingUnlabeledData2002","container-title":"Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining","DOI":"10.1145/775047.775090","event-place":"Edmonton, Canada","issued":{"date-parts":[["2002"]]},"page":"289–296","publisher":"ACM","publisher-place":"Edmonton, Canada","title":"Exploiting unlabeled data in ensemble methods","type":"paper-conference"},
  {"id":"berkmanLargeOptionTrades1996","accessed":{"date-parts":[["2023",5,18]]},"author":[{"family":"Berkman","given":"Henk"}],"citation-key":"berkmanLargeOptionTrades1996","container-title":"The Review of Financial Studies","DOI":"10.1093/rfs/9.3.977","issue":"3","issued":{"date-parts":[["1996"]]},"page":"977–1002","publisher":"[Oxford University Press, Society for Financial Studies]","title":"Large option trades, market makers, and limit orders","type":"article-journal","volume":"9"},
  {"id":"bessembinderBidAskSpreadsMeasuring","author":[{"family":"Bessembinder","given":"Hendrik"}],"citation-key":"bessembinderBidAskSpreadsMeasuring","title":"Bid-ask spreads: measuring trade execution costs in financial markets","type":"article-journal"},
  {"id":"bessembinderIssuesAssessingTrade2003","author":[{"family":"Bessembinder","given":"Hendrik"}],"citation-key":"bessembinderIssuesAssessingTrade2003","container-title":"Journal of Financial Markets","DOI":"10.1016/S1386-4181(02)00064-2","issue":"3","issued":{"date-parts":[["2003"]]},"page":"233–257","title":"Issues in assessing trade execution costs","type":"article-journal","volume":"6"},
  {"id":"bishopPatternRecognitionMachine2006","author":[{"family":"Bishop","given":"Christopher M."}],"citation-key":"bishopPatternRecognitionMachine2006","collection-title":"Information science and statistics","event-place":"New York","issued":{"date-parts":[["2006"]]},"publisher":"Springer","publisher-place":"New York","title":"Pattern recognition and machine learning","type":"book"},
  {"id":"Black_1975","author":[{"family":"Black","given":"Fischer"}],"citation-key":"Black_1975","container-title":"Financial Analysts Journal","DOI":"10.2469/faj.v31.n4.36","issued":{"date-parts":[["1975"]]},"PMID":"null","title":"Fact and fantasy in the use of options","type":"article-journal"},
  {"id":"blackPricingOptionsCorporate1973","author":[{"family":"Black","given":"Fischer"},{"family":"Scholes","given":"Myron"}],"citation-key":"blackPricingOptionsCorporate1973","container-title":"The Journal of Political Economy","DOI":"10.1086/260062","issue":"3","issued":{"date-parts":[["1973"]]},"page":"637–654","title":"The pricing of options and corporate liabilities","type":"article-journal","volume":"81"},
  {"id":"blazejewskiLocalNonParametricModel2005","author":[{"family":"Blazejewski","given":"Adam"},{"family":"Coggins","given":"Richard"}],"citation-key":"blazejewskiLocalNonParametricModel2005","container-title":"Physica A: Statistical Mechanics and its Applications","DOI":"10.1016/j.physa.2004.09.033","issued":{"date-parts":[["2005"]]},"page":"481–495","title":"A local non-parametric model for trade sign inference","type":"article-journal","volume":"348"},
  {"id":"Bloomfield_1999","author":[{"family":"Bloomfield","given":"Robert J."},{"family":"O'Hara","given":"Maureen"}],"citation-key":"Bloomfield_1999","container-title":"Review of Financial Studies","DOI":"10.1093/rfs/12.1.5","issued":{"date-parts":[["1999"]]},"PMID":"null","title":"Market transparency: who wins and who loses?","type":"article-journal"},
  {"id":"boardofgovernorsofthefederalreservesystemus1YearTreasuryBill1959","accessed":{"date-parts":[["2021",10,31]]},"author":[{"literal":"Board of Governors of the Federal Reserve System (US)"}],"citation-key":"boardofgovernorsofthefederalreservesystemus1YearTreasuryBill1959","issued":{"date-parts":[["1959"]]},"title":"1-year treasury bill secondary market rate","type":"document","URL":"https://fred.stlouisfed.org/series/DTB1YR"},
  {"id":"Boehmer_2007","author":[{"family":"Boehmer","given":"Ekkehart"},{"family":"Grammig","given":"Joachim"},{"family":"Theissen","given":"Erik"}],"citation-key":"Boehmer_2007","container-title":"Journal of Financial Markets","DOI":"10.1016/j.finmar.2006.07.002","issued":{"date-parts":[["2007"]]},"PMID":"null","title":"Estimating the probability of informed trading - does trade misclassification matter?","type":"article-journal"},
  {"id":"bojanowskiEnrichingWordVectors2017","author":[{"family":"Bojanowski","given":"Piotr"},{"family":"Grave","given":"Edouard"},{"family":"Joulin","given":"Armand"},{"family":"Mikolov","given":"Tomas"}],"citation-key":"bojanowskiEnrichingWordVectors2017","container-title":"Transactions of the Association for Computational Linguistics","DOI":"10.1162/tacl\\_a\\_00051","issued":{"date-parts":[["2017"]]},"page":"135–146","title":"Enriching word vectors with subword information","type":"article-journal","volume":"5"},
  {"id":"bojerLearningsKaggleForecasting","author":[{"family":"Bojer","given":"Casper Solheim"},{"family":"Meldgaard","given":"Jens Peder"}],"citation-key":"bojerLearningsKaggleForecasting","title":"Learnings from kaggle's forecasting competitions","type":"article-journal"},
  {"id":"boleyBetterShortGreedy2021","accessed":{"date-parts":[["2023",2,27]]},"author":[{"family":"Boley","given":"Mario"},{"family":"Teshuva","given":"Simon"},{"family":"Bodic","given":"Pierre Le"},{"family":"Webb","given":"Geoffrey I."}],"citation-key":"boleyBetterShortGreedy2021","issued":{"date-parts":[["2021"]]},"title":"Better short than greedy: interpretable models through optimal rule boosting","type":"document","URL":"http://arxiv.org/abs/2101.08380"},
  {"id":"bonedSyntheticDatasetID2024","abstract":"This paper presents a new synthetic dataset of ID and travel documents, called SIDTD. The SIDTD dataset is created to help training and evaluating forged ID documents detection systems. Such a dataset has become a necessity as ID documents contain personal information and a public dataset of real documents can not be released. Moreover, forged documents are scarce, compared to legit ones, and the way they are generated varies from one fraudster to another resulting in a class of high intra-variability. In this paper we trained state-of-the-art models on this dataset and we compare them to the performance achieved in larger, but private, datasets. The creation of this dataset will help to document image analysis community to progress in the task of ID document verification.","accessed":{"date-parts":[["2024",12,10]]},"author":[{"family":"Boned","given":"Carlos"},{"family":"Talarmain","given":"Maxime"},{"family":"Ghanmi","given":"Nabil"},{"family":"Chiron","given":"Guillaume"},{"family":"Biswas","given":"Sanket"},{"family":"Awal","given":"Ahmad Montaser"},{"family":"Terrades","given":"Oriol Ramos"}],"citation-key":"bonedSyntheticDatasetID2024","DOI":"10.48550/arXiv.2401.01858","issued":{"date-parts":[["2024",1,3]]},"number":"arXiv:2401.01858","publisher":"arXiv","source":"arXiv.org","title":"Synthetic dataset of ID and Travel Document","type":"article","URL":"http://arxiv.org/abs/2401.01858"},
  {"id":"bordesIntroductionVisionLanguageModeling2024","abstract":"Following the recent popularity of Large Language Models (LLMs), several attempts have been made to extend them to the visual domain. From having a visual assistant that could guide us through unfamiliar environments to generative models that produce images using only a high-level text description, the vision-language model (VLM) applications will significantly impact our relationship with technology. However, there are many challenges that need to be addressed to improve the reliability of those models. While language is discrete, vision evolves in a much higher dimensional space in which concepts cannot always be easily discretized. To better understand the mechanics behind mapping vision to language, we present this introduction to VLMs which we hope will help anyone who would like to enter the field. First, we introduce what VLMs are, how they work, and how to train them. Then, we present and discuss approaches to evaluate VLMs. Although this work primarily focuses on mapping images to language, we also discuss extending VLMs to videos.","accessed":{"date-parts":[["2024",11,28]]},"author":[{"family":"Bordes","given":"Florian"},{"family":"Pang","given":"Richard Yuanzhe"},{"family":"Ajay","given":"Anurag"},{"family":"Li","given":"Alexander C."},{"family":"Bardes","given":"Adrien"},{"family":"Petryk","given":"Suzanne"},{"family":"Mañas","given":"Oscar"},{"family":"Lin","given":"Zhiqiu"},{"family":"Mahmoud","given":"Anas"},{"family":"Jayaraman","given":"Bargav"},{"family":"Ibrahim","given":"Mark"},{"family":"Hall","given":"Melissa"},{"family":"Xiong","given":"Yunyang"},{"family":"Lebensold","given":"Jonathan"},{"family":"Ross","given":"Candace"},{"family":"Jayakumar","given":"Srihari"},{"family":"Guo","given":"Chuan"},{"family":"Bouchacourt","given":"Diane"},{"family":"Al-Tahan","given":"Haider"},{"family":"Padthe","given":"Karthik"},{"family":"Sharma","given":"Vasu"},{"family":"Xu","given":"Hu"},{"family":"Tan","given":"Xiaoqing Ellen"},{"family":"Richards","given":"Megan"},{"family":"Lavoie","given":"Samuel"},{"family":"Astolfi","given":"Pietro"},{"family":"Hemmat","given":"Reyhane Askari"},{"family":"Chen","given":"Jun"},{"family":"Tirumala","given":"Kushal"},{"family":"Assouel","given":"Rim"},{"family":"Moayeri","given":"Mazda"},{"family":"Talattof","given":"Arjang"},{"family":"Chaudhuri","given":"Kamalika"},{"family":"Liu","given":"Zechun"},{"family":"Chen","given":"Xilun"},{"family":"Garrido","given":"Quentin"},{"family":"Ullrich","given":"Karen"},{"family":"Agrawal","given":"Aishwarya"},{"family":"Saenko","given":"Kate"},{"family":"Celikyilmaz","given":"Asli"},{"family":"Chandra","given":"Vikas"}],"citation-key":"bordesIntroductionVisionLanguageModeling2024","DOI":"10.48550/arXiv.2405.17247","issued":{"date-parts":[["2024",5,27]]},"language":"en","number":"arXiv:2405.17247","publisher":"arXiv","source":"arXiv.org","title":"An Introduction to Vision-Language Modeling","type":"article","URL":"http://arxiv.org/abs/2405.17247"},
  {"id":"borisovDeepNeuralNetworks2022","author":[{"family":"Borisov","given":"Vadim"},{"family":"Leemann","given":"Tobias"},{"family":"Sessler","given":"Kathrin"},{"family":"Haug","given":"Johannes"},{"family":"Pawelczyk","given":"Martin"},{"family":"Kasneci","given":"Gjergji"}],"citation-key":"borisovDeepNeuralNetworks2022","container-title":"IEEE Transactions on Neural Networks and Learning Systems","DOI":"10.1109/TNNLS.2022.3229161","issued":{"date-parts":[["2022"]]},"page":"1–21","title":"Deep Neural Networks and Tabular Data: A Survey","type":"article-journal"},
  {"id":"boweNewClassicalBayesian","author":[{"family":"Bowe","given":"Michael"},{"family":"Cho","given":"Sungjun"},{"family":"Hyde","given":"Stuart"},{"family":"Sung","given":"Iljin"}],"citation-key":"boweNewClassicalBayesian","issued":{"date-parts":[["2018"]]},"page":"78","title":"New classical and bayesian estimators for classifying trade direction in the absence of quotes","type":"article-journal"},
  {"id":"boxAnalysisTransformations2022","author":[{"family":"Box","given":"G E P"},{"family":"Cox","given":"D R"}],"citation-key":"boxAnalysisTransformations2022","collection-title":"Series B (Methodological)","container-title":"Journal of the Royal Statistical Society","issue":"2","issued":{"date-parts":[["1964"]]},"page":"211–252","title":"An analysis of transformations","type":"article-journal","volume":"26"},
  {"id":"breedenPricesStateContingentClaims1978","author":[{"family":"Breeden","given":"Douglas T."},{"family":"Litzenberger","given":"Robert H."}],"citation-key":"breedenPricesStateContingentClaims1978","container-title":"The Journal of Business","DOI":"10.1086/296025","issue":"4","issued":{"date-parts":[["1978"]]},"page":"621","title":"Prices of state-contingent claims implicit in option prices","type":"article-journal","volume":"51"},
  {"id":"breimanBaggingPredictors1996","accessed":{"date-parts":[["2021",7,13]]},"author":[{"family":"Breiman","given":"Leo"}],"citation-key":"breimanBaggingPredictors1996","container-title":"Machine Learning","DOI":"10.1007/BF00058655","issue":"2","issued":{"date-parts":[["1996"]]},"page":"123–140","title":"Bagging predictors","type":"article-journal","volume":"24"},
  {"id":"breimanClassificationRegressionTrees2017","author":[{"family":"Breiman","given":"Leo"},{"family":"Friedman","given":"Jerome H."},{"family":"Olshen","given":"Richard A."},{"family":"Stone","given":"Charles J."}],"citation-key":"breimanClassificationRegressionTrees2017","edition":"1","event-place":"Boca Raton, FL, USA","issued":{"date-parts":[["1984"]]},"publisher":"CLC Press","publisher-place":"Boca Raton, FL, USA","title":"Classification and regression trees","type":"book"},
  {"id":"breimanRandomForests2001","author":[{"family":"Breiman","given":"Leo"}],"citation-key":"breimanRandomForests2001","container-title":"Machine Learning","DOI":"10.1023/A:1010933404324","issue":"1","issued":{"date-parts":[["2001"]]},"page":"5–32","title":"Random forests","type":"article-journal","volume":"45"},
  {"id":"breuelEffectsHyperparametersSGD2015","accessed":{"date-parts":[["2022",10,25]]},"author":[{"family":"Breuel","given":"Thomas M."}],"citation-key":"breuelEffectsHyperparametersSGD2015","issued":{"date-parts":[["2015"]]},"title":"The effects of hyperparameters on SGD training of neural networks","type":"document"},
  {"id":"bringhurstElementsTypographicStyle2004","author":[{"family":"Bringhurst","given":"Robert"}],"citation-key":"bringhurstElementsTypographicStyle2004","edition":"3rd ed","event-place":"Point Roberts, WA","issued":{"date-parts":[["2004"]]},"publisher":"Hartley & Marks, Publishers","publisher-place":"Point Roberts, WA","title":"The elements of typographic style","type":"book"},
  {"id":"brownLanguageModelsAre2020","accessed":{"date-parts":[["2023",1,9]]},"author":[{"family":"Brown","given":"Tom B."},{"family":"Mann","given":"Benjamin"},{"family":"Ryder","given":"Nick"},{"family":"Subbiah","given":"Melanie"},{"family":"Kaplan","given":"Jared"},{"family":"Dhariwal","given":"Prafulla"},{"family":"Neelakantan","given":"Arvind"},{"family":"Shyam","given":"Pranav"},{"family":"Sastry","given":"Girish"},{"family":"Askell","given":"Amanda"},{"family":"Agarwal","given":"Sandhini"},{"family":"Herbert-Voss","given":"Ariel"},{"family":"Krueger","given":"Gretchen"},{"family":"Henighan","given":"Tom"},{"family":"Child","given":"Rewon"},{"family":"Ramesh","given":"Aditya"},{"family":"Ziegler","given":"Daniel M."},{"family":"Wu","given":"Jeffrey"},{"family":"Winter","given":"Clemens"},{"family":"Hesse","given":"Christopher"},{"family":"Chen","given":"Mark"},{"family":"Sigler","given":"Eric"},{"family":"Litwin","given":"Mateusz"},{"family":"Gray","given":"Scott"},{"family":"Chess","given":"Benjamin"},{"family":"Clark","given":"Jack"},{"family":"Berner","given":"Christopher"},{"family":"McCandlish","given":"Sam"},{"family":"Radford","given":"Alec"},{"family":"Sutskever","given":"Ilya"},{"family":"Amodei","given":"Dario"}],"citation-key":"brownLanguageModelsAre2020","issued":{"date-parts":[["2020"]]},"title":"Language models are few-shot learners","type":"document","URL":"http://arxiv.org/abs/2005.14165"},
  {"id":"burkeHybridRecommenderSystems2002","accessed":{"date-parts":[["2021",5,6]]},"author":[{"family":"Burke","given":"Robin"}],"citation-key":"burkeHybridRecommenderSystems2002","container-title":"User Modeling and User-Adapted Interaction","DOI":"10.1023/A:1021240730564","issue":"4","issued":{"date-parts":[["2002"]]},"page":"331–370","title":"Hybrid recommender systems: survey and experiments†","type":"article-journal","volume":"12"},
  {"id":"busariCrudeOilPrice2021","accessed":{"date-parts":[["2022",7,12]]},"author":[{"family":"Busari","given":"Ganiyu Adewale"},{"family":"Lim","given":"Dong Hoon"}],"citation-key":"busariCrudeOilPrice2021","container-title":"Computers & Chemical Engineering","DOI":"10.1016/j.compchemeng.2021.107513","issued":{"date-parts":[["2021"]]},"page":"107513","title":"Crude oil price prediction: a comparison between AdaBoost-LSTM and AdaBoost-GRU for improving forecasting performance","type":"article-journal","volume":"155"},
  {"id":"caoInformationalContentOption2005","author":[{"family":"Cao","given":"Charles"},{"family":"Chen","given":"Zhiwu"},{"family":"Griffin","given":"John M."}],"citation-key":"caoInformationalContentOption2005","container-title":"The Journal of Business","DOI":"10.1086/429654","issue":"3","issued":{"date-parts":[["2005"]]},"page":"1073–1109","title":"Informational content of option volume prior to takeovers","type":"article-journal","volume":"78"},
  {"id":"carionEndtoendObjectDetection2020","accessed":{"date-parts":[["2023",1,18]]},"author":[{"family":"Carion","given":"Nicolas"},{"family":"Massa","given":"Francisco"},{"family":"Synnaeve","given":"Gabriel"},{"family":"Usunier","given":"Nicolas"},{"family":"Kirillov","given":"Alexander"},{"family":"Zagoruyko","given":"Sergey"}],"citation-key":"carionEndtoendObjectDetection2020","issued":{"date-parts":[["2020"]]},"title":"End-to-end object detection with transformers","type":"document","URL":"http://arxiv.org/abs/2005.12872"},
  {"id":"carrionTradeSigningFast2020","author":[{"family":"Carrion","given":"Allen"},{"family":"Kolay","given":"Madhuparna"}],"citation-key":"carrionTradeSigningFast2020","container-title":"Financial Review","DOI":"10.1111/fire.12218","issue":"3","issued":{"date-parts":[["2020"]]},"page":"385–404","title":"Trade signing in fast markets","type":"article-journal","volume":"55"},
  {"id":"caruanaObtainingCalibratedProbabilities","author":[{"family":"Caruana","given":"Alexandru Niculescu-Mizil Rich"}],"citation-key":"caruanaObtainingCalibratedProbabilities","title":"Obtaining calibrated probabilities from boosting","type":"document"},
  {"id":"carvalhoMachineLearningInterpretability2019","accessed":{"date-parts":[["2023",4,8]]},"author":[{"family":"Carvalho","given":"Diogo V."},{"family":"Pereira","given":"Eduardo M."},{"family":"Cardoso","given":"Jaime S."}],"citation-key":"carvalhoMachineLearningInterpretability2019","container-title":"Electronics","DOI":"10.3390/electronics8080832","issue":"8","issued":{"date-parts":[["2019"]]},"page":"832","title":"Machine learning interpretability: a survey on methods and metrics","type":"article-journal","volume":"8"},
  {"id":"cerdaEncodingHighcardinalityString2022","accessed":{"date-parts":[["2023",1,28]]},"author":[{"family":"Cerda","given":"Patricio"},{"family":"Varoquaux","given":"Gaël"}],"citation-key":"cerdaEncodingHighcardinalityString2022","container-title":"IEEE Transactions on Knowledge and Data Engineering","DOI":"10.1109/TKDE.2020.2992529","issue":"3","issued":{"date-parts":[["2022"]]},"page":"1164–1176","title":"Encoding high-cardinality string categorical variables","type":"article-journal","volume":"34"},
  {"id":"chakrabartyEvaluatingTradeClassification2015","author":[{"family":"Chakrabarty","given":"Bidisha"},{"family":"Pascual","given":"Roberto"},{"family":"Shkilko","given":"Andriy"}],"citation-key":"chakrabartyEvaluatingTradeClassification2015","container-title":"Journal of Financial Markets","DOI":"10.1016/j.finmar.2015.06.001","issued":{"date-parts":[["2015"]]},"page":"52–79","title":"Evaluating trade classification algorithms: bulk volume classification versus the tick rule and the lee-ready algorithm","type":"article-journal","volume":"25"},
  {"id":"chakrabartyTradeClassificationAlgorithms2007","author":[{"family":"Chakrabarty","given":"Bidisha"},{"family":"Li","given":"Bingguang"},{"family":"Nguyen","given":"Vanthuan"},{"family":"Van Ness","given":"Robert A."}],"citation-key":"chakrabartyTradeClassificationAlgorithms2007","container-title":"Journal of Banking & Finance","DOI":"10.1016/j.jbankfin.2007.03.003","issue":"12","issued":{"date-parts":[["2007"]]},"page":"3806–3821","title":"Trade classification algorithms for electronic communications network trades","type":"article-journal","volume":"31"},
  {"id":"chakrabartyTradeClassificationAlgorithms2012","author":[{"family":"Chakrabarty","given":"Bidisha"},{"family":"Pascual","given":"Roberto"},{"family":"Shkilko","given":"Andriy"}],"citation-key":"chakrabartyTradeClassificationAlgorithms2012","container-title":"SSRN Electronic Journal","DOI":"10.2139/ssrn.2182819","issued":{"date-parts":[["2012"]]},"title":"Trade classification algorithms: a horse race between the bulk-based and the tick-based rules","type":"article-journal"},
  {"id":"chakravartyInformedTradingStock2004","accessed":{"date-parts":[["2023",6,2]]},"author":[{"family":"Chakravarty","given":"Sugato"},{"family":"Gulen","given":"Huseyin"},{"family":"Mayhew","given":"Stewart"}],"citation-key":"chakravartyInformedTradingStock2004","container-title":"The Journal of Finance","DOI":"10.1111/j.1540-6261.2004.00661.x","issue":"3","issued":{"date-parts":[["2004"]]},"page":"1235–1257","title":"Informed Trading in Stock and Option Markets","type":"article-journal","volume":"59"},
  {"id":"Chan_1995","author":[{"family":"Chan","given":"Louis K.C."},{"family":"Lakonishok","given":"Josef"}],"citation-key":"Chan_1995","container-title":"Journal of Finance","DOI":"10.1111/j.1540-6261.1995.tb04053.x","issued":{"date-parts":[["1995"]]},"PMID":"null","title":"The behavior of stock prices around institutional trades","type":"article-journal"},
  {"id":"Chan_2002","author":[{"family":"Chan","given":"Kalok"},{"family":"Chung","given":"Y. Peter"},{"family":"Fong","given":"Wai-Ming"}],"citation-key":"Chan_2002","container-title":"Review of Financial Studies","DOI":"10.2139/ssrn.170356","issued":{"date-parts":[["2002"]]},"PMID":"null","title":"The informational role of stock and option volume","type":"article-journal"},
  {"id":"chanAlgorithmicTrading","author":[{"family":"Chan","given":"Ernie"}],"citation-key":"chanAlgorithmicTrading","DOI":"10.1002/9781118676998","page":"225","title":"Algorithmic trading","type":"article-journal"},
  {"id":"chanTransformersGeneralizeDifferently2022","accessed":{"date-parts":[["2022",10,18]]},"author":[{"family":"Chan","given":"Stephanie C. Y."},{"family":"Dasgupta","given":"Ishita"},{"family":"Kim","given":"Junkyung"},{"family":"Kumaran","given":"Dharshan"},{"family":"Lampinen","given":"Andrew K."},{"family":"Hill","given":"Felix"}],"citation-key":"chanTransformersGeneralizeDifferently2022","issued":{"date-parts":[["2022"]]},"title":"Transformers generalize differently from information stored in context vs in weights","type":"document","URL":"http://arxiv.org/abs/2210.05675"},
  {"id":"chapelleSemiSupervisedClassificationLow2005","author":[{"family":"Chapelle","given":"Olivier"},{"family":"Zien","given":"Alexander"}],"citation-key":"chapelleSemiSupervisedClassificationLow2005","container-title":"Proceedings of the Tenth International Workshop on Artificial Intelligence and Statistics","issued":{"date-parts":[["2005"]]},"page":"57–64","title":"Semi-supervised classification by low density separation","type":"paper-conference"},
  {"id":"chapelleSemisupervisedLearning2006","author":[{"family":"Chapelle","given":"Olivier"},{"family":"Schölkopf","given":"Bernhard"},{"family":"Zien","given":"Alexander"}],"citation-key":"chapelleSemisupervisedLearning2006","collection-title":"Adaptive computation and machine learning","event-place":"Cambridge, MA, USA","issued":{"date-parts":[["2006"]]},"publisher":"MIT Press","publisher-place":"Cambridge, MA, USA","title":"Semi-supervised learning","type":"book"},
  {"id":"chaumUntraceableElectronicMail1981","accessed":{"date-parts":[["2022",10,14]]},"author":[{"family":"Chaum","given":"David L."}],"citation-key":"chaumUntraceableElectronicMail1981","container-title":"Communications of the ACM","DOI":"10.1145/358549.358563","issue":"2","issued":{"date-parts":[["1981"]]},"page":"84–90","title":"Untraceable electronic mail, return addresses, and digital pseudonyms","type":"article-journal","volume":"24"},
  {"id":"cheferGenericAttentionmodelExplainability2021","author":[{"family":"Chefer","given":"Hila"},{"family":"Gur","given":"Shir"},{"family":"Wolf","given":"Lior"}],"citation-key":"cheferGenericAttentionmodelExplainability2021","container-title":"2021 IEEE/CVF International Conference on Computer Vision","DOI":"10.1109/ICCV48922.2021.00045","event-place":"Montreal, QC, Canada","issued":{"date-parts":[["2021"]]},"page":"387–396","publisher":"IEEE","publisher-place":"Montreal, QC, Canada","title":"Generic attention-model explainability for interpreting bi-modal and encoder-decoder transformers","type":"paper-conference"},
  {"id":"cheferTransformerInterpretabilityAttention2021","accessed":{"date-parts":[["2023",1,8]]},"author":[{"family":"Chefer","given":"Hila"},{"family":"Gur","given":"Shir"},{"family":"Wolf","given":"Lior"}],"citation-key":"cheferTransformerInterpretabilityAttention2021","container-title":"2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)","DOI":"10.1109/CVPR46437.2021.00084","event-place":"Nashville, TN, USA","issued":{"date-parts":[["2021"]]},"page":"782–791","publisher":"IEEE","publisher-place":"Nashville, TN, USA","title":"Transformer interpretability beyond attention visualization","type":"paper-conference"},
  {"id":"chenAlgorithmsEstimateShapley2022","accessed":{"date-parts":[["2023",5,23]]},"author":[{"family":"Chen","given":"Hugh"},{"family":"Covert","given":"Ian C."},{"family":"Lundberg","given":"Scott M."},{"family":"Lee","given":"Su-In"}],"citation-key":"chenAlgorithmsEstimateShapley2022","issued":{"date-parts":[["2022"]]},"title":"Algorithms to estimate Shapley value feature attributions","type":"document","URL":"http://arxiv.org/abs/2207.07605"},
  {"id":"chenDebiasedSelfTrainingSemiSupervised2022","author":[{"family":"Chen","given":"Baixu"},{"family":"Jiang","given":"Junguang"},{"family":"Wang","given":"Ximei"},{"family":"Wan","given":"Pengfei"},{"family":"Wang","given":"Jianmin"},{"family":"Long","given":"Mingsheng"}],"citation-key":"chenDebiasedSelfTrainingSemiSupervised2022","container-title":"Advances in Neural Information Processing Systems","event-place":"New Orleans, LA, USA","issued":{"date-parts":[["2022"]]},"page":"32424–32437","publisher":"Curran Associates, Inc.","publisher-place":"New Orleans, LA, USA","title":"Debiased self-training for semi-supervised learning","type":"paper-conference","volume":"36"},
  {"id":"chenDeepLearningAsset2021","author":[{"family":"Chen","given":"Luyang"},{"family":"Pelger","given":"Markus"},{"family":"Zhu","given":"Jason"}],"citation-key":"chenDeepLearningAsset2021","issued":{"date-parts":[["2021"]]},"title":"Deep learning in asset pricing","type":"document"},
  {"id":"chenDemandCrashInsurance2019","accessed":{"date-parts":[["2023",6,26]]},"author":[{"family":"Chen","given":"Hui"},{"family":"Joslin","given":"Scott"},{"family":"Ni","given":"Sophie Xiaoyan"}],"citation-key":"chenDemandCrashInsurance2019","container-title":"The Review of Financial Studies","DOI":"10.1093/rfs/hhy004","issue":"1","issued":{"date-parts":[["2019"]]},"page":"228–265","title":"Demand for Crash Insurance, Intermediary Constraints, and Risk Premia in Financial Markets","type":"article-journal","volume":"32"},
  {"id":"chenExcelFormerNeuralNetwork2023","accessed":{"date-parts":[["2023",1,14]]},"author":[{"family":"Chen","given":"Jintai"},{"family":"Yan","given":"Jiahuan"},{"family":"Chen","given":"Danny Ziyi"},{"family":"Wu","given":"Jian"}],"citation-key":"chenExcelFormerNeuralNetwork2023","issued":{"date-parts":[["2023"]]},"title":"ExcelFormer: a neural network surpassing gbdts on tabular data","type":"document","URL":"http://arxiv.org/abs/2301.02819"},
  {"id":"chenExpandingPerformanceBoundaries2025","abstract":"We introduce InternVL 2.5, an advanced multimodal large language model (MLLM) series that builds upon InternVL 2.0, maintaining its core model architecture while introducing significant enhancements in training and testing strategies as well as data quality. In this work, we delve into the relationship between model scaling and performance, systematically exploring the performance trends in vision encoders, language models, dataset sizes, and test-time configurations. Through extensive evaluations on a wide range of benchmarks, including multi-discipline reasoning, document understanding, multi-image / video understanding, real-world comprehension, multimodal hallucination detection, visual grounding, multilingual capabilities, and pure language processing, InternVL 2.5 exhibits competitive performance, rivaling leading commercial models such as GPT-4o and Claude-3.5-Sonnet. Notably, our model is the first open-source MLLMs to surpass 70% on the MMMU benchmark, achieving a 3.7-point improvement through Chain-of-Thought (CoT) reasoning and showcasing strong potential for test-time scaling. We hope this model contributes to the open-source community by setting new standards for developing and applying multimodal AI systems. HuggingFace demo see https://huggingface.co/spaces/OpenGVLab/InternVL","accessed":{"date-parts":[["2025",4,4]]},"author":[{"family":"Chen","given":"Zhe"},{"family":"Wang","given":"Weiyun"},{"family":"Cao","given":"Yue"},{"family":"Liu","given":"Yangzhou"},{"family":"Gao","given":"Zhangwei"},{"family":"Cui","given":"Erfei"},{"family":"Zhu","given":"Jinguo"},{"family":"Ye","given":"Shenglong"},{"family":"Tian","given":"Hao"},{"family":"Liu","given":"Zhaoyang"},{"family":"Gu","given":"Lixin"},{"family":"Wang","given":"Xuehui"},{"family":"Li","given":"Qingyun"},{"family":"Ren","given":"Yimin"},{"family":"Chen","given":"Zixuan"},{"family":"Luo","given":"Jiapeng"},{"family":"Wang","given":"Jiahao"},{"family":"Jiang","given":"Tan"},{"family":"Wang","given":"Bo"},{"family":"He","given":"Conghui"},{"family":"Shi","given":"Botian"},{"family":"Zhang","given":"Xingcheng"},{"family":"Lv","given":"Han"},{"family":"Wang","given":"Yi"},{"family":"Shao","given":"Wenqi"},{"family":"Chu","given":"Pei"},{"family":"Tu","given":"Zhongying"},{"family":"He","given":"Tong"},{"family":"Wu","given":"Zhiyong"},{"family":"Deng","given":"Huipeng"},{"family":"Ge","given":"Jiaye"},{"family":"Chen","given":"Kai"},{"family":"Zhang","given":"Kaipeng"},{"family":"Wang","given":"Limin"},{"family":"Dou","given":"Min"},{"family":"Lu","given":"Lewei"},{"family":"Zhu","given":"Xizhou"},{"family":"Lu","given":"Tong"},{"family":"Lin","given":"Dahua"},{"family":"Qiao","given":"Yu"},{"family":"Dai","given":"Jifeng"},{"family":"Wang","given":"Wenhai"}],"citation-key":"chenExpandingPerformanceBoundaries2025","DOI":"10.48550/arXiv.2412.05271","issued":{"date-parts":[["2025",1,13]]},"language":"en","number":"arXiv:2412.05271","publisher":"arXiv","source":"arXiv.org","title":"Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling","type":"article","URL":"http://arxiv.org/abs/2412.05271"},
  {"id":"chengWideDeepLearning2016","accessed":{"date-parts":[["2023",1,26]]},"author":[{"family":"Cheng","given":"Heng-Tze"},{"family":"Koc","given":"Levent"},{"family":"Harmsen","given":"Jeremiah"},{"family":"Shaked","given":"Tal"},{"family":"Chandra","given":"Tushar"},{"family":"Aradhye","given":"Hrishi"},{"family":"Anderson","given":"Glen"},{"family":"Corrado","given":"Greg"},{"family":"Chai","given":"Wei"},{"family":"Ispir","given":"Mustafa"},{"family":"Anil","given":"Rohan"},{"family":"Haque","given":"Zakaria"},{"family":"Hong","given":"Lichan"},{"family":"Jain","given":"Vihan"},{"family":"Liu","given":"Xiaobing"},{"family":"Shah","given":"Hemal"}],"citation-key":"chengWideDeepLearning2016","container-title":"Proceedings of the 1st Workshop on Deep Learning for Recommender Systems","DOI":"10.1145/2988450.2988454","event-place":"Boston MA USA","issued":{"date-parts":[["2016"]]},"page":"7–10","publisher":"ACM","publisher-place":"Boston MA USA","title":"Wide & deep learning for recommender systems","type":"paper-conference"},
  {"id":"chenSimpleFrameworkContrastive2020","author":[{"family":"Chen","given":"Ting"},{"family":"Kornblith","given":"Simon"},{"family":"Norouzi","given":"Mohammad"},{"family":"Hinton","given":"Geoffrey"}],"citation-key":"chenSimpleFrameworkContrastive2020","container-title":"Proceedings of the 37th International Conference on Machine Learning","event-place":"Virtual","issued":{"date-parts":[["2020"]]},"page":"1597–1607","publisher":"PMLR","publisher-place":"Virtual","title":"A simple framework for contrastive learning of visual representations","type":"paper-conference","volume":"119"},
  {"id":"chenTrainingDeepNets2016","accessed":{"date-parts":[["2022",11,23]]},"author":[{"family":"Chen","given":"Tianqi"},{"family":"Xu","given":"Bing"},{"family":"Zhang","given":"Chiyuan"},{"family":"Guestrin","given":"Carlos"}],"citation-key":"chenTrainingDeepNets2016","issued":{"date-parts":[["2016"]]},"title":"Training deep nets with sublinear memory cost","type":"document","URL":"http://arxiv.org/abs/1604.06174"},
  {"id":"chenTrueModelTrue2020","accessed":{"date-parts":[["2023",4,9]]},"author":[{"family":"Chen","given":"Hugh"},{"family":"Janizek","given":"Joseph D."},{"family":"Lundberg","given":"Scott"},{"family":"Lee","given":"Su-In"}],"citation-key":"chenTrueModelTrue2020","issued":{"date-parts":[["2020"]]},"title":"True to the model or true to the data?","type":"document","URL":"http://arxiv.org/abs/2006.16234"},
  {"id":"chenXGBoostScalableTree2016","author":[{"family":"Chen","given":"Tianqi"},{"family":"Guestrin","given":"Carlos"}],"citation-key":"chenXGBoostScalableTree2016","container-title":"Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining","DOI":"10.1145/2939672.2939785","editor":[{"literal":"Krishnapuram,Balaji"},{"literal":"Shah, Mohak"},{"literal":"Smola, Alexander J."},{"literal":"Aggarwal, Charu C."},{"literal":"Shen, Dou"},{"literal":"Rastogi, Rajeev"}],"event-place":"San Francisco, CA, USA","issued":{"date-parts":[["2016"]]},"page":"785–794","publisher-place":"San Francisco, CA, USA","title":"XGBoost: a scalable tree boosting system","type":"paper-conference"},
  {"id":"choiEstimationBidAskSpreads1988","author":[{"family":"Choi","given":"J. Y."},{"family":"Salandro","given":"Dan"},{"family":"Shastri","given":"Kuldeep"}],"citation-key":"choiEstimationBidAskSpreads1988","container-title":"The Journal of Financial and Quantitative Analysis","DOI":"10.2307/2330882","issue":"2","issued":{"date-parts":[["1988"]]},"page":"219–230","publisher":"Cambridge University Press","title":"On the Estimation of Bid-Ask Spreads: Theory and Evidence","type":"article-journal","volume":"23"},
  {"id":"cholakovGatedTabTransformerEnhancedDeep2022","accessed":{"date-parts":[["2023",1,11]]},"author":[{"family":"Cholakov","given":"Radostin"},{"family":"Kolev","given":"Todor"}],"citation-key":"cholakovGatedTabTransformerEnhancedDeep2022","issued":{"date-parts":[["2022"]]},"title":"The GatedTabTransformer. An enhanced deep learning architecture for tabular modeling","type":"document","URL":"http://arxiv.org/abs/2201.00199"},
  {"id":"chordiaIndexOptionTrading2021","accessed":{"date-parts":[["2023",6,20]]},"author":[{"family":"Chordia","given":"Tarun"},{"family":"Kurov","given":"Alexander"},{"family":"Muravyev","given":"Dmitriy"},{"family":"Subrahmanyam","given":"Avanidhar"}],"citation-key":"chordiaIndexOptionTrading2021","container-title":"Management Science","DOI":"10.1287/mnsc.2019.3529","issue":"3","issued":{"date-parts":[["2021"]]},"page":"1758–1778","title":"Index Option Trading Activity and Market Returns","type":"article-journal","volume":"67"},
  {"id":"christianoDeepReinforcementLearning2017","accessed":{"date-parts":[["2021",9,23]]},"author":[{"family":"Christiano","given":"Paul"},{"family":"Leike","given":"Jan"},{"family":"Brown","given":"Tom B."},{"family":"Martic","given":"Miljan"},{"family":"Legg","given":"Shane"},{"family":"Amodei","given":"Dario"}],"citation-key":"christianoDeepReinforcementLearning2017","issued":{"date-parts":[["2017"]]},"title":"Deep reinforcement learning from human preferences","type":"document","URL":"http://arxiv.org/abs/1706.03741"},
  {"id":"chuanSuccessAdaBoostIts2021","accessed":{"date-parts":[["2022",7,12]]},"author":[{"family":"Chuan","given":"Yijian"},{"family":"Zhao","given":"Chaoyi"},{"family":"He","given":"Zhenrui"},{"family":"Wu","given":"Lan"}],"citation-key":"chuanSuccessAdaBoostIts2021","container-title":"International Journal of Financial Engineering","DOI":"10.1142/S2424786321420019","issue":"02","issued":{"date-parts":[["2021"]]},"page":"2142001","title":"The success of AdaBoost and its application in portfolio management","type":"article-journal","volume":"08"},
  {"id":"clarkElectraPretrainingText2020","author":[{"family":"Clark","given":"Kevin"},{"family":"Luong","given":"Minh-Thang"},{"family":"Le","given":"Quoc V."},{"family":"Manning","given":"Christopher D."}],"citation-key":"clarkElectraPretrainingText2020","container-title":"Proceedings of the 8th International Conference on Learning Representations","event-place":"Online","issued":{"date-parts":[["2020"]]},"publisher-place":"Online","title":"ELECTRA: pre-training text encoders as discriminators rather than generators","type":"paper-conference"},
  {"id":"clarkWhatDoesBERT2019","author":[{"family":"Clark","given":"Kevin"},{"family":"Khandelwal","given":"Urvashi"},{"family":"Levy","given":"Omer"},{"family":"Manning","given":"Christopher D."}],"citation-key":"clarkWhatDoesBERT2019","container-title":"Proceedings of the 2019 ACL workshop BlackboxNLP: Analyzing and interpreting neural networks for NLP","DOI":"10.18653/v1/W19-4828","editor":[{"literal":"Linzen, Tal"},{"literal":"Chrupala, Grzegorz"},{"literal":"Belinkov, Yonatan"},{"literal":"Hupkes, Dieuwke"}],"event-place":"Florence, Italy","issued":{"date-parts":[["2019"]]},"page":"276–286","publisher":"Association for Computational Linguistics","publisher-place":"Florence, Italy","title":"What does BERT look at? An analysis of BERT's attention","type":"paper-conference"},
  {"id":"coenenVisualizingMeasuringGeometry2019","author":[{"family":"Coenen","given":"Andy"},{"family":"Reif","given":"Emily"},{"family":"Yuan","given":"Ann"},{"family":"Kim","given":"Been"},{"family":"Pearce","given":"Adam"},{"family":"Viégas","given":"Fernanda"},{"family":"Wattenberg","given":"Martin"}],"citation-key":"coenenVisualizingMeasuringGeometry2019","issued":{"date-parts":[["2019"]]},"title":"Visualizing and Measuring the Geometry of BERT","type":"document"},
  {"id":"collin-dufresneInformedTradingStock2021","accessed":{"date-parts":[["2023",6,26]]},"author":[{"family":"Collin-Dufresne","given":"Pierre"},{"family":"Fos","given":"Vyacheslav"},{"family":"Muravyev","given":"Dmitry"}],"citation-key":"collin-dufresneInformedTradingStock2021","container-title":"Journal of Financial and Quantitative Analysis","DOI":"10.1017/S0022109020000629","issue":"6","issued":{"date-parts":[["2021"]]},"page":"1945–1984","title":"Informed Trading in the Stock Market and Option-Price Discovery","type":"article-journal","volume":"56"},
  {"id":"congDEEPSEQUENCEMODELING","author":[{"family":"Cong","given":"Lin William"},{"family":"Tang","given":"Ke"},{"family":"Wang","given":"Jingyuan"},{"family":"Zhang","given":"Yang"}],"citation-key":"congDEEPSEQUENCEMODELING","title":"Deep sequence modeling: development and applications in asset pricing","type":"document"},
  {"id":"Cont_2013","author":[{"family":"Cont","given":"Rama"},{"family":"Larrard","given":"Adrien","non-dropping-particle":"de"}],"citation-key":"Cont_2013","container-title":"Siam Journal on Financial Mathematics","DOI":"10.1137/110856605","issued":{"date-parts":[["2013"]]},"PMID":"null","title":"Price dynamics in a markovian limit order market","type":"article-journal"},
  {"id":"CosineSimilarityEmbeddingsReally","accessed":{"date-parts":[["2025",11,11]]},"citation-key":"CosineSimilarityEmbeddingsReally","title":"Is Cosine-Similarity of Embeddings Really About Similarity?","type":"webpage","URL":"https://arxiv.org/html/2403.05440v1"},
  {"id":"covertExplainingRemovingUnified","author":[{"family":"Covert","given":"Ian C"}],"citation-key":"covertExplainingRemovingUnified","title":"Explaining by Removing: A Unified Framework for Model Explanation","type":"article-journal"},
  {"id":"covertUnderstandingGlobalFeature2020","author":[{"family":"Covert","given":"Ian"},{"family":"Lundberg","given":"Scott M"},{"family":"Lee","given":"Su-In"}],"citation-key":"covertUnderstandingGlobalFeature2020","container-title":"Advances in Neural Information Processing Systems","event-place":"Online","issued":{"date-parts":[["2020"]]},"page":"17212–17223","publisher":"Curran Associates, Inc.","publisher-place":"Online","title":"Understanding global feature contributions with additive importance measures","type":"paper-conference","volume":"33"},
  {"id":"cowgillAlgorithmicFairnessEconomics","author":[{"family":"Cowgill","given":"Bo"},{"family":"Tucker","given":"Catherine"}],"citation-key":"cowgillAlgorithmicFairnessEconomics","page":"31","title":"Algorithmic fairness and economics","type":"article-journal"},
  {"id":"coxExploratoryDataAnalysis2017","accessed":{"date-parts":[["2023",1,22]]},"author":[{"family":"Cox","given":"Victoria"}],"citation-key":"coxExploratoryDataAnalysis2017","container-title":"Translating Statistics to Make Decisions","contributor":[{"family":"Cox","given":"Victoria"}],"DOI":"10.1007/978-1-4842-2256-0\\_3","event-place":"Berkeley, CA","issued":{"date-parts":[["2017"]]},"page":"47–74","publisher":"Apress","publisher-place":"Berkeley, CA","title":"Exploratory data analysis: what data do I have?","type":"chapter"},
  {"id":"coxOptionPricingSimplified1979","author":[{"family":"Cox","given":"John C"},{"family":"Ross","given":"A"}],"citation-key":"coxOptionPricingSimplified1979","DOI":"10.1016/0304-405X(79)90015-1","issued":{"date-parts":[["1979"]]},"page":"35","title":"Option pricing: a simplified approach","type":"article-journal"},
  {"id":"coxRelationForwardPrices1981","author":[{"family":"Cox","given":"John C."}],"citation-key":"coxRelationForwardPrices1981","container-title":"Journal of Financial Economics","DOI":"10.1016/0304-405X(81)90002-7","issued":{"date-parts":[["1981"]]},"page":"321–346","title":"The relation between forward prices and futures prices","type":"article-journal"},
  {"id":"creamerAutomatedTradingBoosting2010","accessed":{"date-parts":[["2022",7,12]]},"author":[{"family":"Creamer","given":"Germán"},{"family":"Freund","given":"Yoav"}],"citation-key":"creamerAutomatedTradingBoosting2010","container-title":"Quantitative Finance","DOI":"10.1080/14697680903104113","issue":"4","issued":{"date-parts":[["2010"]]},"page":"401–420","title":"Automated trading with boosting and expert weighting","type":"article-journal","volume":"10"},
  {"id":"crspDATADESCRIPTIONSGUIDE","author":[{"literal":"CRSP"}],"citation-key":"crspDATADESCRIPTIONSGUIDE","page":"130","title":"Data descriptions guide crsp us stock & us index databases","type":"article-journal","URL":"http://www.crsp.org/files/data_descriptions_guide_0.pdf"},
  {"id":"culurcielloFallRNNLSTM2019","accessed":{"date-parts":[["2021",12,3]]},"author":[{"family":"Culurciello","given":"Eugenio"}],"citation-key":"culurcielloFallRNNLSTM2019","issued":{"date-parts":[["2019"]]},"title":"The fall of RNN / LSTM","type":"document","URL":"https://towardsdatascience.com/the-fall-of-rnn-lstm-2d1594c74ce0"},
  {"id":"culurcielloMemoryAttentionSequences2018","accessed":{"date-parts":[["2021",12,3]]},"author":[{"family":"Culurciello","given":"Eugenio"}],"citation-key":"culurcielloMemoryAttentionSequences2018","issued":{"date-parts":[["2018"]]},"title":"Memory, attention, sequences","type":"document","URL":"https://towardsdatascience.com/memory-attention-sequences-37456d271992"},
  {"id":"daiEmbeddingLearning2022","accessed":{"date-parts":[["2023",2,24]]},"author":[{"family":"Dai","given":"Ben"},{"family":"Shen","given":"Xiaotong"},{"family":"Wang","given":"Junhui"}],"citation-key":"daiEmbeddingLearning2022","container-title":"Journal of the American Statistical Association","DOI":"10.1080/01621459.2020.1775614","issue":"537","issued":{"date-parts":[["2022"]]},"page":"307–319","title":"Embedding learning","type":"article-journal","volume":"117"},
  {"id":"daiTransformerXLAttentiveLanguage2019","accessed":{"date-parts":[["2023",1,11]]},"author":[{"family":"Dai","given":"Zihang"},{"family":"Yang","given":"Zhilin"},{"family":"Yang","given":"Yiming"},{"family":"Carbonell","given":"Jaime"},{"family":"Le","given":"Quoc V."},{"family":"Salakhutdinov","given":"Ruslan"}],"citation-key":"daiTransformerXLAttentiveLanguage2019","issued":{"date-parts":[["2019"]]},"title":"Transformer-XL: attentive language models beyond a fixed-length context","type":"document","URL":"http://arxiv.org/abs/1901.02860"},
  {"id":"dalche-bucSemisupervisedMarginBoost2001","author":[{"family":"Alché-Buc","given":"Florence","non-dropping-particle":"d' "},{"family":"Grandvalet","given":"Yves"},{"family":"Ambroise","given":"Christophe"}],"citation-key":"dalche-bucSemisupervisedMarginBoost2001","container-title":"Advances in Neural Information Processing Systems","event-place":"Vancouver, Canada","issued":{"date-parts":[["2001"]]},"page":"553–560","publisher":"MIT Press","publisher-place":"Vancouver, Canada","title":"Semi-supervised MarginBoost","type":"paper-conference","volume":"14"},
  {"id":"darabiContrastiveMixupSelf2021","accessed":{"date-parts":[["2023",1,24]]},"author":[{"family":"Darabi","given":"Sajad"},{"family":"Fazeli","given":"Shayan"},{"family":"Pazoki","given":"Ali"},{"family":"Sankararaman","given":"Sriram"},{"family":"Sarrafzadeh","given":"Majid"}],"citation-key":"darabiContrastiveMixupSelf2021","issued":{"date-parts":[["2021"]]},"title":"Contrastive mixup: self- and semi-supervised learning for tabular domain","type":"document","URL":"http://arxiv.org/abs/2108.12296"},
  {"id":"dauphinLanguageModelingGated2017","accessed":{"date-parts":[["2023",1,17]]},"author":[{"family":"Dauphin","given":"Yann N."},{"family":"Fan","given":"Angela"},{"family":"Auli","given":"Michael"},{"family":"Grangier","given":"David"}],"citation-key":"dauphinLanguageModelingGated2017","issued":{"date-parts":[["2017"]]},"title":"Language modeling with gated convolutional networks","type":"document","URL":"http://arxiv.org/abs/1612.08083"},
  {"id":"davisGradientBoostingQuantitative2019","author":[{"family":"Davis","given":"Jesse"},{"family":"Devos","given":"Laurens"},{"family":"Reyners","given":"Sofie"},{"family":"Schoutens","given":"Wim"}],"citation-key":"davisGradientBoostingQuantitative2019","container-title":"The Journal of Computational Finance","DOI":"10.21314/JCF.2020.403","issue":"4","issued":{"date-parts":[["2019"]]},"page":"4","title":"Gradient boosting for quantitative finance","type":"article-journal","volume":"24"},
  {"id":"dehghaniUniversalTransformers2019","author":[{"family":"Dehghani","given":"Mostafa"},{"family":"Gouws","given":"Stephan"},{"family":"Vinyals","given":"Oriol"},{"family":"Uszkoreit","given":"Jakob"},{"family":"Kaiser","given":"Łukasz"}],"citation-key":"dehghaniUniversalTransformers2019","issued":{"date-parts":[["2019"]]},"title":"Universal transformers","type":"document"},
  {"id":"deisenrothMathematicsMachineLearning","author":[{"family":"Deisenroth","given":"Marc Peter"},{"family":"Faisal","given":"A Aldo"},{"family":"Ong","given":"Cheng Soon"}],"citation-key":"deisenrothMathematicsMachineLearning","DOI":"10.1017/9781108679930","page":"417","title":"Mathematics for machine learning","type":"article-journal"},
  {"id":"deitkeMolmoPixMoOpen2024","abstract":"Today’s most advanced vision-language models (VLMs) remain proprietary. The strongest open-weight models rely heavily on synthetic data from proprietary VLMs to achieve good performance, effectively distilling these closed VLMs into open ones. As a result, the community has been missing foundational knowledge about how to build performant VLMs from scratch. We present Molmo, a new family of VLMs that are state-of-the-art in their class of openness. Our key contribution is a collection of new datasets called PixMo, including a dataset of highly detailed image captions for pre-training, a free-form image Q&A dataset for fine-tuning, and an innovative 2D pointing dataset, all collected without the use of external VLMs. The success of our approach relies on careful modeling choices, a welltuned training pipeline, and, most critically, the quality of our newly collected datasets. Our best-in-class 72B model not only outperforms others in the class of open weight and data models, but also outperforms larger proprietary models including Claude 3.5 Sonnet, and Gemini 1.5 Pro and Flash, second only to GPT-4o based on both academic benchmarks and on a large human evaluation. Our model weights, new datasets, and source code are available at https://molmo.allenai.org/blog.","accessed":{"date-parts":[["2024",12,9]]},"author":[{"family":"Deitke","given":"Matt"},{"family":"Clark","given":"Christopher"},{"family":"Lee","given":"Sangho"},{"family":"Tripathi","given":"Rohun"},{"family":"Yang","given":"Yue"},{"family":"Park","given":"Jae Sung"},{"family":"Salehi","given":"Mohammadreza"},{"family":"Muennighoff","given":"Niklas"},{"family":"Lo","given":"Kyle"},{"family":"Soldaini","given":"Luca"},{"family":"Lu","given":"Jiasen"},{"family":"Anderson","given":"Taira"},{"family":"Bransom","given":"Erin"},{"family":"Ehsani","given":"Kiana"},{"family":"Ngo","given":"Huong"},{"family":"Chen","given":"YenSung"},{"family":"Patel","given":"Ajay"},{"family":"Yatskar","given":"Mark"},{"family":"Callison-Burch","given":"Chris"},{"family":"Head","given":"Andrew"},{"family":"Hendrix","given":"Rose"},{"family":"Bastani","given":"Favyen"},{"family":"VanderBilt","given":"Eli"},{"family":"Lambert","given":"Nathan"},{"family":"Chou","given":"Yvonne"},{"family":"Chheda","given":"Arnavi"},{"family":"Sparks","given":"Jenna"},{"family":"Skjonsberg","given":"Sam"},{"family":"Schmitz","given":"Michael"},{"family":"Sarnat","given":"Aaron"},{"family":"Bischoff","given":"Byron"},{"family":"Walsh","given":"Pete"},{"family":"Newell","given":"Chris"},{"family":"Wolters","given":"Piper"},{"family":"Gupta","given":"Tanmay"},{"family":"Zeng","given":"Kuo-Hao"},{"family":"Borchardt","given":"Jon"},{"family":"Groeneveld","given":"Dirk"},{"family":"Nam","given":"Crystal"},{"family":"Lebrecht","given":"Sophie"},{"family":"Wittlif","given":"Caitlin"},{"family":"Schoenick","given":"Carissa"},{"family":"Michel","given":"Oscar"},{"family":"Krishna","given":"Ranjay"},{"family":"Weihs","given":"Luca"},{"family":"Smith","given":"Noah A."},{"family":"Hajishirzi","given":"Hannaneh"},{"family":"Girshick","given":"Ross"},{"family":"Farhadi","given":"Ali"},{"family":"Kembhavi","given":"Aniruddha"}],"citation-key":"deitkeMolmoPixMoOpen2024","DOI":"10.48550/arXiv.2409.17146","issued":{"date-parts":[["2024",12,5]]},"language":"en","number":"arXiv:2409.17146","publisher":"arXiv","source":"arXiv.org","title":"Molmo and PixMo: Open Weights and Open Data for State-of-the-Art Vision-Language Models","title-short":"Molmo and PixMo","type":"article","URL":"http://arxiv.org/abs/2409.17146"},
  {"id":"dengStrategicTradingManipulation","author":[{"family":"Deng","given":"Xinyi"},{"family":"He","given":"Xue-Zhong"}],"citation-key":"dengStrategicTradingManipulation","title":"Strategic trading and manipulation: machine learning in limit order markets","type":"article-journal"},
  {"id":"dettmersQLoRAEfficientFinetuning2023","abstract":"We present QLoRA, an efficient finetuning approach that reduces memory usage enough to finetune a 65B parameter model on a single 48GB GPU while preserving full 16-bit finetuning task performance. QLoRA backpropagates gradients through a frozen, 4-bit quantized pretrained language model into Low Rank Adapters~(LoRA). Our best model family, which we name Guanaco, outperforms all previous openly released models on the Vicuna benchmark, reaching 99.3% of the performance level of ChatGPT while only requiring 24 hours of finetuning on a single GPU. QLoRA introduces a number of innovations to save memory without sacrificing performance: (a) 4-bit NormalFloat (NF4), a new data type that is information theoretically optimal for normally distributed weights (b) double quantization to reduce the average memory footprint by quantizing the quantization constants, and (c) paged optimziers to manage memory spikes. We use QLoRA to finetune more than 1,000 models, providing a detailed analysis of instruction following and chatbot performance across 8 instruction datasets, multiple model types (LLaMA, T5), and model scales that would be infeasible to run with regular finetuning (e.g. 33B and 65B parameter models). Our results show that QLoRA finetuning on a small high-quality dataset leads to state-of-the-art results, even when using smaller models than the previous SoTA. We provide a detailed analysis of chatbot performance based on both human and GPT-4 evaluations showing that GPT-4 evaluations are a cheap and reasonable alternative to human evaluation. Furthermore, we find that current chatbot benchmarks are not trustworthy to accurately evaluate the performance levels of chatbots. A lemon-picked analysis demonstrates where Guanaco fails compared to ChatGPT. We release all of our models and code, including CUDA kernels for 4-bit training.","accessed":{"date-parts":[["2024",11,26]]},"author":[{"family":"Dettmers","given":"Tim"},{"family":"Pagnoni","given":"Artidoro"},{"family":"Holtzman","given":"Ari"},{"family":"Zettlemoyer","given":"Luke"}],"citation-key":"dettmersQLoRAEfficientFinetuning2023","DOI":"10.48550/arXiv.2305.14314","issued":{"date-parts":[["2023",5,23]]},"language":"en","number":"arXiv:2305.14314","publisher":"arXiv","source":"arXiv.org","title":"QLoRA: Efficient Finetuning of Quantized LLMs","title-short":"QLoRA","type":"article","URL":"http://arxiv.org/abs/2305.14314"},
  {"id":"devlinBERTPretrainingDeep2019","author":[{"family":"Devlin","given":"Jacob"},{"family":"Chang","given":"Ming-Wei"},{"family":"Lee","given":"Kenton"},{"family":"Toutanova","given":"Kristina"}],"citation-key":"devlinBERTPretrainingDeep2019","container-title":"Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)","DOI":"10.18653/v1/N19-1423","event-place":"Minneapolis, MN","issued":{"date-parts":[["2019"]]},"page":"4171–4186","publisher":"Association for Computational Linguistics","publisher-place":"Minneapolis, MN","title":"BERT: pre-training of deep bidirectional transformers for language understanding","type":"paper-conference","volume":"1"},
  {"id":"dieboldComparingPredictiveAccuracy1995","author":[{"family":"Diebold","given":"Francis X."},{"family":"Mariano","given":"Roberto S."}],"citation-key":"dieboldComparingPredictiveAccuracy1995","container-title":"Journal of Business & Economic Statistics","DOI":"10.1080/07350015.1995.10524599","issue":"3","issued":{"date-parts":[["1995"]]},"page":"253–263","title":"Comparing predictive accuracy","type":"article-journal","volume":"13"},
  {"id":"dongTablePretrainingSurvey2022","accessed":{"date-parts":[["2023",1,25]]},"author":[{"family":"Dong","given":"Haoyu"},{"family":"Cheng","given":"Zhoujun"},{"family":"He","given":"Xinyi"},{"family":"Zhou","given":"Mengyu"},{"family":"Zhou","given":"Anda"},{"family":"Zhou","given":"Fan"},{"family":"Liu","given":"Ao"},{"family":"Han","given":"Shi"},{"family":"Zhang","given":"Dongmei"}],"citation-key":"dongTablePretrainingSurvey2022","container-title":"Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence","DOI":"10.24963/ijcai.2022/761","event-place":"Vienna, Austria","issued":{"date-parts":[["2022"]]},"page":"5426–5435","publisher":"International Joint Conferences on Artificial Intelligence Organization","publisher-place":"Vienna, Austria","title":"Table pre-training: a survey on model architectures, pre-training objectives, and downstream tasks","type":"paper-conference"},
  {"id":"dorogushCatBoostGradientBoosting","author":[{"family":"Dorogush","given":"Anna Veronika"},{"family":"Ershov","given":"Vasily"},{"family":"Gulin","given":"Andrey"}],"citation-key":"dorogushCatBoostGradientBoosting","title":"CatBoost: gradient boosting with categorical features support","type":"article-journal"},
  {"id":"dosovitskiyImageWorth16x162021","author":[{"family":"Dosovitskiy","given":"Alexey"},{"family":"Beyer","given":"Lucas"},{"family":"Kolesnikov","given":"Alexander"},{"family":"Weissenborn","given":"Dirk"},{"family":"Zhai","given":"Xiaohua"},{"family":"Unterthiner","given":"Thomas"},{"family":"Dehghani","given":"Mostafa"},{"family":"Minderer","given":"Matthias"},{"family":"Heigold","given":"Georg"},{"family":"Gelly","given":"Sylvain"},{"family":"Uszkoreit","given":"Jakob"},{"family":"Houlsby","given":"Neil"}],"citation-key":"dosovitskiyImageWorth16x162021","container-title":"Proceedings of the 9th International Conference on Learning Representations","event-place":"Online","issued":{"date-parts":[["2021"]]},"publisher-place":"Online","title":"An image is worth 16x16 words: transformers for image recognition at scale","type":"paper-conference"},
  {"id":"duTextCrafterAccuratelyRendering2025","abstract":"This paper explores the task of Complex Visual Text Generation (CVTG), which centers on generating intricate textual content distributed across diverse regions within visual images. In CVTG, image generation models often rendering distorted and blurred visual text or missing some visual text. To tackle these challenges, we propose TextCrafter, a novel multi-visual text rendering method. TextCrafter employs a progressive strategy to decompose complex visual text into distinct components while ensuring robust alignment between textual content and its visual carrier. Additionally, it incorporates a token focus enhancement mechanism to amplify the prominence of visual text during the generation process. TextCrafter effectively addresses key challenges in CVTG tasks, such as text confusion, omissions, and blurriness. Moreover, we present a new benchmark dataset, CVTG-2K, tailored to rigorously evaluate the performance of generative models on CVTG tasks. Extensive experiments demonstrate that our method surpasses state-of-the-art approaches.","accessed":{"date-parts":[["2025",4,7]]},"author":[{"family":"Du","given":"Nikai"},{"family":"Chen","given":"Zhennan"},{"family":"Chen","given":"Zhizhou"},{"family":"Gao","given":"Shan"},{"family":"Chen","given":"Xi"},{"family":"Jiang","given":"Zhengkai"},{"family":"Yang","given":"Jian"},{"family":"Tai","given":"Ying"}],"citation-key":"duTextCrafterAccuratelyRendering2025","DOI":"10.48550/arXiv.2503.23461","issued":{"date-parts":[["2025",4,1]]},"language":"en","number":"arXiv:2503.23461","publisher":"arXiv","source":"arXiv.org","title":"TextCrafter: Accurately Rendering Multiple Texts in Complex Visual Scenes","title-short":"TextCrafter","type":"article","URL":"http://arxiv.org/abs/2503.23461"},
  {"id":"duTextCrafterAccuratelyRendering2025a","abstract":"This paper explores the task of Complex Visual Text Generation (CVTG), which centers on generating intricate textual content distributed across diverse regions within visual images. In CVTG, image generation models often rendering distorted and blurred visual text or missing some visual text. To tackle these challenges, we propose TextCrafter, a novel multi-visual text rendering method. TextCrafter employs a progressive strategy to decompose complex visual text into distinct components while ensuring robust alignment between textual content and its visual carrier. Additionally, it incorporates a token focus enhancement mechanism to amplify the prominence of visual text during the generation process. TextCrafter effectively addresses key challenges in CVTG tasks, such as text confusion, omissions, and blurriness. Moreover, we present a new benchmark dataset, CVTG2K, tailored to rigorously evaluate the performance of generative models on CVTG tasks. Extensive experiments demonstrate that our method surpasses state-of-the-art approaches.","accessed":{"date-parts":[["2025",11,12]]},"author":[{"family":"Du","given":"Nikai"},{"family":"Chen","given":"Zhennan"},{"family":"Gao","given":"Shan"},{"family":"Chen","given":"Zhizhou"},{"family":"Chen","given":"Xi"},{"family":"Jiang","given":"Zhengkai"},{"family":"Yang","given":"Jian"},{"family":"Tai","given":"Ying"}],"citation-key":"duTextCrafterAccuratelyRendering2025a","DOI":"10.48550/arXiv.2503.23461","issued":{"date-parts":[["2025",8,19]]},"language":"en","number":"arXiv:2503.23461","publisher":"arXiv","source":"arXiv.org","title":"TextCrafter: Accurately Rendering Multiple Texts in Complex Visual Scenes","title-short":"TextCrafter","type":"article","URL":"http://arxiv.org/abs/2503.23461"},
  {"id":"Easley_1996","author":[{"family":"Easley","given":"David"},{"family":"Kiefer","given":"Nicholas M."},{"family":"O'Hara","given":"Maureen"},{"family":"Paperman","given":"Joseph B."}],"citation-key":"Easley_1996","container-title":"Journal of Finance","DOI":"10.1111/j.1540-6261.1996.tb04074.x","issued":{"date-parts":[["1996"]]},"PMID":"null","title":"Liquidity, information, and infrequently traded stocks","type":"article-journal"},
  {"id":"Easley_2002","author":[{"family":"Easley","given":"David"},{"family":"Hvidkjaer","given":"Soeren"},{"family":"O'Hara","given":"Maureen"}],"citation-key":"Easley_2002","container-title":"Journal of Finance","DOI":"10.1111/1540-6261.00493","issued":{"date-parts":[["2002"]]},"PMID":"null","title":"Is information risk a determinant of asset returns","type":"article-journal"},
  {"id":"Easley_2012","author":[{"family":"Easley","given":"David"},{"family":"Prado","given":"Marcos Lopez","non-dropping-particle":"de"},{"family":"O'Hara","given":"Maureen"}],"citation-key":"Easley_2012","container-title":"null","DOI":"null","issued":{"date-parts":[["2012"]]},"PMID":"null","title":"Bulk classification of trading activity","type":"article-journal"},
  {"id":"easleyDiscerningInformationTrade2016","author":[{"family":"Easley","given":"David"},{"family":"Prado","given":"Marcos Lopez","non-dropping-particle":"de"},{"family":"O'Hara","given":"Maureen"}],"citation-key":"easleyDiscerningInformationTrade2016","container-title":"Journal of Financial Economics","DOI":"10.1016/j.jfineco.2016.01.018","issue":"2","issued":{"date-parts":[["2016"]]},"page":"269–285","title":"Discerning information from trade data","type":"article-journal","volume":"120"},
  {"id":"easleyFlowToxicityLiquidity2012","accessed":{"date-parts":[["2022",10,9]]},"author":[{"family":"Easley","given":"David"},{"family":"López de Prado","given":"Marcos M."},{"family":"O'Hara","given":"Maureen"}],"citation-key":"easleyFlowToxicityLiquidity2012","container-title":"Review of Financial Studies","DOI":"10.1093/rfs/hhs053","issue":"5","issued":{"date-parts":[["2012"]]},"page":"1457–1493","title":"Flow toxicity and liquidity in a high-frequency world","type":"article-journal","volume":"25"},
  {"id":"easleyMicrostructureFlashCrash2011","accessed":{"date-parts":[["2023",2,10]]},"author":[{"family":"Easley","given":"David"},{"family":"López de Prado","given":"Marcos M."},{"family":"O'Hara","given":"Maureen"}],"citation-key":"easleyMicrostructureFlashCrash2011","container-title":"The Journal of Portfolio Management","DOI":"10.3905/jpm.2011.37.2.118","issue":"2","issued":{"date-parts":[["2011"]]},"page":"118–128","title":"The microstructure of the “flash crash”: <i>flow toxicity, liquidity crashes, and the probability of informed trading</i>","type":"article-journal","volume":"37"},
  {"id":"easleyOptionVolumeStock1998","author":[{"family":"Easley","given":"David"},{"family":"O'Hara","given":"Maureen"},{"family":"Srinivas","given":"P.S."}],"citation-key":"easleyOptionVolumeStock1998","container-title":"The Journal of Finance","DOI":"10.1111/0022-1082.194060","issue":"2","issued":{"date-parts":[["1998"]]},"page":"431–465","title":"Option volume and stock prices: evidence on where informed traders trade","type":"article-journal","volume":"53"},
  {"id":"elhage2021mathematical","accessed":{"date-parts":[["2023",1,11]]},"author":[{"family":"Elhage","given":"Nelson"},{"family":"Nanda","given":"Neel"},{"family":"Olsson","given":"Catherine"},{"family":"Henighan","given":"Tom"},{"family":"Joseph","given":"Nicholas"},{"family":"Mann","given":"Ben"},{"family":"Askell","given":"Amanda"},{"family":"Bai","given":"Yuntao"},{"family":"Chen","given":"Anna"},{"family":"Conerly","given":"Tom"},{"family":"DasSarma","given":"Nova"},{"family":"Drain","given":"Dawn"},{"family":"Ganguli","given":"Deep"},{"family":"Hatfield-Dodds","given":"Zac"},{"family":"Hernandez","given":"Danny"},{"family":"Jones","given":"Andy"},{"family":"Kernion","given":"Jackson"},{"family":"Lovitt","given":"Liane"},{"family":"Ndousse","given":"Kamal"},{"family":"Amodei","given":"Dario"},{"family":"Brown","given":"Tom"},{"family":"Clark","given":"Jack"},{"family":"Kaplan","given":"Jared"},{"family":"McCandlish","given":"Sam"},{"family":"Olah","given":"Chris"}],"citation-key":"elhage2021mathematical","container-title":"Transformer Circuits Thread","issued":{"date-parts":[["2021"]]},"title":"A mathematical framework for transformer circuits","type":"article-journal","URL":"https://transformer-circuits.pub/2021/framework/index.html"},
  {"id":"ellisAccuracyTradeClassification2000","author":[{"family":"Ellis","given":"Katrina"},{"family":"Michaely","given":"Roni"},{"family":"O'Hara","given":"Maureen"}],"citation-key":"ellisAccuracyTradeClassification2000","container-title":"The Journal of Financial and Quantitative Analysis","DOI":"10.2307/2676254","issue":"4","issued":{"date-parts":[["2000"]]},"page":"529–551","title":"The accuracy of trade classification rules: evidence from nasdaq","type":"article-journal","volume":"35"},
  {"id":"enguehardSemiSupervisedLearningDeep2019","accessed":{"date-parts":[["2023",4,14]]},"author":[{"family":"Enguehard","given":"Joseph"},{"family":"O'Halloran","given":"Peter"},{"family":"Gholipour","given":"Ali"}],"citation-key":"enguehardSemiSupervisedLearningDeep2019","container-title":"IEEE access : practical innovations, open solutions","container-title-short":"IEEE Access","DOI":"10.1109/ACCESS.2019.2891970","issued":{"date-parts":[["2019"]]},"page":"11093–11104","title":"Semi-supervised learning with deep embedded clustering for image classification and segmentation","type":"article-journal","volume":"7"},
  {"id":"erhanWhyDoesUnsupervised","author":[{"family":"Erhan","given":"Dumitru"},{"family":"Bengio","given":"Yoshua"},{"family":"Courville","given":"Aaron"},{"family":"Manzagol","given":"Pierre-Antoine"},{"family":"Vincent","given":"Pascal"},{"family":"Bengio","given":"Samy"}],"citation-key":"erhanWhyDoesUnsupervised","container-title":"Journal of Machine Learning Research","issue":"19","issued":{"date-parts":[["2010"]]},"page":"625–660","title":"Why does unsupervised pre-training help deep learning?","type":"article-journal","volume":"11"},
  {"id":"ExplainingIndividualPredictions","accessed":{"date-parts":[["2023",3,26]]},"citation-key":"ExplainingIndividualPredictions","DOI":"10.1016/j.artint.2021.103502","title":"Explaining individual predictions when features are dependent: more accurate approximations to shapley values | elsevier enhanced reader","type":"document"},
  {"id":"falkPracticalRecommenderSystems2019","author":[{"family":"Falk","given":"Kim"}],"citation-key":"falkPracticalRecommenderSystems2019","event-place":"Shelter Island, NY","issued":{"date-parts":[["2019"]]},"publisher":"Manning","publisher-place":"Shelter Island, NY","title":"Practical recommender systems","type":"book"},
  {"id":"famaCAPMWantedDead1996","accessed":{"date-parts":[["2021",10,29]]},"author":[{"family":"Fama","given":"Eugene F."},{"family":"French","given":"Kenneth R."}],"citation-key":"famaCAPMWantedDead1996","container-title":"The Journal of Finance","DOI":"10.1111/j.1540-6261.1996.tb05233.x","issue":"5","issued":{"date-parts":[["1996"]]},"page":"1947–1958","title":"The CAPM is wanted, dead or alive","type":"article-journal","volume":"51"},
  {"id":"famaCommonRiskFactors1993","accessed":{"date-parts":[["2021",10,29]]},"author":[{"family":"Fama","given":"Eugene F."},{"family":"French","given":"Kenneth R."}],"citation-key":"famaCommonRiskFactors1993","container-title":"Journal of Financial Economics","DOI":"10.1016/0304-405X(93)90023-5","issue":"1","issued":{"date-parts":[["1993"]]},"page":"3–56","title":"Common risk factors in the returns on stocks and bonds","type":"article-journal","volume":"33"},
  {"id":"famaFivefactorAssetPricing2015","accessed":{"date-parts":[["2021",10,31]]},"author":[{"family":"Fama","given":"Eugene F."},{"family":"French","given":"Kenneth R."}],"citation-key":"famaFivefactorAssetPricing2015","container-title":"Journal of Financial Economics","DOI":"10.1016/j.jfineco.2014.10.010","issue":"1","issued":{"date-parts":[["2015"]]},"page":"1–22","title":"A five-factor asset pricing model","type":"article-journal","volume":"116"},
  {"id":"fanScalingLanguageFreeVisual2025","abstract":"Visual Self-Supervised Learning (SSL) currently underperforms Contrastive Language-Image Pretraining (CLIP) in multimodal settings such as Visual Question Answering (VQA). This multimodal gap is often attributed to the semantics introduced by language supervision, even though visual SSL and CLIP models are often trained on different data. In this work, we ask the question: \"Do visual self-supervised approaches lag behind CLIP due to the lack of language supervision, or differences in the training data?\" We study this question by training both visual SSL and CLIP models on the same MetaCLIP data, and leveraging VQA as a diverse testbed for vision encoders. In this controlled setup, visual SSL models scale better than CLIP models in terms of data and model capacity, and visual SSL performance does not saturate even after scaling up to 7B parameters. Consequently, we observe visual SSL methods achieve CLIP-level performance on a wide range of VQA and classic vision benchmarks. These findings demonstrate that pure visual SSL can match language-supervised visual pretraining at scale, opening new opportunities for vision-centric representation learning.","accessed":{"date-parts":[["2025",4,3]]},"author":[{"family":"Fan","given":"David"},{"family":"Tong","given":"Shengbang"},{"family":"Zhu","given":"Jiachen"},{"family":"Sinha","given":"Koustuv"},{"family":"Liu","given":"Zhuang"},{"family":"Chen","given":"Xinlei"},{"family":"Rabbat","given":"Michael"},{"family":"Ballas","given":"Nicolas"},{"family":"LeCun","given":"Yann"},{"family":"Bar","given":"Amir"},{"family":"Xie","given":"Saining"}],"citation-key":"fanScalingLanguageFreeVisual2025","DOI":"10.48550/arXiv.2504.01017","issued":{"date-parts":[["2025",4,1]]},"language":"en","number":"arXiv:2504.01017","publisher":"arXiv","source":"arXiv.org","title":"Scaling Language-Free Visual Representation Learning","type":"article","URL":"http://arxiv.org/abs/2504.01017"},
  {"id":"fardRecommenderSystemBased2013","author":[{"family":"Fard","given":"Karamollah Bagheri"},{"family":"Nilashi","given":"Mehrbakhsh"},{"family":"Rahmani","given":"Mohsen"},{"family":"Ibrahim","given":"Othman"}],"citation-key":"fardRecommenderSystemBased2013","issue":"6","issued":{"date-parts":[["2013"]]},"page":"11","title":"Recommender system based on semantic similarity","type":"article-journal","volume":"3"},
  {"id":"fawziDiscoveringFasterMatrix2022","accessed":{"date-parts":[["2022",10,10]]},"author":[{"family":"Fawzi","given":"Alhussein"},{"family":"Balog","given":"Matej"},{"family":"Huang","given":"Aja"},{"family":"Hubert","given":"Thomas"},{"family":"Romera-Paredes","given":"Bernardino"},{"family":"Barekatain","given":"Mohammadamin"},{"family":"Novikov","given":"Alexander"},{"family":"R. Ruiz","given":"Francisco J."},{"family":"Schrittwieser","given":"Julian"},{"family":"Swirszcz","given":"Grzegorz"},{"family":"Silver","given":"David"},{"family":"Hassabis","given":"Demis"},{"family":"Kohli","given":"Pushmeet"}],"citation-key":"fawziDiscoveringFasterMatrix2022","container-title":"Nature","DOI":"10.1038/s41586-022-05172-4","issue":"7930","issued":{"date-parts":[["2022"]]},"page":"47–53","title":"Discovering faster matrix multiplication algorithms with reinforcement learning","type":"article-journal","volume":"610"},
  {"id":"fedeniaMachineLearningCorporate2021","author":[{"family":"Fedenia","given":"Mark A."},{"family":"Nam","given":"Seunghan"},{"family":"Ronen","given":"Tavy"}],"citation-key":"fedeniaMachineLearningCorporate2021","container-title":"SSRN Electronic Journal","DOI":"10.2139/ssrn.3848068","issued":{"date-parts":[["2021"]]},"title":"Machine learning in the corporate bond market and beyond: a new classifier","type":"article-journal"},
  {"id":"federalreservebankofstlouisNBERBasedRecession2022","accessed":{"date-parts":[["2022",7,26]]},"author":[{"literal":"Federal Reserve Bank of St. Louis"}],"citation-key":"federalreservebankofstlouisNBERBasedRecession2022","issued":{"date-parts":[["2022"]]},"title":"NBER based recession indicators for the united states from the period following the peak through the trough [USREC]","type":"document","URL":"https://fred.stlouisfed.org/series/USREC"},
  {"id":"feldhutterSameBondDifferent2012","accessed":{"date-parts":[["2022",12,30]]},"author":[{"family":"Feldhütter","given":"Peter"}],"citation-key":"feldhutterSameBondDifferent2012","container-title":"The Review of Financial Studies","DOI":"10.1093/rfs/hhr093","issue":"4","issued":{"date-parts":[["2012"]]},"page":"1155–1206","title":"The same bond at different prices: identifying search frictions and selling pressures","type":"article-journal","volume":"25"},
  {"id":"fengDeepLearningPredicting2018","author":[{"family":"Feng","given":"Guanhao"},{"family":"He","given":"Jingyu"},{"family":"Polson","given":"Nicholas G."}],"citation-key":"fengDeepLearningPredicting2018","issued":{"date-parts":[["2018"]]},"title":"Deep learning for predicting asset returns","type":"document"},
  {"id":"fengLogtransformationItsImplications2014","author":[{"family":"Feng","given":"Changyong"},{"family":"Wang","given":"Hongyue"},{"family":"Lu","given":"Naiji"},{"family":"Chen","given":"Tian"},{"family":"He","given":"Hua"},{"family":"Lu","given":"Ying"},{"family":"Tu","given":"Xin M"}],"citation-key":"fengLogtransformationItsImplications2014","issue":"2","issued":{"date-parts":[["2014"]]},"page":"6","title":"Log-transformation and its implications for data analysis","type":"article-journal","volume":"26"},
  {"id":"fiedlerSimpleModificationsImprove2021","author":[{"family":"Fiedler","given":"James"}],"citation-key":"fiedlerSimpleModificationsImprove2021","issued":{"date-parts":[["2021"]]},"title":"Simple modifications to improve tabular neural networks","type":"document"},
  {"id":"finucaneDirectTestMethods2000","author":[{"family":"Finucane","given":"Thomas J."}],"citation-key":"finucaneDirectTestMethods2000","container-title":"The Journal of Financial and Quantitative Analysis","DOI":"10.2307/2676255","issue":"4","issued":{"date-parts":[["2000"]]},"page":"553–576","title":"A direct test of methods for inferring trade direction from intra-day data","type":"article-journal","volume":"35"},
  {"id":"fisherAllModelsAre","author":[{"family":"Fisher","given":"Aaron"},{"family":"Rudin","given":"Cynthia"},{"family":"Dominici","given":"Francesca"}],"citation-key":"fisherAllModelsAre","title":"All models are wrong, but many are useful: learning a variable's importance by studying an entire class of prediction models simultaneously","type":"article-journal"},
  {"id":"fletcherSophisticatedInvestorsFederal1988","accessed":{"date-parts":[["2023",2,4]]},"author":[{"family":"Fletcher","given":"C. Edward"}],"citation-key":"fletcherSophisticatedInvestorsFederal1988","container-title":"Duke Law Journal","DOI":"10.2307/1372532","issue":"6","issued":{"date-parts":[["1988"]]},"page":"1081","title":"Sophisticated investors under the federal securities laws","type":"article-journal","volume":"1988"},
  {"id":"frazziniBettingBeta2014","accessed":{"date-parts":[["2020",11,15]]},"author":[{"family":"Frazzini","given":"Andrea"},{"family":"Pedersen","given":"Lasse Heje"}],"citation-key":"frazziniBettingBeta2014","container-title":"Journal of Financial Economics","DOI":"10.1016/j.jfineco.2013.10.005","issue":"1","issued":{"date-parts":[["2014"]]},"page":"1–25","title":"Betting against beta","type":"article-journal","volume":"111"},
  {"id":"freeboroughInvestigatingExplainabilityMethods2022","accessed":{"date-parts":[["2023",5,22]]},"author":[{"family":"Freeborough","given":"Warren"},{"family":"Van Zyl","given":"Terence"}],"citation-key":"freeboroughInvestigatingExplainabilityMethods2022","container-title":"Applied Sciences","DOI":"10.3390/app12031427","issue":"3","issued":{"date-parts":[["2022"]]},"page":"1427","title":"Investigating Explainability Methods in Recurrent Neural Network Architectures for Financial Time Series Data","type":"article-journal","volume":"12"},
  {"id":"freybergerDissectingCharacteristicsNonparametrically","author":[{"family":"Freyberger","given":"Joachim"},{"family":"Neuhierl","given":"Andreas"},{"family":"Weber","given":"Michael"}],"citation-key":"freybergerDissectingCharacteristicsNonparametrically","container-title":"The Review of Financial Studies","DOI":"10.1093/rfs/hhz123","issue":"33","issued":{"date-parts":[["2020"]]},"page":"2326–2377","title":"Dissecting characteristics nonparametrically","type":"article-journal","volume":"5"},
  {"id":"friedmanAdditiveLogisticRegression2000","author":[{"family":"Friedman","given":"Jerome"},{"family":"Hastie","given":"Trevor"},{"family":"Tibshirani","given":"Robert"}],"citation-key":"friedmanAdditiveLogisticRegression2000","container-title":"The Annals of Statistics","DOI":"10.1214/aos/1016218223","issue":"2","issued":{"date-parts":[["2000"]]},"title":"Additive logistic regression: a statistical view of boosting (with discussion and a rejoinder by the authors)","type":"article-journal","volume":"28"},
  {"id":"friedmanGreedyFunctionApproximation2001","author":[{"family":"Friedman","given":"Jerome"}],"citation-key":"friedmanGreedyFunctionApproximation2001","container-title":"The Annals of Statistics","DOI":"10.1214/aos/1013203451","issue":"5","issued":{"date-parts":[["2001"]]},"page":"1189–1232","title":"Greedy function approximation: a gradient boosting machine.","type":"article-journal","volume":"29"},
  {"id":"friedmanStochasticGradientBoosting2002","author":[{"family":"Friedman","given":"Jerome"}],"citation-key":"friedmanStochasticGradientBoosting2002","container-title":"Computational Statistics & Data Analysis","DOI":"10.1016/S0167-9473(01)00065-2","issue":"4","issued":{"date-parts":[["2002"]]},"page":"367–378","title":"Stochastic gradient boosting","type":"article-journal","volume":"38"},
  {"id":"frommelAccuracyTradeClassification2021","accessed":{"date-parts":[["2023",2,1]]},"author":[{"family":"Frömmel","given":"Michael"},{"family":"D'Hoore","given":"Dick"},{"family":"Lampaert","given":"Kevin"}],"citation-key":"frommelAccuracyTradeClassification2021","container-title":"Finance Research Letters","DOI":"10.1016/j.frl.2020.101892","issued":{"date-parts":[["2021"]]},"page":"101892","title":"The accuracy of trade classification systems on the foreign exchange market: evidence from the RUB/USD market","type":"article-journal","volume":"42"},
  {"id":"gabrielDynamicPricingUsing2021","accessed":{"date-parts":[["2022",1,14]]},"author":[{"family":"Gabriel","given":"Reslley"}],"citation-key":"gabrielDynamicPricingUsing2021","issued":{"date-parts":[["2021"]]},"title":"Dynamic pricing using reinforcement learning and neural networks","type":"document","URL":"https://towardsdatascience.com/dynamic-pricing-using-reinforcement-learning-and-neural-networks-cc3abe374bf5"},
  {"id":"garleanuDemandBasedOptionPricing2009","author":[{"family":"Gârleanu","given":"Nicolae"},{"family":"Pedersen","given":"Lasse Heje"},{"family":"Poteshman","given":"Allen M."}],"citation-key":"garleanuDemandBasedOptionPricing2009","container-title":"Review of Financial Studies","DOI":"10.1093/rfs/hhp005","issue":"10","issued":{"date-parts":[["2009"]]},"page":"4259–4299","title":"Demand-based option pricing","type":"article-journal","volume":"22"},
  {"id":"gengUnmetPromiseSynthetic2024","abstract":"Generative text-to-image models enable us to synthesize unlimited amounts of images in a controllable manner, spurring many recent efforts to train vision models with synthetic data. However, every synthetic image ultimately originates from the upstream data used to train the generator. What additional value does the intermediate generator provide over directly training on relevant parts of the upstream data? Grounding this question in the setting of image classification, we compare finetuning on task-relevant, targeted synthetic data generated by Stable Diffusion—a generative model trained on the LAION-2B dataset—against finetuning on targeted real images retrieved directly from LAION-2B. We show that while synthetic data can benefit some downstream tasks, it is universally matched or outperformed by real data from the simple retrieval baseline. Our analysis suggests that this underperformance is partially due to generator artifacts and inaccurate task-relevant visual details in the synthetic images. Overall, we argue that retrieval is a critical baseline to consider when training with synthetic data—a baseline that current methods do not yet surpass. We release code, data, and models at https://github.com/scottgeng00/unmet-promise.","accessed":{"date-parts":[["2024",12,11]]},"author":[{"family":"Geng","given":"Scott"},{"family":"Hsieh","given":"Cheng-Yu"},{"family":"Ramanujan","given":"Vivek"},{"family":"Wallingford","given":"Matthew"},{"family":"Li","given":"Chun-Liang"},{"family":"Koh","given":"Pang Wei"},{"family":"Krishna","given":"Ranjay"}],"citation-key":"gengUnmetPromiseSynthetic2024","DOI":"10.48550/arXiv.2406.05184","issued":{"date-parts":[["2024",7,3]]},"language":"en","number":"arXiv:2406.05184","publisher":"arXiv","source":"arXiv.org","title":"The Unmet Promise of Synthetic Training Images: Using Retrieved Real Images Performs Better","title-short":"The Unmet Promise of Synthetic Training Images","type":"article","URL":"http://arxiv.org/abs/2406.05184"},
  {"id":"gengUnmetPromiseSynthetic2025","abstract":"Generative text-to-image models enable us to synthesize unlimited amounts of images in a controllable manner, spurring many recent efforts to train vision models with synthetic data. However, every synthetic image ultimately originates from the upstream data used to train the generator. Does the intermediate generator provide additional information over directly training on relevant parts of the upstream data? Grounding this question in the setting of image classification, we compare finetuning on task-relevant, targeted synthetic data generated by Stable Diffusion—a generative model trained on the LAION-2B dataset—against finetuning on targeted real images retrieved directly from LAION-2B. We show that while synthetic data can benefit some downstream tasks, it is universally matched or outperformed by real data from the simple retrieval baseline. Our analysis suggests that this underperformance is partially due to generator artifacts and inaccurate task-relevant visual details in the synthetic images. Overall, we argue that targeted retrieval is a critical baseline to consider when training with synthetic data—a baseline that current methods do not yet surpass. We release code, data, and models at https://github.com/scottgeng00/unmet-promise.","accessed":{"date-parts":[["2025",11,12]]},"author":[{"family":"Geng","given":"Scott"},{"family":"Hsieh","given":"Cheng-Yu"},{"family":"Ramanujan","given":"Vivek"},{"family":"Wallingford","given":"Matthew"},{"family":"Li","given":"Chun-Liang"},{"family":"Koh","given":"Pang Wei"},{"family":"Krishna","given":"Ranjay"}],"citation-key":"gengUnmetPromiseSynthetic2025","DOI":"10.48550/arXiv.2406.05184","issued":{"date-parts":[["2025",1,3]]},"language":"en","number":"arXiv:2406.05184","publisher":"arXiv","source":"arXiv.org","title":"The Unmet Promise of Synthetic Training Images: Using Retrieved Real Images Performs Better","title-short":"The Unmet Promise of Synthetic Training Images","type":"article","URL":"http://arxiv.org/abs/2406.05184"},
  {"id":"gevaTransformerFeedforwardLayers2021","accessed":{"date-parts":[["2023",1,16]]},"author":[{"family":"Geva","given":"Mor"},{"family":"Schuster","given":"Roei"},{"family":"Berant","given":"Jonathan"},{"family":"Levy","given":"Omer"}],"citation-key":"gevaTransformerFeedforwardLayers2021","issued":{"date-parts":[["2021"]]},"title":"Transformer feed-forward layers are key-value memories","type":"document","URL":"http://arxiv.org/abs/2012.14913"},
  {"id":"GivingSoftwareIts2019","accessed":{"date-parts":[["2022",12,8]]},"citation-key":"GivingSoftwareIts2019","container-title":"Nature Methods","DOI":"10.1038/s41592-019-0350-x","issue":"3","issued":{"date-parts":[["2019"]]},"page":"207–207","title":"Giving software its due","type":"article-journal","volume":"16"},
  {"id":"glorotDeepSparseRectifier2011","author":[{"family":"Glorot","given":"Xavier"},{"family":"Bordes","given":"Antoine"},{"family":"Bengio","given":"Yoshua"}],"citation-key":"glorotDeepSparseRectifier2011","collection-title":"Proceedings of Machine Learning Research","container-title":"Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics","event-place":"Fort Lauderdale, FL, USA","issued":{"date-parts":[["2011"]]},"page":"315–323","publisher":"PMLR","publisher-place":"Fort Lauderdale, FL, USA","title":"Deep sparse rectifier neural networks","type":"paper-conference","volume":"15"},
  {"id":"Glosten_1988","author":[{"family":"Glosten","given":"Lawrence R."},{"family":"Harris","given":"Lawrence"}],"citation-key":"Glosten_1988","container-title":"Journal of Financial Economics","DOI":"10.1016/0304-405x(88)90034-7","issued":{"date-parts":[["1988"]]},"PMID":"null","title":"Estimating the components of the bid/ask spread","type":"article-journal"},
  {"id":"goettlerEquilibriumDynamicLimit2005","author":[{"family":"Goettler","given":"Ronald L."},{"family":"Parlour","given":"Christine A."},{"family":"Rajan","given":"Uday"}],"citation-key":"goettlerEquilibriumDynamicLimit2005","container-title":"The Journal of Finance","DOI":"10.1111/j.1540-6261.2005.00795.x","issue":"5","issued":{"date-parts":[["2005"]]},"page":"2149–2192","title":"Equilibrium in a dynamic limit order market","type":"article-journal","volume":"60"},
  {"id":"goncalves-pintoWhyOptionPrices2020","accessed":{"date-parts":[["2023",6,23]]},"author":[{"family":"Goncalves-Pinto","given":"Luis"},{"family":"Grundy","given":"Bruce D."},{"family":"Hameed","given":"Allaudeen"},{"family":"Van Der Heijden","given":"Thijs"},{"family":"Zhu","given":"Yichao"}],"citation-key":"goncalves-pintoWhyOptionPrices2020","container-title":"Management Science","DOI":"10.1287/mnsc.2019.3398","issue":"9","issued":{"date-parts":[["2020"]]},"page":"3903–3926","title":"Why Do Option Prices Predict Stock Returns? The Role of Price Pressure in the Stock Market","type":"article-journal","volume":"66"},
  {"id":"goodfellowDeepLearning2016","author":[{"family":"Goodfellow","given":"Ian"},{"family":"Bengio","given":"Yoshua"},{"family":"Courville","given":"Aaron"}],"citation-key":"goodfellowDeepLearning2016","issued":{"date-parts":[["2016"]]},"publisher":"MIT Press","title":"Deep learning","type":"book"},
  {"id":"goossensLaTeXGraphicsCompanion2008","citation-key":"goossensLaTeXGraphicsCompanion2008","collection-title":"Addison-Wesley series on tools and techniques for computer typesetting","edition":"2nd ed","editor":[{"family":"Goossens","given":"Michel"}],"event-place":"Upper Saddle River, NJ","issued":{"date-parts":[["2008"]]},"publisher":"Addison-Wesley","publisher-place":"Upper Saddle River, NJ","title":"The latex graphics companion","type":"book"},
  {"id":"gorishniyEmbeddingsNumericalFeatures2022","author":[{"family":"Gorishniy","given":"Yury"},{"family":"Rubachev","given":"Ivan"},{"family":"Babenko","given":"Artem"}],"citation-key":"gorishniyEmbeddingsNumericalFeatures2022","container-title":"Advances in Neural Information Processing Systems","editor":[{"family":"Koyejo","given":"S."},{"family":"Mohamed","given":"S."},{"family":"Agarwal","given":"A."},{"family":"Belgrave","given":"D."},{"family":"Cho","given":"K."},{"family":"Oh","given":"A."}],"issued":{"date-parts":[["2022"]]},"page":"24991–25004","publisher":"Curran Associates, Inc.","title":"On embeddings for numerical features in tabular deep learning","type":"paper-conference","volume":"35"},
  {"id":"gorishniyRevisitingDeepLearning2021","author":[{"family":"Gorishniy","given":"Yury"},{"family":"Rubachev","given":"Ivan"},{"family":"Khrulkov","given":"Valentin"},{"family":"Babenko","given":"Artem"}],"citation-key":"gorishniyRevisitingDeepLearning2021","container-title":"Advances in Neural Information Processing Systems","event-place":"Red Hook, NY","issued":{"date-parts":[["2021"]]},"page":"18932–18943","publisher":"Curran Associates, Inc.","publisher-place":"Red Hook, NY","title":"Revisiting deep learning models for tabular data","type":"paper-conference","volume":"34"},
  {"id":"GradientBoostPart","accessed":{"date-parts":[["2021",12,25]]},"citation-key":"GradientBoostPart","title":"Gradient boost part 1 (of 4): regression main ideas - YouTube","type":"document","URL":"https://www.youtube.com/watch?v=3CC4N4z3GJc"},
  {"id":"grammigDivergingRoadsTheoryBased2020","accessed":{"date-parts":[["2021",11,3]]},"author":[{"family":"Grammig","given":"Joachim"},{"family":"Hanenberg","given":"Constantin"},{"family":"Schlag","given":"Christian"},{"family":"Sönksen","given":"Jantje"}],"citation-key":"grammigDivergingRoadsTheoryBased2020","container-title":"SSRN Electronic Journal","DOI":"10.2139/ssrn.3536835","issued":{"date-parts":[["2020"]]},"title":"Diverging roads: theory-based vs. machine learning-implied stock risk premia","type":"article-journal"},
  {"id":"grauerOptionTradeClassification2022","author":[{"family":"Grauer","given":"Caroline"},{"family":"Schuster","given":"Philipp"},{"family":"Uhrig-Homburg","given":"Marliese"}],"citation-key":"grauerOptionTradeClassification2022","DOI":"10.2139/ssrn.4098475","issued":{"date-parts":[["2023"]]},"title":"Option trade classification","type":"document"},
  {"id":"griffinZeroShotCoresetSelection2024","abstract":"Deep learning increasingly relies on massive data with substantial costs for storage, annotation, and model training. To reduce these costs, coreset selection aims to find a representative subset of data to train models while ideally performing on par with the full data training. State-ofthe-art coreset methods use carefully-designed criteria to quantify the importance of each data example via ground truth labels and dataset-specific training, then select examples whose scores lie in a certain range to construct a coreset. These methods work well in their respective settings, however, they cannot select data that are unlabeled, which is the majority of real-world data. To that end, this paper motivates and formalizes the problem of unlabeled coreset selection to enable greater scale and reduce annotation costs for deep learning. As a solution, we develop Zero-Shot Coreset Selection (ZCore), a method that efficiently selects coresets without ground truth labels or training on candidate data. Instead, ZCore uses existing foundation models to generate a zero-shot embedding space for unlabeled data, then quantifies the relative importance of each example based on overall coverage and redundancy within the embedding distribution. We evaluate ZCore on four datasets and outperform several state-of-theart label-based methods, leading to a strong baseline for future research in unlabeled coreset selection. On ImageNet, ZCore selections achieve a downstream model accuracy of 53.99% with only 10% training data, which outperforms label-based methods while removing annotation requirements for 1.15 million images. Our code is publicly available at https://github.com/voxel51/zcore.","accessed":{"date-parts":[["2024",12,10]]},"author":[{"family":"Griffin","given":"Brent A."},{"family":"Marks","given":"Jacob"},{"family":"Corso","given":"Jason J."}],"citation-key":"griffinZeroShotCoresetSelection2024","DOI":"10.48550/arXiv.2411.15349","issued":{"date-parts":[["2024",11,22]]},"language":"en","number":"arXiv:2411.15349","publisher":"arXiv","source":"arXiv.org","title":"Zero-Shot Coreset Selection: Efficient Pruning for Unlabeled Data","title-short":"Zero-Shot Coreset Selection","type":"article","URL":"http://arxiv.org/abs/2411.15349"},
  {"id":"grimmKinderUndHausmaerchen2015","abstract":"<p>Layout neu bearbeitet für Zulu Ebooks (Mai 2017 A.B.)</p>","author":[{"family":"Grimm","given":"Jacob und Wilhelm"}],"citation-key":"grimmKinderUndHausmaerchen2015","issued":{"date-parts":[["2015",6,29]]},"language":"de","note":"Item ID: _:n0","publisher":"Edition Zulu-Ebooks.com","title":"Kinder- und Hausmärchen - Edition Zulu-Ebooks.com","type":"book"},
  {"id":"grinsztajnWhyTreebasedModels2022","author":[{"family":"Grinsztajn","given":"Léo"},{"family":"Oyallon","given":"Edouard"},{"family":"Varoquaux","given":"Gaël"}],"citation-key":"grinsztajnWhyTreebasedModels2022","collection-title":"NeurIPS 2022","container-title":"Advances in Neural Information Processing Systems","event-place":"Red Hook, NY","issued":{"date-parts":[["2022"]]},"page":"507–520","publisher":"Curran Associates Inc.","publisher-place":"Red Hook, NY","title":"Why do tree-based models still outperform deep learning on typical tabular data?","type":"paper-conference","volume":"36"},
  {"id":"guanIDNetNovelDataset2024","abstract":"Effective fraud detection and analysis of government-issued identity documents, such as passports, driver's licenses, and identity cards, are essential in thwarting identity theft and bolstering security on online platforms. The training of accurate fraud detection and analysis tools depends on the availability of extensive identity document datasets. However, current publicly available benchmark datasets for identity document analysis, including MIDV-500, MIDV-2020, and FMIDV, fall short in several respects: they offer a limited number of samples, cover insufficient varieties of fraud patterns, and seldom include alterations in critical personal identifying fields like portrait images, limiting their utility in training models capable of detecting realistic frauds while preserving privacy. In response to these shortcomings, our research introduces a new benchmark dataset, IDNet, designed to advance privacy-preserving fraud detection efforts. The IDNet dataset comprises 837,060 images of synthetically generated identity documents, totaling approximately 490 gigabytes, categorized into 20 types from $10$ U.S. states and 10 European countries. We evaluate the utility and present use cases of the dataset, illustrating how it can aid in training privacy-preserving fraud detection methods, facilitating the generation of camera and video capturing of identity documents, and testing schema unification and other identity document management functionalities.","accessed":{"date-parts":[["2024",12,10]]},"author":[{"family":"Guan","given":"Hong"},{"family":"Wang","given":"Yancheng"},{"family":"Xie","given":"Lulu"},{"family":"Nag","given":"Soham"},{"family":"Goel","given":"Rajeev"},{"family":"Swamy","given":"Niranjan Erappa Narayana"},{"family":"Yang","given":"Yingzhen"},{"family":"Xiao","given":"Chaowei"},{"family":"Prisby","given":"Jonathan"},{"family":"Maciejewski","given":"Ross"},{"family":"Zou","given":"Jia"}],"citation-key":"guanIDNetNovelDataset2024","DOI":"10.48550/arXiv.2408.01690","issued":{"date-parts":[["2024",9,3]]},"number":"arXiv:2408.01690","publisher":"arXiv","source":"arXiv.org","title":"IDNet: A Novel Dataset for Identity Document Analysis and Fraud Detection","title-short":"IDNet","type":"article","URL":"http://arxiv.org/abs/2408.01690"},
  {"id":"guAutoencoderAssetPricing2021","author":[{"family":"Gu","given":"Shihao"},{"family":"Kelly","given":"Bryan"},{"family":"Xiu","given":"Dacheng"}],"citation-key":"guAutoencoderAssetPricing2021","container-title":"Journal of Econometrics","DOI":"10.1016/j.jeconom.2020.07.009","issue":"1","issued":{"date-parts":[["2021"]]},"page":"429–450","title":"Autoencoder asset pricing models","type":"article-journal","volume":"222"},
  {"id":"guEmpiricalAssetPricing2020","accessed":{"date-parts":[["2021",10,19]]},"author":[{"family":"Gu","given":"Shihao"},{"family":"Kelly","given":"Bryan"},{"family":"Xiu","given":"Dacheng"}],"citation-key":"guEmpiricalAssetPricing2020","container-title":"The Review of Financial Studies","DOI":"10.1093/rfs/hhaa009","issue":"5","issued":{"date-parts":[["2020"]]},"page":"2223–2273","title":"Empirical asset pricing via machine learning","type":"article-journal","volume":"33"},
  {"id":"gunnarssonDeepLearningCredit2021","accessed":{"date-parts":[["2022",1,12]]},"author":[{"family":"Gunnarsson","given":"Björn Rafn"},{"family":"Broucke","given":"Seppe","non-dropping-particle":"vanden"},{"family":"Baesens","given":"Bart"},{"family":"Óskarsdóttir","given":"María"},{"family":"Lemahieu","given":"Wilfried"}],"citation-key":"gunnarssonDeepLearningCredit2021","container-title":"European Journal of Operational Research","DOI":"10.1016/j.ejor.2021.03.006","issue":"1","issued":{"date-parts":[["2021"]]},"page":"292–305","title":"Deep learning for credit scoring: do or don't?","type":"article-journal","volume":"295"},
  {"id":"guoEmbeddingLearningFramework2021","accessed":{"date-parts":[["2023",1,14]]},"author":[{"family":"Guo","given":"Huifeng"},{"family":"Chen","given":"Bo"},{"family":"Tang","given":"Ruiming"},{"family":"Zhang","given":"Weinan"},{"family":"Li","given":"Zhenguo"},{"family":"He","given":"Xiuqiang"}],"citation-key":"guoEmbeddingLearningFramework2021","container-title":"Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining","DOI":"10.1145/3447548.3467077","issued":{"date-parts":[["2021"]]},"page":"2910–2918","title":"An embedding learning framework for numerical features in CTR prediction","type":"paper-conference"},
  {"id":"guoEntityEmbeddingsCategorical2016","accessed":{"date-parts":[["2023",1,25]]},"author":[{"family":"Guo","given":"Cheng"},{"family":"Berkhahn","given":"Felix"}],"citation-key":"guoEntityEmbeddingsCategorical2016","issued":{"date-parts":[["2016"]]},"title":"Entity embeddings of categorical variables","type":"document","URL":"http://arxiv.org/abs/1604.06737"},
  {"id":"guptaXTNestedTokenization2024","abstract":"Modern computer vision pipelines handle large images in one of two sub-optimal ways: down-sampling or cropping. These two methods incur significant losses in the amount of information and context present in an image. There are many downstream applications in which global context matters as much as high frequency details, such as in real-world satellite imagery; in such cases researchers have to make the uncomfortable choice of which information to discard. We introduce xT, a simple framework for vision transformers which effectively aggregates global context with local details and can model large images end-to-end on contemporary GPUs. We select a set of benchmark datasets across classic vision tasks which accurately reflect a vision model’s ability to understand truly large images and incorporate fine details over large scales and assess our method’s improvement on them. xT is a streaming, two-stage architecture that adapts existing vision backbones and long sequence language models to effectively model large images without quadratic memory growth. We are able to increase accuracy by up to 8.6% on challenging classification tasks and F1 score by 11.6 on context-dependent segmentation on images as large as 29,000 x 29,000 pixels.","accessed":{"date-parts":[["2025",11,15]]},"author":[{"family":"Gupta","given":"Ritwik"},{"family":"Li","given":"Shufan"},{"family":"Zhu","given":"Tyler"},{"family":"Malik","given":"Jitendra"},{"family":"Darrell","given":"Trevor"},{"family":"Mangalam","given":"Karttikeya"}],"citation-key":"guptaXTNestedTokenization2024","DOI":"10.48550/arXiv.2403.01915","issued":{"date-parts":[["2024",7,21]]},"language":"en","number":"arXiv:2403.01915","publisher":"arXiv","source":"arXiv.org","title":"xT: Nested Tokenization for Larger Context in Large Images","title-short":"xT","type":"article","URL":"http://arxiv.org/abs/2403.01915"},
  {"id":"gyamerahStockMarketMovement2019","accessed":{"date-parts":[["2022",7,12]]},"author":[{"family":"Gyamerah","given":"Samuel Asante"},{"family":"Ngare","given":"Philip"},{"family":"Ikpe","given":"Dennis"}],"citation-key":"gyamerahStockMarketMovement2019","container-title":"2019 IEEE Conference on Computational Intelligence for Financial Engineering & Economics (CIFEr)","DOI":"10.1109/CIFEr.2019.8759062","event-place":"Shenzhen, China","issued":{"date-parts":[["2019"]]},"page":"1–8","publisher":"IEEE","publisher-place":"Shenzhen, China","title":"On stock market movement prediction via stacking ensemble learning method","type":"paper-conference"},
  {"id":"hagstromerBiasEffectiveBidask2021","accessed":{"date-parts":[["2023",2,25]]},"author":[{"family":"Hagströmer","given":"Björn"}],"citation-key":"hagstromerBiasEffectiveBidask2021","container-title":"Journal of Financial Economics","DOI":"10.1016/j.jfineco.2021.04.018","issue":"1","issued":{"date-parts":[["2021"]]},"page":"314–337","title":"Bias in the effective bid-ask spread","type":"article-journal","volume":"142"},
  {"id":"hanAutoEncoderInspiredUnsupervised2018","author":[{"family":"Han","given":"Kai"},{"family":"Wang","given":"Yunhe"},{"family":"Zhang","given":"Chao"},{"family":"Li","given":"Chao"},{"family":"Xu","given":"Chao"}],"citation-key":"hanAutoEncoderInspiredUnsupervised2018","container-title":"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)","DOI":"10.1109/ICASSP.2018.8462261","event-place":"Calgary, AB","issued":{"date-parts":[["2018"]]},"publisher-place":"Calgary, AB","title":"AutoEncoder inspired unsupervised feature selection","type":"paper-conference"},
  {"id":"hancockSurveyCategoricalData2020","author":[{"family":"Hancock","given":"John T."},{"family":"Khoshgoftaar","given":"Taghi M."}],"citation-key":"hancockSurveyCategoricalData2020","container-title":"Journal of Big Data","DOI":"10.1186/s40537-020-00305-w","issue":"1","issued":{"date-parts":[["2020"]]},"page":"28","title":"Survey on categorical data for neural networks","type":"article-journal","volume":"7"},
  {"id":"hansBeGoldfishDont2024","abstract":"Large language models can memorize and repeat their training data, causing privacy and copyright risks. To mitigate memorization, we introduce a subtle modification to the next-token training objective that we call the goldfish loss. During training, a randomly sampled subsets of tokens are excluded from the loss computation. These dropped tokens are not memorized by the model, which prevents verbatim reproduction of a complete chain of tokens from the training set. We run extensive experiments training billion-scale LLaMA-2 models, both pre-trained and trained from scratch, and demonstrate significant reductions in extractable memorization with little to no impact on downstream benchmarks.","accessed":{"date-parts":[["2025",12,1]]},"author":[{"family":"Hans","given":"Abhimanyu"},{"family":"Wen","given":"Yuxin"},{"family":"Jain","given":"Neel"},{"family":"Kirchenbauer","given":"John"},{"family":"Kazemi","given":"Hamid"},{"family":"Singhania","given":"Prajwal"},{"family":"Singh","given":"Siddharth"},{"family":"Somepalli","given":"Gowthami"},{"family":"Geiping","given":"Jonas"},{"family":"Bhatele","given":"Abhinav"},{"family":"Goldstein","given":"Tom"}],"citation-key":"hansBeGoldfishDont2024","DOI":"10.48550/arXiv.2406.10209","issued":{"date-parts":[["2024",11,2]]},"language":"en","number":"arXiv:2406.10209","publisher":"arXiv","source":"arXiv.org","title":"Be like a Goldfish, Don't Memorize! Mitigating Memorization in Generative LLMs","type":"article","URL":"http://arxiv.org/abs/2406.10209"},
  {"id":"harrisDayEndTransactionPrice1989","author":[{"family":"Harris","given":"Lawrence"}],"citation-key":"harrisDayEndTransactionPrice1989","container-title":"The Journal of Financial and Quantitative Analysis","DOI":"10.2307/2330746","issue":"1","issued":{"date-parts":[["1989"]]},"page":"29","title":"A day-end transaction price anomaly","type":"article-journal","volume":"24"},
  {"id":"harveyMultivariateStochasticVariance1994","accessed":{"date-parts":[["2020",12,12]]},"author":[{"family":"Harvey","given":"A."},{"family":"Ruiz","given":"E."},{"family":"Shephard","given":"N."}],"citation-key":"harveyMultivariateStochasticVariance1994","container-title":"The Review of Economic Studies","DOI":"10.2307/2297980","issue":"2","issued":{"date-parts":[["1994"]]},"page":"247–264","title":"Multivariate stochastic variance models","type":"article-journal","volume":"61"},
  {"id":"harveyTestingEqualityPrediction1997","author":[{"family":"Harvey","given":"David"},{"family":"Leybourne","given":"Stephen"},{"family":"Newbold","given":"Paul"}],"citation-key":"harveyTestingEqualityPrediction1997","container-title":"International Journal of Forecasting","DOI":"10.1016/S0169-2070(96)00719-4","issue":"2","issued":{"date-parts":[["1997"]]},"page":"281–291","title":"Testing the equality of prediction mean squared errors","type":"article-journal","volume":"13"},
  {"id":"hasbrouckTradesQuotesInventories1988","author":[{"family":"Hasbrouck","given":"Joel"}],"citation-key":"hasbrouckTradesQuotesInventories1988","container-title":"Journal of Financial Economics","DOI":"10.1016/0304-405X(88)90070-0","issue":"2","issued":{"date-parts":[["1988"]]},"page":"229–252","title":"Trades, quotes, inventories, and information","type":"article-journal","volume":"22"},
  {"id":"hasbrouckTradingCostsReturns2009","accessed":{"date-parts":[["2023",2,26]]},"author":[{"family":"Hasbrouck","given":"Joel"}],"citation-key":"hasbrouckTradingCostsReturns2009","container-title":"The Journal of Finance","DOI":"10.1111/j.1540-6261.2009.01469.x","issue":"3","issued":{"date-parts":[["2009"]]},"page":"1445–1477","title":"Trading costs and returns for U.s. Equities: estimating effective costs from daily data","type":"article-journal","volume":"64"},
  {"id":"hastietrevorElementsStatisticalLearning2009","author":[{"family":"Hastie","given":"Sami","suffix":"Trevor"},{"family":"Friedman","given":"Harry"},{"family":"Tibshirani","given":"Robert"}],"citation-key":"hastietrevorElementsStatisticalLearning2009","collection-title":"Springer Series in Statistics","event-place":"New York, NY","issued":{"date-parts":[["2009"]]},"publisher":"Springer","publisher-place":"New York, NY","title":"The elements of statistical learning","type":"book"},
  {"id":"hazimehTreeEnsembleLayer2020","accessed":{"date-parts":[["2023",5,15]]},"author":[{"family":"Hazimeh","given":"Hussein"},{"family":"Ponomareva","given":"Natalia"},{"family":"Mol","given":"Petros"},{"family":"Tan","given":"Zhenyu"},{"family":"Mazumder","given":"Rahul"}],"citation-key":"hazimehTreeEnsembleLayer2020","container-title":"Proceedings of the 37th International Conference on Machine Learning","issued":{"date-parts":[["2020"]]},"page":"4138–4148","publisher":"PMLR","title":"The Tree Ensemble Layer: Differentiability meets Conditional Computation","type":"paper-conference","URL":"https://proceedings.mlr.press/v119/hazimeh20a.html"},
  {"id":"heatonEmpiricalAnalysisFeature2016","author":[{"family":"Heaton","given":"Jeff"}],"citation-key":"heatonEmpiricalAnalysisFeature2016","container-title":"SoutheastCon 2016","DOI":"10.1109/SECON.2016.7506650","issued":{"date-parts":[["2016"]]},"page":"1–6","title":"An empirical analysis of feature engineering for predictive modeling","type":"paper-conference"},
  {"id":"heBagTricksImage2018","accessed":{"date-parts":[["2022",10,26]]},"author":[{"family":"He","given":"Tong"},{"family":"Zhang","given":"Zhi"},{"family":"Zhang","given":"Hang"},{"family":"Zhang","given":"Zhongyue"},{"family":"Xie","given":"Junyuan"},{"family":"Li","given":"Mu"}],"citation-key":"heBagTricksImage2018","issued":{"date-parts":[["2018"]]},"title":"Bag of tricks for image classification with convolutional neural networks","type":"document","URL":"http://arxiv.org/abs/1812.01187"},
  {"id":"heDeepResidualLearning2015","author":[{"family":"He","given":"Kaiming"},{"family":"Zhang","given":"Xiangyu"},{"family":"Ren","given":"Shaoqing"},{"family":"Sun","given":"Jian"}],"citation-key":"heDeepResidualLearning2015","issued":{"date-parts":[["2015"]]},"title":"Deep residual learning for image recognition","type":"document"},
  {"id":"heegaardPhDResearchPlan","author":[{"family":"Heegaard","given":"Poul"}],"citation-key":"heegaardPhDResearchPlan","title":"PhD research plan","type":"article-journal"},
  {"id":"hegselmannTabLLMFewshotClassification2022","accessed":{"date-parts":[["2023",1,14]]},"author":[{"family":"Hegselmann","given":"Stefan"},{"family":"Buendia","given":"Alejandro"},{"family":"Lang","given":"Hunter"},{"family":"Agrawal","given":"Monica"},{"family":"Jiang","given":"Xiaoyi"},{"family":"Sontag","given":"David"}],"citation-key":"hegselmannTabLLMFewshotClassification2022","issued":{"date-parts":[["2022"]]},"title":"TabLLM: few-shot classification of tabular data with large language models","type":"document","URL":"http://arxiv.org/abs/2210.10723"},
  {"id":"hendrycksGaussianErrorLinear2020","author":[{"family":"Hendrycks","given":"Dan"},{"family":"Gimpel","given":"Kevin"}],"citation-key":"hendrycksGaussianErrorLinear2020","issued":{"date-parts":[["2020"]]},"title":"Gaussian Error Linear Units (GELUs)","type":"document"},
  {"id":"hennessyComputerArchitecture","author":[{"family":"Hennessy","given":"John L"}],"citation-key":"hennessyComputerArchitecture","language":"en","source":"Zotero","title":"Computer Architecture","type":"article-journal"},
  {"id":"hertzPrompttopromptImageEditing2022","accessed":{"date-parts":[["2022",9,12]]},"author":[{"family":"Hertz","given":"Amir"},{"family":"Mokady","given":"Ron"},{"family":"Tenenbaum","given":"Jay"},{"family":"Aberman","given":"Kfir"},{"family":"Pritch","given":"Yael"},{"family":"Cohen-Or","given":"Daniel"}],"citation-key":"hertzPrompttopromptImageEditing2022","issued":{"date-parts":[["2022"]]},"title":"Prompt-to-prompt image editing with cross attention control","type":"document","URL":"http://arxiv.org/abs/2208.01626"},
  {"id":"hidasiRecurrentNeuralNetworks2018","accessed":{"date-parts":[["2021",5,4]]},"author":[{"family":"Hidasi","given":"Balázs"},{"family":"Karatzoglou","given":"Alexandros"}],"citation-key":"hidasiRecurrentNeuralNetworks2018","container-title":"Proceedings of the 27th ACM International Conference on Information and Knowledge Management","DOI":"10.1145/3269206.3271761","issued":{"date-parts":[["2018"]]},"page":"843–852","title":"Recurrent neural networks with top-k gains for session-based recommendations","type":"article-journal"},
  {"id":"hintonForwardForwardAlgorithmPreliminary","author":[{"family":"Hinton","given":"Geoffrey"}],"citation-key":"hintonForwardForwardAlgorithmPreliminary","title":"The forward-forward algorithm: some preliminary investigations","type":"article-journal"},
  {"id":"hintonImprovingNeuralNetworks2012","author":[{"family":"Hinton","given":"Geoffrey E."},{"family":"Srivastava","given":"Nitish"},{"family":"Krizhevsky","given":"Alex"},{"family":"Sutskever","given":"Ilya"},{"family":"Salakhutdinov","given":"Ruslan R."}],"citation-key":"hintonImprovingNeuralNetworks2012","issued":{"date-parts":[["2012"]]},"title":"Improving neural networks by preventing co-adaptation of feature detectors","type":"article-journal"},
  {"id":"hirtEndtoendProcessModel","author":[{"family":"Hirt","given":"Robin"},{"family":"Kuhl","given":"Niklas"},{"family":"Satzger","given":"Gerhard"}],"citation-key":"hirtEndtoendProcessModel","page":"9","title":"An end-to-end process model for supervised machine learning classification: from problem to deployment in information systems","type":"article-journal"},
  {"id":"hoangMachineLearningMethods","author":[{"family":"Hoang","given":"Daniel"},{"family":"Wiegratz","given":"Kevin"}],"citation-key":"hoangMachineLearningMethods","page":"64","title":"Machine learning methods in finance: recent applications and prospects","type":"article-journal"},
  {"id":"hoAxialAttentionMultidimensional2019","accessed":{"date-parts":[["2022",1,4]]},"author":[{"family":"Ho","given":"Jonathan"},{"family":"Kalchbrenner","given":"Nal"},{"family":"Weissenborn","given":"Dirk"},{"family":"Salimans","given":"Tim"}],"citation-key":"hoAxialAttentionMultidimensional2019","issued":{"date-parts":[["2019"]]},"title":"Axial attention in multidimensional transformers","type":"document","URL":"http://arxiv.org/abs/1912.12180"},
  {"id":"hochreiterLongShorttermMemory1997","accessed":{"date-parts":[["2021",12,25]]},"author":[{"family":"Hochreiter","given":"Sepp"},{"family":"Schmidhuber","given":"Jürgen"}],"citation-key":"hochreiterLongShorttermMemory1997","container-title":"Neural Computation","DOI":"10.1162/neco.1997.9.8.1735","issue":"8","issued":{"date-parts":[["1997"]]},"page":"1735–1780","title":"Long short-term memory","type":"article-journal","volume":"9"},
  {"id":"hoffmannTrainingComputeOptimalLarge2022","author":[{"family":"Hoffmann","given":"Jordan"},{"family":"Borgeaud","given":"Sebastian"},{"family":"Mensch","given":"Arthur"},{"family":"Buchatskaya","given":"Elena"},{"family":"Cai","given":"Trevor"},{"family":"Rutherford","given":"Eliza"},{"family":"Las Casas","given":"Diego","non-dropping-particle":"de"},{"family":"Hendricks","given":"Lisa Anne"},{"family":"Welbl","given":"Johannes"},{"family":"Clark","given":"Aidan"},{"family":"Hennigan","given":"Thomas"},{"family":"Noland","given":"Eric"},{"family":"Millican","given":"Katherine"},{"family":"Driessche","given":"George","non-dropping-particle":"van den"},{"family":"Damoc","given":"Bogdan"},{"family":"Guy","given":"Aurelia"},{"family":"Osindero","given":"Simon"},{"family":"Simonyan","given":"Karén"},{"family":"Elsen","given":"Erich"},{"family":"Vinyals","given":"Oriol"},{"family":"Rae","given":"Jack"},{"family":"Sifre","given":"Laurent"}],"citation-key":"hoffmannTrainingComputeOptimalLarge2022","container-title":"Advances in neural information processing systems","editor":[{"family":"Koyejo","given":"S."},{"family":"Mohamed","given":"S."},{"family":"Agarwal","given":"A."},{"family":"Belgrave","given":"D."},{"family":"Cho","given":"K."},{"family":"Oh","given":"A."}],"issued":{"date-parts":[["2022"]]},"page":"30016–30030","publisher":"Curran Associates, Inc.","title":"An empirical analysis of compute-optimal large language model training","type":"paper-conference","volume":"35"},
  {"id":"holdenLiquidityMeasurementProblems2014","accessed":{"date-parts":[["2023",2,6]]},"author":[{"family":"Holden","given":"Craig W."},{"family":"Jacobsen","given":"Stacey"}],"citation-key":"holdenLiquidityMeasurementProblems2014","container-title":"The Journal of Finance","DOI":"10.1111/jofi.12127","issue":"4","issued":{"date-parts":[["2014"]]},"page":"1747–1785","title":"Liquidity measurement problems in fast, competitive markets: expensive and cheap solutions: liquidity measurement problems in fast, competitive markets","type":"article-journal","volume":"69"},
  {"id":"holthausenEffectLargeBlock1987","author":[{"family":"Holthausen","given":"Robert W."},{"family":"Leftwich","given":"Richard W."},{"family":"Mayers","given":"David"}],"citation-key":"holthausenEffectLargeBlock1987","container-title":"Journal of Financial Economics","DOI":"10.1016/0304-405X(87)90004-3","issue":"2","issued":{"date-parts":[["1987"]]},"page":"237–267","title":"The effect of large block transactions on security prices: a cross-sectional analysis","type":"article-journal","volume":"19"},
  {"id":"holzingerXxAIExplainableAI2022","accessed":{"date-parts":[["2023",5,22]]},"citation-key":"holzingerXxAIExplainableAI2022","collection-title":"Lecture Notes in Computer Science","DOI":"10.1007/978-3-031-04083-2","editor":[{"family":"Holzinger","given":"Andreas"},{"family":"Goebel","given":"Randy"},{"family":"Fong","given":"Ruth"},{"family":"Moon","given":"Taesup"},{"family":"Müller","given":"Klaus-Robert"},{"family":"Samek","given":"Wojciech"}],"event-place":"Cham","issued":{"date-parts":[["2022"]]},"publisher":"Springer International Publishing","publisher-place":"Cham","title":"xxAI - Beyond Explainable AI: International Workshop, Held in Conjunction with ICML 2020, July 18, 2020, Vienna, Austria, Revised and Extended Papers","type":"book","volume":"13200"},
  {"id":"hookerUnrestrictedPermutationForces2021","accessed":{"date-parts":[["2023",4,11]]},"author":[{"family":"Hooker","given":"Giles"},{"family":"Mentch","given":"Lucas"},{"family":"Zhou","given":"Siyu"}],"citation-key":"hookerUnrestrictedPermutationForces2021","container-title":"Statistics and Computing","DOI":"10.1007/s11222-021-10057-z","issue":"6","issued":{"date-parts":[["2021"]]},"page":"82","title":"Unrestricted permutation forces extrapolation: variable importance requires at least one more model, or there is no free variable importance","type":"article-journal","volume":"31"},
  {"id":"hornikMultilayerFeedforwardNetworks1989","accessed":{"date-parts":[["2021",12,8]]},"author":[{"family":"Hornik","given":"Kurt"},{"family":"Stinchcombe","given":"Maxwell"},{"family":"White","given":"Halbert"}],"citation-key":"hornikMultilayerFeedforwardNetworks1989","container-title":"Neural Networks","DOI":"10.1016/0893-6080(89)90020-8","issue":"5","issued":{"date-parts":[["1989"]]},"page":"359–366","title":"Multilayer feedforward networks are universal approximators","type":"article-journal","volume":"2"},
  {"id":"houselPsychologyMoney2020","author":[{"family":"Housel","given":"Morgan"}],"citation-key":"houselPsychologyMoney2020","issued":{"date-parts":[["2020",6,9]]},"language":"en-GB","note":"Item ID: _:n0","title":"The Psychology of Money","type":"book"},
  {"id":"huangSnapshotEnsemblesTrain2017","author":[{"family":"Huang","given":"Gao"},{"family":"Li","given":"Yixuan"},{"family":"Pleiss","given":"Geoff"},{"family":"Liu","given":"Zhuang"},{"family":"Hopcroft","given":"John E."},{"family":"Weinberger","given":"Kilian Q."}],"citation-key":"huangSnapshotEnsemblesTrain2017","issued":{"date-parts":[["2017"]]},"title":"Snapshot ensembles: train 1, get M for free","type":"document"},
  {"id":"huangTabTransformerTabularData2020","author":[{"family":"Huang","given":"Xin"},{"family":"Khetan","given":"Ashish"},{"family":"Cvitkovic","given":"Milan"},{"family":"Karnin","given":"Zohar"}],"citation-key":"huangTabTransformerTabularData2020","issued":{"date-parts":[["2020"]]},"title":"TabTransformer: tabular data modeling using contextual embeddings","type":"document"},
  {"id":"huDoesOptionTrading2014","author":[{"family":"Hu","given":"Jianfeng"}],"citation-key":"huDoesOptionTrading2014","container-title":"Journal of Financial Economics","DOI":"10.1016/j.jfineco.2013.12.004","issue":"3","issued":{"date-parts":[["2014"]]},"page":"625–645","title":"Does option trading convey stock price information?","type":"article-journal","volume":"111"},
  {"id":"hullOptionsFuturesOther2012","author":[{"family":"Hull","given":"John"}],"citation-key":"hullOptionsFuturesOther2012","edition":"8th ed","event-place":"Boston","issued":{"date-parts":[["2012"]]},"publisher":"Prentice Hall","publisher-place":"Boston","title":"Options, futures, and other derivatives","type":"book"},
  {"id":"huyenDesigningMachineLearning","author":[{"family":"Huyen","given":"Chip"}],"citation-key":"huyenDesigningMachineLearning","title":"Designing machine learning systems","type":"book"},
  {"id":"hyndmanForecastingPrinciplesPractice2021","author":[{"family":"Hyndman","given":"Rob J"},{"family":"Athanasopoulos","given":"George"}],"citation-key":"hyndmanForecastingPrinciplesPractice2021","edition":"3","issued":{"date-parts":[["2021"]]},"title":"Forecasting: principles and practice","type":"book"},
  {"id":"inceINDIVIDUALEQUITYRETURN2006","accessed":{"date-parts":[["2021",10,29]]},"author":[{"family":"Ince","given":"Ozgur S."},{"family":"Porter","given":"R. Burt"}],"citation-key":"inceINDIVIDUALEQUITYRETURN2006","container-title":"Journal of Financial Research","DOI":"10.1111/j.1475-6803.2006.00189.x","issue":"4","issued":{"date-parts":[["2006"]]},"page":"463–479","title":"Individual equity return data from thomson datastream: handle with care!","type":"article-journal","volume":"29"},
  {"id":"IndexOptionTrading","accessed":{"date-parts":[["2023",6,20]]},"citation-key":"IndexOptionTrading","DOI":"10.1287/mnsc.2019.3529","title":"Index Option Trading Activity and Market Returns","type":"document"},
  {"id":"ioffeBatchNormalizationAccelerating2015","author":[{"family":"Ioffe","given":"Sergey"},{"family":"Szegedy","given":"Christian"}],"citation-key":"ioffeBatchNormalizationAccelerating2015","issued":{"date-parts":[["2015"]]},"title":"Batch normalization: accelerating deep network training by reducing internal covariate shift","type":"document"},
  {"id":"ismailfawazDeepLearningTime2019","accessed":{"date-parts":[["2021",11,16]]},"author":[{"family":"Ismail Fawaz","given":"Hassan"},{"family":"Forestier","given":"Germain"},{"family":"Weber","given":"Jonathan"},{"family":"Idoumghar","given":"Lhassane"},{"family":"Muller","given":"Pierre-Alain"}],"citation-key":"ismailfawazDeepLearningTime2019","container-title":"Data Mining and Knowledge Discovery","DOI":"10.1007/s10618-019-00619-1","issue":"4","issued":{"date-parts":[["2019"]]},"page":"917–963","title":"Deep learning for time series classification: a review","type":"article-journal","volume":"33"},
  {"id":"ivanovDataMovementAll2021","accessed":{"date-parts":[["2023",1,15]]},"author":[{"family":"Ivanov","given":"Andrei"},{"family":"Dryden","given":"Nikoli"},{"family":"Ben-Nun","given":"Tal"},{"family":"Li","given":"Shigang"},{"family":"Hoefler","given":"Torsten"}],"citation-key":"ivanovDataMovementAll2021","issued":{"date-parts":[["2021"]]},"title":"Data movement is all you need: a case study on optimizing transformers","type":"document","URL":"http://arxiv.org/abs/2007.00072"},
  {"id":"izmailovAveragingWeightsLeads2019","accessed":{"date-parts":[["2022",10,13]]},"author":[{"family":"Izmailov","given":"Pavel"},{"family":"Podoprikhin","given":"Dmitrii"},{"family":"Garipov","given":"Timur"},{"family":"Vetrov","given":"Dmitry"},{"family":"Wilson","given":"Andrew Gordon"}],"citation-key":"izmailovAveragingWeightsLeads2019","issued":{"date-parts":[["2019"]]},"title":"Averaging weights leads to wider optima and better generalization","type":"document","URL":"http://arxiv.org/abs/1803.05407"},
  {"id":"jacobGroupLassoOverlap2009","accessed":{"date-parts":[["2021",10,1]]},"author":[{"family":"Jacob","given":"Laurent"},{"family":"Obozinski","given":"Guillaume"},{"family":"Vert","given":"Jean-Philippe"}],"citation-key":"jacobGroupLassoOverlap2009","container-title":"Proceedings of the 26th Annual International Conference on Machine Learning - ICML '09","DOI":"10.1145/1553374.1553431","event-place":"Montreal, Quebec, Canada","issued":{"date-parts":[["2009"]]},"page":"1–8","publisher":"ACM Press","publisher-place":"Montreal, Quebec, Canada","title":"Group lasso with overlap and graph lasso","type":"paper-conference"},
  {"id":"jainAttentionNotExplanation2019","author":[{"family":"Jain","given":"Sarthak"},{"family":"Wallace","given":"Byron C."}],"citation-key":"jainAttentionNotExplanation2019","issued":{"date-parts":[["2019"]]},"title":"Attention is not explanation","type":"document"},
  {"id":"japkowiczClassImbalanceProblem2002","author":[{"family":"Japkowicz","given":"Nathalie"},{"family":"Stephen","given":"Shaju"}],"citation-key":"japkowiczClassImbalanceProblem2002","container-title":"Intelligent Data Analysis","DOI":"10.3233/IDA-2002-6504","issue":"5","issued":{"date-parts":[["2002"]]},"page":"429–449","title":"The class imbalance problem: a systematic study","type":"article-journal","volume":"6"},
  {"id":"jarmulPracticalDataPrivacy2023","abstract":"Between major privacy regulations like the GDPR and CCPA and expensive and notorious data breaches, there has never been so much pressure to ensure data privacy. Unfortunately, integrating privacy into data systems is still complicated. This essential guide will give you a fundamental understanding of modern privacy building blocks, like differential privacy, federated learning, and encrypted computation. Based on hard-won lessons, this book provides solid advice and best practices for integrating breakthrough privacy-enhancing technologies into production systems","author":[{"family":"Jarmul","given":"Katharine"}],"call-number":"QA76.9.A25 J375 2023","citation-key":"jarmulPracticalDataPrivacy2023","edition":"First edition","event-place":"Sebastopol, CA","ISBN":"978-1-0981-2946-0","issued":{"date-parts":[["2023"]]},"note":"OCLC: on1356034197","number-of-pages":"315","publisher":"O'Reilly Media","publisher-place":"Sebastopol, CA","source":"Library of Congress ISBN","title":"Practical data privacy: enhancing privacy and security in data","title-short":"Practical data privacy","type":"book"},
  {"id":"jawaharWhatDoesBERT2019","author":[{"family":"Jawahar","given":"Ganesh"},{"family":"Sagot","given":"Benoît"},{"family":"Seddah","given":"Djamé"}],"citation-key":"jawaharWhatDoesBERT2019","container-title":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics","DOI":"10.18653/v1/P19-1356","event-place":"Florence, Italy","issued":{"date-parts":[["2019"]]},"page":"3651–3657","publisher":"Association for Computational Linguistics","publisher-place":"Florence, Italy","title":"What does BERT learn about the structure of language?","type":"paper-conference"},
  {"id":"jinDatadrivenApproachPredict2015","author":[{"family":"Jin","given":"Yu"},{"family":"Zhu","given":"Yudan"}],"citation-key":"jinDatadrivenApproachPredict2015","container-title":"2015 Fifth International Conference on Communication Systems and Network Technologies","DOI":"10.1109/CSNT.2015.25","issued":{"date-parts":[["2015"]]},"page":"609–613","title":"A data-driven approach to predict default risk of loan for online peer-to-peer (P2P) lending","type":"paper-conference"},
  {"id":"jinPruningEffectGeneralization2022","accessed":{"date-parts":[["2023",1,15]]},"author":[{"family":"Jin","given":"Tian"},{"family":"Carbin","given":"Michael"},{"family":"Roy","given":"Daniel M."},{"family":"Frankle","given":"Jonathan"},{"family":"Dziugaite","given":"Gintare Karolina"}],"citation-key":"jinPruningEffectGeneralization2022","issued":{"date-parts":[["2022"]]},"title":"Pruning's effect on generalization through the lens of training and regularization","type":"document","URL":"http://arxiv.org/abs/2210.13738"},
  {"id":"johnsonSurveyDeepLearning2019","accessed":{"date-parts":[["2022",11,9]]},"author":[{"family":"Johnson","given":"Justin M."},{"family":"Khoshgoftaar","given":"Taghi M."}],"citation-key":"johnsonSurveyDeepLearning2019","container-title":"Journal of Big Data","DOI":"10.1186/s40537-019-0192-5","issue":"1","issued":{"date-parts":[["2019"]]},"page":"27","title":"Survey on deep learning with class imbalance","type":"article-journal","volume":"6"},
  {"id":"jorgensonAlmanackNavalRavikant2020","author":[{"family":"Jorgenson","given":"Eric"}],"citation-key":"jorgensonAlmanackNavalRavikant2020","edition":"1st ed","event-place":"Cork","ISBN":"978-1-5445-1420-8","issued":{"date-parts":[["2020"]]},"language":"eng","number-of-pages":"1","publisher":"BookBaby","publisher-place":"Cork","source":"K10plus ISBN","title":"The Almanack of Naval Ravikant: A Guide to Wealth and Happiness","title-short":"The Almanack of Naval Ravikant","type":"book"},
  {"id":"josseConsistencySupervisedLearning2020","author":[{"family":"Josse","given":"Julie"},{"family":"Prost","given":"Nicolas"},{"family":"Scornet","given":"Erwan"},{"family":"Varoquaux","given":"Gaël"}],"citation-key":"josseConsistencySupervisedLearning2020","issued":{"date-parts":[["2020"]]},"title":"On the consistency of supervised learning with missing values","type":"document"},
  {"id":"jurkatisInferringTradeDirections2022","author":[{"family":"Jurkatis","given":"Simon"}],"citation-key":"jurkatisInferringTradeDirections2022","container-title":"Journal of Financial Markets","DOI":"10.1016/j.finmar.2021.100635","issued":{"date-parts":[["2022"]]},"page":"100635","title":"Inferring trade directions in fast markets","type":"article-journal","volume":"58"},
  {"id":"kadanBoundExpectedStock2020","author":[{"family":"Kadan","given":"Ohad"},{"family":"Tang","given":"Xiaoxiao"}],"citation-key":"kadanBoundExpectedStock2020","container-title":"The Review of Financial Studies","DOI":"10.1093/rfs/hhz075","editor":[{"family":"Van Nieuwerburgh","given":"Stijn"}],"issue":"4","issued":{"date-parts":[["2020"]]},"page":"1565–1617","title":"A bound on expected stock returns","type":"article-journal","volume":"33"},
  {"id":"kadraWelltunedSimpleNets2021","author":[{"family":"Kadra","given":"Arlind"},{"family":"Lindauer","given":"Marius"},{"family":"Hutter","given":"Frank"},{"family":"Grabocka","given":"Josif"}],"citation-key":"kadraWelltunedSimpleNets2021","container-title":"Advances in Neural Information Processing Systems","issued":{"date-parts":[["2021"]]},"page":"23928–23941","publisher":"Curran Associates, Inc.","title":"Well-tuned simple nets excel on tabular datasets","type":"paper-conference","volume":"34"},
  {"id":"kaeckPriceImpactBid2022","accessed":{"date-parts":[["2023",6,20]]},"author":[{"family":"Kaeck","given":"Andreas"},{"family":"Van Kervel","given":"Vincent"},{"family":"Seeger","given":"Norman J."}],"citation-key":"kaeckPriceImpactBid2022","container-title":"Journal of Financial Markets","DOI":"10.1016/j.finmar.2021.100675","issued":{"date-parts":[["2022"]]},"page":"100675","title":"Price impact versus bid–ask spreads in the index option market","type":"article-journal","volume":"59"},
  {"id":"KatanamlorgInvoicesdonutmodelv1Main2023","abstract":"We’re on a journey to advance and democratize artificial intelligence through open source and open science.","accessed":{"date-parts":[["2024",12,10]]},"citation-key":"KatanamlorgInvoicesdonutmodelv1Main2023","issued":{"date-parts":[["2023",5,11]]},"title":"katanaml-org/invoices-donut-model-v1 at main","type":"webpage","URL":"https://huggingface.co/katanaml-org/invoices-donut-model-v1/tree/main"},
  {"id":"kaufmanLeakageDataMining2012","accessed":{"date-parts":[["2023",2,24]]},"author":[{"family":"Kaufman","given":"Shachar"},{"family":"Rosset","given":"Saharon"},{"family":"Perlich","given":"Claudia"},{"family":"Stitelman","given":"Ori"}],"citation-key":"kaufmanLeakageDataMining2012","container-title":"ACM Transactions on Knowledge Discovery from Data","DOI":"10.1145/2382577.2382579","issue":"4","issued":{"date-parts":[["2012"]]},"page":"1–21","title":"Leakage in data mining: formulation, detection, and avoidance","type":"article-journal","volume":"6"},
  {"id":"kavajeczPackagingLiquidityBlind2005","accessed":{"date-parts":[["2023",4,9]]},"author":[{"family":"Kavajecz","given":"Kenneth A."},{"family":"Keim","given":"Donald B."}],"citation-key":"kavajeczPackagingLiquidityBlind2005","container-title":"The Journal of Financial and Quantitative Analysis","DOI":"10.1017/S0022109000001836","issue":"3","issued":{"date-parts":[["2005"]]},"page":"465–492","publisher":"Cambridge University Press","title":"Packaging liquidity: blind auctions and transaction efficiencies","type":"article-journal","volume":"40"},
  {"id":"keLightGBMHighlyEfficient2017","author":[{"family":"Ke","given":"Guolin"},{"family":"Meng","given":"Qi"},{"family":"Finley","given":"Thomas"},{"family":"Wang","given":"Taifeng"},{"family":"Chen","given":"Wei"},{"family":"Ma","given":"Weidong"},{"family":"Ye","given":"Qiwei"},{"family":"Liu","given":"Tie-Yan"}],"citation-key":"keLightGBMHighlyEfficient2017","container-title":"Advances in Neural Information Processing Systems","issued":{"date-parts":[["2017"]]},"page":"3146–3154","publisher":"Curran Associates, Inc.","title":"LightGBM: a highly efficient gradient boosting decision tree","type":"paper-conference","volume":"30"},
  {"id":"kellyCharacteristicsAreCovariances2019","author":[{"family":"Kelly","given":"Bryan T."},{"family":"Pruitt","given":"Seth"},{"family":"Su","given":"Yinan"}],"citation-key":"kellyCharacteristicsAreCovariances2019","container-title":"Journal of Financial Economics","DOI":"10.1016/j.jfineco.2019.05.001","issue":"3","issued":{"date-parts":[["2019"]]},"page":"501–524","title":"Characteristics are covariances: a unified model of risk and return","type":"article-journal","volume":"134"},
  {"id":"keskarLargeBatchTrainingDeep2017","author":[{"family":"Keskar","given":"Nitish Shirish"},{"family":"Mudigere","given":"Dheevatsa"},{"family":"Nocedal","given":"Jorge"},{"family":"Smelyanskiy","given":"Mikhail"},{"family":"Tang","given":"Ping Tak Peter"}],"citation-key":"keskarLargeBatchTrainingDeep2017","container-title":"Proceedings of the 5th international conference on learning representations","event-place":"Toulon, France","issued":{"date-parts":[["2017"]]},"publisher-place":"Toulon, France","title":"On large-batch training for deep learning: generalization gap and sharp minima","type":"paper-conference"},
  {"id":"khorramEndtoendCNNLSTM2021","accessed":{"date-parts":[["2022",5,3]]},"author":[{"family":"Khorram","given":"Amin"},{"family":"Khalooei","given":"Mohammad"},{"family":"Rezghi","given":"Mansoor"}],"citation-key":"khorramEndtoendCNNLSTM2021","container-title":"Applied Intelligence","DOI":"10.1007/s10489-020-01859-1","issue":"2","issued":{"date-parts":[["2021"]]},"page":"736–751","title":"End-to-end CNN + LSTM deep learning approach for bearing fault diagnosis","type":"article-journal","volume":"51"},
  {"id":"kichererSeamlesslyPortableApplications2012","accessed":{"date-parts":[["2021",2,20]]},"author":[{"family":"Kicherer","given":"Mario"},{"family":"Nowak","given":"Fabian"},{"family":"Buchty","given":"Rainer"},{"family":"Karl","given":"Wolfgang"}],"citation-key":"kichererSeamlesslyPortableApplications2012","container-title":"ACM Transactions on Architecture and Code Optimization","DOI":"10.1145/2086696.2086721","issue":"4","issued":{"date-parts":[["2012"]]},"page":"1–20","title":"Seamlessly portable applications: managing the diversity of modern heterogeneous systems","type":"article-journal","volume":"8"},
  {"id":"kitaevReformerEfficientTransformer2020","author":[{"family":"Kitaev","given":"Nikita"},{"family":"Kaiser","given":"Łukasz"},{"family":"Levskaya","given":"Anselm"}],"citation-key":"kitaevReformerEfficientTransformer2020","container-title":"Proceedings of the 8th International Conference on Learning Representations","event-place":"Addis Ababa, Ethopia","issued":{"date-parts":[["2020"]]},"publisher-place":"Addis Ababa, Ethopia","title":"Reformer: the efficient transformer","type":"paper-conference"},
  {"id":"klingenbrunnTransformerImplementationTimeseries2021","accessed":{"date-parts":[["2021",11,6]]},"author":[{"family":"Klingenbrunn","given":"Natasha"}],"citation-key":"klingenbrunnTransformerImplementationTimeseries2021","issued":{"date-parts":[["2021"]]},"title":"Transformer implementation for time-series forecasting","type":"document","URL":"https://medium.com/mlearning-ai/transformer-implementation-for-time-series-forecasting-a9db2db5c820"},
  {"id":"kommerImmobilienkaufUndFinanzierung2022","abstract":"Immobilien gelten als solide Wertanlage und seit Corona hat sich die Nachfrage nach eigenen vier Wänden weiter verstärkt. Die Zinsen sind niedrig, die Preise regional sehr unterschiedlich. Und in den Kreditverträgen der Banken wird das Kleingedruckte immer komplexer. Um die Tücken des Hauskaufs zu durchschauen, braucht es Sachverstand. Dieses Buch hilft, diesen zu entwickeln: bei der Einschätzung des Kaufpreises und der Risiken, bei der Strukturierung des Kaufvertrags und bei der Finanzierung. Gerd Kommer versetzt seine Leserinnen und Leser in die Lage, auf Augenhöhe mit Verkäufern, Maklern und Banken zu sprechen, um das beste Ergebnis zu erzielen. (Verlagstext)","author":[{"family":"Kommer","given":"Gerd"}],"citation-key":"kommerImmobilienkaufUndFinanzierung2022","edition":"2., vollständig überarbeitete und erweiterete Auflage","event-place":"Frankfurt New York","ISBN":"978-3-593-51554-0","issued":{"date-parts":[["2022"]]},"language":"ger","number-of-pages":"315","publisher":"Campus Verlag","publisher-place":"Frankfurt New York","source":"K10plus ISBN","title":"Immobilienkauf und Finanzierung für Selbstnutzer: Geld sparen und Fehler vermeiden beim Kauf der eigenen vier Wände","title-short":"Immobilienkauf und Finanzierung für Selbstnutzer","type":"book"},
  {"id":"kommerSouveraenInvestierenMit2024","author":[{"family":"Kommer","given":"Gerd"}],"citation-key":"kommerSouveraenInvestierenMit2024","edition":"6., vollständig aktualisierte und überarbeitete Auflage","event-place":"Frankfurt New York","ISBN":"978-3-593-51770-4","issued":{"date-parts":[["2024"]]},"language":"ger","number-of-pages":"552","publisher":"Campus Verlag","publisher-place":"Frankfurt New York","source":"K10plus ISBN","title":"Souverän investieren mit Indexfonds und ETFs: ein Investmentbuch für fortgeschrittene Privatanleger","title-short":"Souverän investieren mit Indexfonds und ETFs","type":"book"},
  {"id":"kommerSouveraenInvestierenVor2020","author":[{"family":"Kommer","given":"Gerd"},{"family":"Pappenberger","given":"Sebastian"}],"citation-key":"kommerSouveraenInvestierenVor2020","edition":"Ungekürzte Lesefassung","event-place":"München","ISBN":"978-3-593-51245-7 978-3-95471-740-8","issued":{"date-parts":[["2020"]]},"language":"ger","number-of-pages":"9","publisher":"Abod Verlag GmbH","publisher-place":"München","source":"K10plus ISBN","title":"Souverän investieren vor und im Ruhestand: mit ETFs Ihren Lebensstandard und Ihre Vermögensziele sichern","title-short":"Souverän investieren vor und im Ruhestand","type":"song"},
  {"id":"kommerSouveraenVermoegenSchuetzen2021","abstract":"Vermögen sichern für die jetzige und die nächste Generation, finanziell unabhängig sein und bleiben. So lauten die Ziele, die wohlhabende Menschen in der zweiten Lebenshälfte bewegen. Gerade heute machen sich viele von ihnen Sorgen um ihr Eigentum. Gerd Kommer und Olaf Gierhake, beide selbst finanziell unabhängige Unternehmer, zeigen in diesem Schritt-für-Schritt-Ratgeber praxisnahe, wirksame Instrumente des Vermögensschutzes. Zur Senkung der Belastung mit Kosten und Steuern. Zur Reduktion politischer, volkswirtschaftlicher, steuerlicher, rechtlicher und marktbedingter Risiken. Einen überzeugenden Mehrwert liefern hier Familienstiftungen IBM und zwar für alle wichtigen Vermögensarten: liquide Investments, Immobilien und Unternehmensbeteiligungen. (Verlagstext)","author":[{"family":"Kommer","given":"Gerd"},{"family":"Gierhake","given":"Olaf"}],"citation-key":"kommerSouveraenVermoegenSchuetzen2021","event-place":"Frankfurt New York","ISBN":"978-3-593-51368-3","issued":{"date-parts":[["2021"]]},"language":"ger","number-of-pages":"407","publisher":"Campus Verlag","publisher-place":"Frankfurt New York","source":"K10plus ISBN","title":"Souverän Vermögen schützen: wie sich Vermögende gegen Risiken absichern – ein praktischer Asset-Protection-Ratgeber","title-short":"Souverän Vermögen schützen","type":"book"},
  {"id":"kossenSelfAttentionDatapointsGoing2021","author":[{"family":"Kossen","given":"Jannik"},{"family":"Band","given":"Neil"},{"family":"Lyle","given":"Clare"},{"family":"Gomez","given":"Aidan N"},{"family":"Rainforth","given":"Thomas"},{"family":"Gal","given":"Yarin"}],"citation-key":"kossenSelfAttentionDatapointsGoing2021","container-title":"Advances in Neural Information Processing Systems","event-place":"Online","issued":{"date-parts":[["2021"]]},"page":"28742–28756","publisher":"Curran Associates, Inc.","publisher-place":"Online","title":"Self-attention between datapoints: going beyond individual input-output pairs in deep learning","type":"paper-conference","volume":"34"},
  {"id":"kozlowskiSamplesElectronicInvoices2021","abstract":"Electronic invoices have become the product of the information age, increasing their utility on the nowadays market. Looking at real electronic invoices across the globe, we have come up with sufficient placement of the information. Each detail has been generated in a programmable way using Python programs. Billing information is minimalistic to omit or lower the chance of fraud detection. The process of collecting each product has been achieved by scrapping popular online marketplaces. As a result, categorized groups have been created to imitate a manner of the persona. The direction of the potential reusability is heading towards becoming an input of the machine learning fraud detection algorithms or data extraction mechanisms. Datasets presents 1000 samples each of auto-generated invoices containing: - valid information. - valid information with colored iban background. RGB color of a background varies between (255,255,240) to (255,255,254). - valid information with modified space between iban characters. Charspace coefficient varies between 0.001 to 1. Both ends of a special invoice modifier represents a domain from detectable to non-detectable factor by a human eye. Nomenclature: invoice_<invoice_id>(_charspace_<coefficent_numerator>)(_color_B_<blue_color_value>).pdf","accessed":{"date-parts":[["2024",12,10]]},"author":[{"family":"Kozłowski","given":"Marek"},{"family":"Weichbroth","given":"Paweł"}],"citation-key":"kozlowskiSamplesElectronicInvoices2021","DOI":"10.17632/tnj49gpmtz.2","issued":{"date-parts":[["2021",6,1]]},"language":"en","publisher":"Mendeley Data","source":"data.mendeley.com","title":"Samples of electronic invoices","type":"article-journal","URL":"https://data.mendeley.com/datasets/tnj49gpmtz/2","volume":"2"},
  {"id":"kraussDeepNeuralNetworks2017","author":[{"family":"Krauss","given":"Christopher"},{"family":"Do","given":"Xuan Anh"},{"family":"Huck","given":"Nicolas"}],"citation-key":"kraussDeepNeuralNetworks2017","container-title":"European Journal of Operational Research","DOI":"10.1016/j.ejor.2016.10.031","issue":"2","issued":{"date-parts":[["2017"]]},"page":"689–702","title":"Deep neural networks, gradient-boosted trees, random forests: statistical arbitrage on the S&P 500","type":"article-journal","volume":"259"},
  {"id":"krogerKapitelOutlierDetection","author":[{"family":"Kröger","given":"Peer"},{"family":"Zimek","given":"Arthur"}],"citation-key":"krogerKapitelOutlierDetection","page":"36","title":"Kapitel 6: outlier detection","type":"article-journal"},
  {"id":"kudoSentencePieceSimpleLanguage2018","abstract":"This paper describes SentencePiece, a language-independent subword tokenizer and detokenizer designed for Neural-based text processing, including Neural Machine Translation. It provides open-source C++ and Python implementations for subword units. While existing subword segmentation tools assume that the input is pre-tokenized into word sequences, SentencePiece can train subword models directly from raw sentences, which allows us to make a purely end-to-end and language independent system. We perform a validation experiment of NMT on English-Japanese machine translation, and ﬁnd that it is possible to achieve comparable accuracy to direct subword training from raw sentences. We also compare the performance of subword training and segmentation with various conﬁgurations. SentencePiece is available under the Apache 2 license at https://github.com/google/ sentencepiece.","accessed":{"date-parts":[["2024",11,26]]},"author":[{"family":"Kudo","given":"Taku"},{"family":"Richardson","given":"John"}],"citation-key":"kudoSentencePieceSimpleLanguage2018","DOI":"10.48550/arXiv.1808.06226","issued":{"date-parts":[["2018",8,19]]},"language":"en","number":"arXiv:1808.06226","publisher":"arXiv","source":"arXiv.org","title":"SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing","title-short":"SentencePiece","type":"article","URL":"http://arxiv.org/abs/1808.06226"},
  {"id":"kuhlHumanVsSupervised2020","accessed":{"date-parts":[["2021",11,27]]},"author":[{"family":"Kühl","given":"Niklas"},{"family":"Goutier","given":"Marc"},{"family":"Baier","given":"Lucas"},{"family":"Wolff","given":"Clemens"},{"family":"Martin","given":"Dominik"}],"citation-key":"kuhlHumanVsSupervised2020","container-title":"arXiv:2012.03661 [cs]","issued":{"date-parts":[["2020"]]},"title":"Human vs. supervised machine learning: who learns patterns faster?","type":"article-journal","URL":"http://arxiv.org/abs/2012.03661"},
  {"id":"kuhnFeatureEngineeringSelection2020","author":[{"family":"Kuhn","given":"Max"},{"family":"Johnson","given":"Kjell"}],"citation-key":"kuhnFeatureEngineeringSelection2020","event-place":"Boca Raton, FL","issued":{"date-parts":[["2020"]]},"publisher":"Chapman and Hall/CRC","publisher-place":"Boca Raton, FL","title":"Feature engineering and selection: a practical approach for predictive models","type":"book","volume":"74"},
  {"id":"kusupatiMatryoshkaRepresentationLearning2024","abstract":"Learned representations are a central component in modern ML systems, serving a multitude of downstream tasks. When training such representations, it is often the case that computational and statistical constraints for each downstream task are unknown. In this context, rigid fixed-capacity representations can be either over or under-accommodating to the task at hand. This leads us to ask: can we design a flexible representation that can adapt to multiple downstream tasks with varying computational resources? Our main contribution is Matryoshka Representation Learning (MRL) which encodes information at different granularities and allows a single embedding to adapt to the computational constraints of downstream tasks. MRL minimally modifies existing representation learning pipelines and imposes no additional cost during inference and deployment. MRL learns coarse-to-fine representations that are at least as accurate and rich as independently trained low-dimensional representations. The flexibility within the learned Matryoshka Representations offer: (a) up to 14× smaller embedding size for ImageNet-1K classification at the same level of accuracy; (b) up to 14× real-world speed-ups for large-scale retrieval on ImageNet-1K and 4K; and (c) up to 2% accuracy improvements for long-tail few-shot classification, all while being as robust as the original representations. Finally, we show that MRL extends seamlessly to web-scale datasets (ImageNet, JFT) across various modalities – vision (ViT, ResNet), vision + language (ALIGN) and language (BERT). MRL code and pretrained models are open-sourced at https://github.com/RAIVNLab/MRL.","accessed":{"date-parts":[["2024",11,26]]},"author":[{"family":"Kusupati","given":"Aditya"},{"family":"Bhatt","given":"Gantavya"},{"family":"Rege","given":"Aniket"},{"family":"Wallingford","given":"Matthew"},{"family":"Sinha","given":"Aditya"},{"family":"Ramanujan","given":"Vivek"},{"family":"Howard-Snyder","given":"William"},{"family":"Chen","given":"Kaifeng"},{"family":"Kakade","given":"Sham"},{"family":"Jain","given":"Prateek"},{"family":"Farhadi","given":"Ali"}],"citation-key":"kusupatiMatryoshkaRepresentationLearning2024","DOI":"10.48550/arXiv.2205.13147","issued":{"date-parts":[["2024",2,8]]},"language":"en","number":"arXiv:2205.13147","publisher":"arXiv","source":"arXiv.org","title":"Matryoshka Representation Learning","type":"article","URL":"http://arxiv.org/abs/2205.13147"},
  {"id":"kusupatiMatryoshkaRepresentationLearning2024a","abstract":"Learned representations are a central component in modern ML systems, serving a multitude of downstream tasks. When training such representations, it is often the case that computational and statistical constraints for each downstream task are unknown. In this context, rigid fixed-capacity representations can be either over or under-accommodating to the task at hand. This leads us to ask: can we design a flexible representation that can adapt to multiple downstream tasks with varying computational resources? Our main contribution is Matryoshka Representation Learning (MRL) which encodes information at different granularities and allows a single embedding to adapt to the computational constraints of downstream tasks. MRL minimally modifies existing representation learning pipelines and imposes no additional cost during inference and deployment. MRL learns coarse-to-fine representations that are at least as accurate and rich as independently trained low-dimensional representations. The flexibility within the learned Matryoshka Representations offer: (a) up to 14× smaller embedding size for ImageNet-1K classification at the same level of accuracy; (b) up to 14× real-world speed-ups for large-scale retrieval on ImageNet-1K and 4K; and (c) up to 2% accuracy improvements for long-tail few-shot classification, all while being as robust as the original representations. Finally, we show that MRL extends seamlessly to web-scale datasets (ImageNet, JFT) across various modalities – vision (ViT, ResNet), vision + language (ALIGN) and language (BERT). MRL code and pretrained models are open-sourced at https://github.com/RAIVNLab/MRL.","accessed":{"date-parts":[["2025",11,12]]},"author":[{"family":"Kusupati","given":"Aditya"},{"family":"Bhatt","given":"Gantavya"},{"family":"Rege","given":"Aniket"},{"family":"Wallingford","given":"Matthew"},{"family":"Sinha","given":"Aditya"},{"family":"Ramanujan","given":"Vivek"},{"family":"Howard-Snyder","given":"William"},{"family":"Chen","given":"Kaifeng"},{"family":"Kakade","given":"Sham"},{"family":"Jain","given":"Prateek"},{"family":"Farhadi","given":"Ali"}],"citation-key":"kusupatiMatryoshkaRepresentationLearning2024a","DOI":"10.48550/arXiv.2205.13147","issued":{"date-parts":[["2024",2,9]]},"language":"en","number":"arXiv:2205.13147","publisher":"arXiv","source":"arXiv.org","title":"Matryoshka Representation Learning","type":"article","URL":"http://arxiv.org/abs/2205.13147"},
  {"id":"lambertonIntroductionStochasticCalculus","author":[{"family":"Lamberton","given":"Damien"},{"family":"Lapeyre","given":"Bernard"}],"citation-key":"lambertonIntroductionStochasticCalculus","page":"253","title":"Introduction to stochastic calculus applied to finance, second edition","type":"article-journal"},
  {"id":"lampleLargeMemoryLayers2019","accessed":{"date-parts":[["2023",1,16]]},"author":[{"family":"Lample","given":"Guillaume"},{"family":"Sablayrolles","given":"Alexandre"},{"family":"Ranzato","given":"Marc'Aurelio"},{"family":"Denoyer","given":"Ludovic"},{"family":"Jégou","given":"Hervé"}],"citation-key":"lampleLargeMemoryLayers2019","issued":{"date-parts":[["2019"]]},"title":"Large memory layers with product keys","type":"document","URL":"http://arxiv.org/abs/1907.05242"},
  {"id":"lecunEfficientBackProp2012","author":[{"family":"LeCun","given":"Yann A."},{"family":"Bottou","given":"Léon"},{"family":"Orr","given":"Genevieve B."},{"family":"Müller","given":"Klaus-Robert"}],"citation-key":"lecunEfficientBackProp2012","container-title":"Neural Networks: Tricks of the Trade","DOI":"10.1007/978-3-642-35289-8\\_3","editor":[{"family":"Montavon","given":"Grégoire"},{"family":"Orr","given":"Geneviève B."},{"family":"Müller","given":"Klaus-Robert"}],"event-place":"Berlin, Heidelberg","issued":{"date-parts":[["2012"]]},"page":"9–48","publisher":"Springer Berlin Heidelberg","publisher-place":"Berlin, Heidelberg","title":"Efficient BackProp","type":"chapter","volume":"7700"},
  {"id":"leeInferringInvestorBehavior2000","author":[{"family":"Lee","given":"Charles"},{"family":"Radhakrishna","given":"Balkrishna"}],"citation-key":"leeInferringInvestorBehavior2000","container-title":"Journal of Financial Markets","DOI":"10.1016/S1386-4181(00)00002-1","issue":"2","issued":{"date-parts":[["2000"]]},"page":"83–111","title":"Inferring investor behavior: evidence from TORQ data","type":"article-journal","volume":"3"},
  {"id":"leeInferringTradeDirection1991","author":[{"family":"Lee","given":"Charles"},{"family":"Ready","given":"Mark J."}],"citation-key":"leeInferringTradeDirection1991","container-title":"The Journal of Finance","DOI":"10.1111/j.1540-6261.1991.tb02683.x","issue":"2","issued":{"date-parts":[["1991"]]},"page":"733–746","title":"Inferring trade direction from intraday data","type":"article-journal","volume":"46"},
  {"id":"leeInformationContentsOrder2019","accessed":{"date-parts":[["2023",6,20]]},"author":[{"family":"Lee","given":"Jaeram"}],"citation-key":"leeInformationContentsOrder2019","container-title":"Journal of Derivatives and Quantitative Studies","DOI":"10.1108/JDQS-04-2019-B0001","issue":"4","issued":{"date-parts":[["2019"]]},"page":"365–400","title":"Information Contents of Order Flow Toxicity in the Options Market : The Case of KOSPI200 Index Options","type":"article-journal","volume":"27"},
  {"id":"leeMarketIntegrationPrice1993","accessed":{"date-parts":[["2023",2,25]]},"author":[{"family":"Lee","given":"Charles"}],"citation-key":"leeMarketIntegrationPrice1993","container-title":"The Journal of Finance","DOI":"10.1111/j.1540-6261.1993.tb04028.x","issue":"3","issued":{"date-parts":[["1993"]]},"page":"1009–1038","title":"Market integration and price execution for NYSE-listed securities","type":"article-journal","volume":"48"},
  {"id":"leePseudolabelSimpleEfficient","author":[{"family":"Lee","given":"Dong-Hyun"}],"citation-key":"leePseudolabelSimpleEfficient","issued":{"date-parts":[["2013"]]},"page":"7","title":"Pseudo-label: the simple and efficient semi-supervised learning method for deep neural networks","type":"article-journal"},
  {"id":"leeSetTransformerFramework2019","accessed":{"date-parts":[["2023",4,20]]},"author":[{"family":"Lee","given":"Juho"},{"family":"Lee","given":"Yoonho"},{"family":"Kim","given":"Jungtaek"},{"family":"Kosiorek","given":"Adam"},{"family":"Choi","given":"Seungjin"},{"family":"Teh","given":"Yee Whye"}],"citation-key":"leeSetTransformerFramework2019","container-title":"Proceedings of the 36th International Conference on Machine Learning","issued":{"date-parts":[["2019"]]},"page":"3744–3753","publisher":"PMLR","title":"Set transformer: a framework for attention-based permutation-invariant neural networks","type":"paper-conference","URL":"https://proceedings.mlr.press/v97/lee19d.html"},
  {"id":"lemorvanWhatGoodImputation2021","author":[{"family":"Le Morvan","given":"Marine"},{"family":"Josse","given":"Julie"},{"family":"Scornet","given":"Erwan"},{"family":"Varoquaux","given":"Gael"}],"citation-key":"lemorvanWhatGoodImputation2021","container-title":"Advances in Neural Information Processing Systems","issued":{"date-parts":[["2021"]]},"page":"11530–11540","publisher":"Curran Associates, Inc.","title":"What's a good imputation to predict with missing values?","type":"paper-conference","volume":"34"},
  {"id":"levinTransferLearningDeep2022","author":[{"family":"Levin","given":"Roman"},{"family":"Cherepanova","given":"Valeriia"},{"family":"Schwarzschild","given":"Avi"},{"family":"Bansal","given":"Arpit"},{"family":"Bruss","given":"C. Bayan"},{"family":"Goldstein","given":"Tom"},{"family":"Wilson","given":"Andrew Gordon"},{"family":"Goldblum","given":"Micah"}],"citation-key":"levinTransferLearningDeep2022","issued":{"date-parts":[["2022"]]},"title":"Transfer learning with deep tabular models","type":"document"},
  {"id":"liangFactorizationMeetsItem2016","accessed":{"date-parts":[["2021",5,4]]},"author":[{"family":"Liang","given":"Dawen"},{"family":"Altosaar","given":"Jaan"},{"family":"Charlin","given":"Laurent"},{"family":"Blei","given":"David M."}],"citation-key":"liangFactorizationMeetsItem2016","container-title":"Proceedings of the 10th ACM Conference on Recommender Systems","DOI":"10.1145/2959100.2959182","event-place":"Boston Massachusetts USA","issued":{"date-parts":[["2016"]]},"page":"59–66","publisher":"ACM","publisher-place":"Boston Massachusetts USA","title":"Factorization meets the item embedding: regularizing matrix factorization with item co-occurrence","type":"paper-conference"},
  {"id":"liDebiasedMDIFeature2019","abstract":"Tree ensembles such as Random Forests have achieved impressive empirical success across a wide variety of applications. To understand how these models make predictions, people routinely turn to feature importance measures calculated from tree ensembles. It has long been known that Mean Decrease Impurity (MDI), one of the most widely used measures of feature importance, incorrectly assigns high importance to noisy features, leading to systematic bias in feature selection. In this paper, we address the feature selection bias of MDI from both theoretical and methodological perspectives. Based on the original deﬁnition of MDI by Breiman et al. (3) for a single tree, we derive a tight non-asymptotic bound on the expected bias of MDI importance of noisy features, showing that deep trees have higher (expected) feature selection bias than shallow ones. However, it is not clear how to reduce the bias of MDI using its existing analytical expression. We derive a new analytical expression for MDI, and based on this new expression, we are able to propose a new MDI feature importance measure using out-of-bag samples, called MDI-oob. For both the simulated data and a genomic ChIP dataset, MDI-oob achieves state-of-the-art performance in feature selection from Random Forests for both deep and shallow trees.","accessed":{"date-parts":[["2025",11,12]]},"author":[{"family":"Li","given":"Xiao"},{"family":"Wang","given":"Yu"},{"family":"Basu","given":"Sumanta"},{"family":"Kumbier","given":"Karl"},{"family":"Yu","given":"Bin"}],"citation-key":"liDebiasedMDIFeature2019","DOI":"10.48550/arXiv.1906.10845","issued":{"date-parts":[["2019",10,29]]},"language":"en","number":"arXiv:1906.10845","publisher":"arXiv","source":"arXiv.org","title":"A Debiased MDI Feature Importance Measure for Random Forests","type":"article","URL":"http://arxiv.org/abs/1906.10845"},
  {"id":"liINVESTABLEINTERPRETABLEMACHINE","author":[{"family":"Li","given":"Yimou"},{"family":"Simon","given":"Zachary"},{"family":"Turkington","given":"David"}],"citation-key":"liINVESTABLEINTERPRETABLEMACHINE","page":"34","title":"Investable and interpretable machine learning for equities","type":"article-journal"},
  {"id":"Lillo_2003","author":[{"family":"Lillo","given":"Fabrizio"},{"family":"Farmer","given":"J. Doyne"},{"family":"Mantegna","given":"Rosario N."}],"citation-key":"Lillo_2003","container-title":"Nature","DOI":"10.1038/421129a","issued":{"date-parts":[["2003"]]},"PMID":"12520292","title":"Econophysics: master curve for price-impact function.","type":"article-journal"},
  {"id":"linnainmaaHistoryCrossSection","author":[{"family":"Linnainmaa","given":"Juhani T"},{"family":"Roberts","given":"Michael"}],"citation-key":"linnainmaaHistoryCrossSection","page":"69","title":"The history of the cross section of stock returns","type":"article-journal"},
  {"id":"linnainmaaWeatherTimeSeries2009","author":[{"family":"Linnainmaa","given":"Juhani T."},{"family":"Rosu","given":"Ioanid"}],"citation-key":"linnainmaaWeatherTimeSeries2009","container-title":"null","DOI":"10.2139/ssrn.1108862","issued":{"date-parts":[["2009"]]},"PMID":"null","title":"Weather and time series determinants of liquidity in a limit order market","type":"article-journal"},
  {"id":"linSurveyTransformers2021","accessed":{"date-parts":[["2022",12,4]]},"author":[{"family":"Lin","given":"Tianyang"},{"family":"Wang","given":"Yuxin"},{"family":"Liu","given":"Xiangyang"},{"family":"Qiu","given":"Xipeng"}],"citation-key":"linSurveyTransformers2021","issued":{"date-parts":[["2021"]]},"title":"A survey of transformers","type":"document","URL":"http://arxiv.org/abs/2106.04554"},
  {"id":"linWhyOptionsPrices2015","accessed":{"date-parts":[["2022",7,12]]},"author":[{"family":"Lin","given":"Tse-Chun"},{"family":"Lu","given":"Xiaolong"}],"citation-key":"linWhyOptionsPrices2015","container-title":"Journal of Banking & Finance","DOI":"10.1016/j.jbankfin.2014.11.008","issued":{"date-parts":[["2015"]]},"page":"17–28","title":"Why do options prices predict stock returns? Evidence from analyst tipping","type":"article-journal","volume":"52"},
  {"id":"liptonMythosModelInterpretability2017","author":[{"family":"Lipton","given":"Zachary C."}],"citation-key":"liptonMythosModelInterpretability2017","container-title":"Queue","DOI":"10.1145/3236386.3241340","issue":"3","issued":{"date-parts":[["2018"]]},"page":"31–57","title":"The mythos of model interpretability: in machine learning, the concept of interpretability is both important and slippery.","type":"article-journal","volume":"16"},
  {"id":"littleStatisticalAnalysisMissing","author":[{"family":"Little","given":"Roderick J A"},{"literal":"Rubin, Donald"}],"citation-key":"littleStatisticalAnalysisMissing","DOI":"10.1002/9781119013563","title":"Statistical analysis with missing data","type":"article-journal"},
  {"id":"littlestoneWeightedMajorityAlgorithm","author":[{"family":"Littlestone","given":"Nick"},{"family":"Warmuth","given":"Manfred K"}],"citation-key":"littlestoneWeightedMajorityAlgorithm","container-title":". Introduction","page":"39","title":"The weighted majority algorithm","type":"article-journal"},
  {"id":"liuDataQualityProblems2020","accessed":{"date-parts":[["2021",10,29]]},"author":[{"family":"Liu","given":"Grace"}],"citation-key":"liuDataQualityProblems2020","container-title":"Journal of Business & Finance Librarianship","DOI":"10.1080/08963568.2020.1847555","issue":"3–4","issued":{"date-parts":[["2020"]]},"page":"315–371","title":"Data quality problems troubling business and financial researchers: a literature review and synthetic analysis","type":"article-journal","volume":"25"},
  {"id":"liuImprovedBaselinesVisual2024","abstract":"Large multimodal models (LMM) have recently shown encouraging progress with visual instruction tuning. In this paper, we present the first systematic study to investigate the design choices of LMMs in a controlled setting under the LLaVA framework. We show that the fully-connected vision-language connector in LLaVA is surprisingly powerful and data-efficient. With simple modifications to LLaVA, namely, using CLIP-ViT-L-336px with an MLP projection and adding academic-task-oriented VQA data with response formatting prompts, we establish stronger baselines that achieve state-of-the-art across 11 benchmarks. Our final 13B checkpoint uses merely 1.2M publicly available data, and finishes full training in ∼1 day on a single 8-A100 node. Furthermore, we present some early exploration of open problems in LMMs, including scaling to higher resolution inputs, compositional capabilities, and model hallucination, etc. We hope this makes state-of-the-art LMM research more accessible. Code and model will be publicly available.","accessed":{"date-parts":[["2024",11,20]]},"author":[{"family":"Liu","given":"Haotian"},{"family":"Li","given":"Chunyuan"},{"family":"Li","given":"Yuheng"},{"family":"Lee","given":"Yong Jae"}],"citation-key":"liuImprovedBaselinesVisual2024","issued":{"date-parts":[["2024",5,15]]},"language":"en","number":"arXiv:2310.03744","publisher":"arXiv","source":"arXiv.org","title":"Improved Baselines with Visual Instruction Tuning","type":"article","URL":"http://arxiv.org/abs/2310.03744"},
  {"id":"liuMonolithRealTime2022","accessed":{"date-parts":[["2022",11,1]]},"author":[{"family":"Liu","given":"Zhuoran"},{"family":"Zou","given":"Leqi"},{"family":"Zou","given":"Xuan"},{"family":"Wang","given":"Caihua"},{"family":"Zhang","given":"Biao"},{"family":"Tang","given":"Da"},{"family":"Zhu","given":"Bolin"},{"family":"Zhu","given":"Yijie"},{"family":"Wu","given":"Peng"},{"family":"Wang","given":"Ke"},{"family":"Cheng","given":"Youlong"}],"citation-key":"liuMonolithRealTime2022","issued":{"date-parts":[["2022"]]},"title":"Monolith: real time recommendation system with collisionless embedding table","type":"document","URL":"http://arxiv.org/abs/2209.07663"},
  {"id":"liuPayAttentionMlps2021","accessed":{"date-parts":[["2022",12,7]]},"author":[{"family":"Liu","given":"Hanxiao"},{"family":"Dai","given":"Zihang"},{"family":"So","given":"David R."},{"family":"Le","given":"Quoc V."}],"citation-key":"liuPayAttentionMlps2021","issued":{"date-parts":[["2021"]]},"title":"Pay attention to mlps","type":"document","URL":"http://arxiv.org/abs/2105.08050"},
  {"id":"liuRelatedPinsPinterest2017","author":[{"family":"Liu","given":"David C."},{"family":"Rogers","given":"Stephanie"},{"family":"Shiau","given":"Raymond"},{"family":"Kislyuk","given":"Dmitry"},{"family":"Ma","given":"Kevin C."},{"family":"Zhong","given":"Zhigang"},{"family":"Liu","given":"Jenny"},{"family":"Jing","given":"Yushi"}],"citation-key":"liuRelatedPinsPinterest2017","container-title":"Proceedings of the 26th International Conference on World Wide Web Companion - WWW '17 Companion","DOI":"10.1145/3041021.3054202","event-place":"Perth, Australia","issued":{"date-parts":[["2017"]]},"page":"583–592","publisher":"ACM Press","publisher-place":"Perth, Australia","title":"Related pins at pinterest: the evolution of a real-world recommender system","type":"paper-conference"},
  {"id":"liuRethinkingSkipConnection2020","author":[{"family":"Liu","given":"Fenglin"},{"family":"Ren","given":"Xuancheng"},{"family":"Zhang","given":"Zhiyuan"},{"family":"Sun","given":"Xu"},{"family":"Zou","given":"Yuexian"}],"citation-key":"liuRethinkingSkipConnection2020","container-title":"Proceedings of the 28th International Conference on Computational Linguistics","DOI":"10.18653/v1/2020.coling-main.320","event-place":"Barcelona, Spain (Online)","issued":{"date-parts":[["2020"]]},"page":"3586–3598","publisher":"International Committee on Computational Linguistics","publisher-place":"Barcelona, Spain (Online)","title":"Rethinking skip connection with layer normalization","type":"paper-conference"},
  {"id":"liuRoBERTaRobustlyOptimized2019","accessed":{"date-parts":[["2023",1,13]]},"author":[{"family":"Liu","given":"Yinhan"},{"family":"Ott","given":"Myle"},{"family":"Goyal","given":"Naman"},{"family":"Du","given":"Jingfei"},{"family":"Joshi","given":"Mandar"},{"family":"Chen","given":"Danqi"},{"family":"Levy","given":"Omer"},{"family":"Lewis","given":"Mike"},{"family":"Zettlemoyer","given":"Luke"},{"family":"Stoyanov","given":"Veselin"}],"citation-key":"liuRoBERTaRobustlyOptimized2019","issued":{"date-parts":[["2019"]]},"title":"Roberta: a robustly optimized bert pretraining approach","type":"document","URL":"http://arxiv.org/abs/1907.11692"},
  {"id":"liuSTAMPShorttermAttention2018","accessed":{"date-parts":[["2021",5,4]]},"author":[{"family":"Liu","given":"Qiao"},{"family":"Zeng","given":"Yifu"},{"family":"Mokhosi","given":"Refuoe"},{"family":"Zhang","given":"Haibin"}],"citation-key":"liuSTAMPShorttermAttention2018","container-title":"Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining","DOI":"10.1145/3219819.3219950","event-place":"London United Kingdom","issued":{"date-parts":[["2018"]]},"page":"1831–1839","publisher":"ACM","publisher-place":"London United Kingdom","title":"STAMP: short-term attention/memory priority model for session-based recommendation","type":"paper-conference"},
  {"id":"liuUnderstandingDifficultyTraining2020","author":[{"family":"Liu","given":"Liyuan"},{"family":"Liu","given":"Xiaodong"},{"family":"Gao","given":"Jianfeng"},{"family":"Chen","given":"Weizhu"},{"family":"Han","given":"Jiawei"}],"citation-key":"liuUnderstandingDifficultyTraining2020","container-title":"Proceedings of the 2020 conference on empirical methods in natural language processing (EMNLP)","DOI":"10.18653/v1/2020.emnlp-main.463","event-place":"Online","issued":{"date-parts":[["2020"]]},"page":"5747–5763","publisher":"Association for Computational Linguistics","publisher-place":"Online","title":"Understanding the difficulty of training transformers","type":"paper-conference"},
  {"id":"liuVarianceAdaptiveLearning2021","accessed":{"date-parts":[["2023",1,9]]},"author":[{"family":"Liu","given":"Liyuan"},{"family":"Jiang","given":"Haoming"},{"family":"He","given":"Pengcheng"},{"family":"Chen","given":"Weizhu"},{"family":"Liu","given":"Xiaodong"},{"family":"Gao","given":"Jianfeng"},{"family":"Han","given":"Jiawei"}],"citation-key":"liuVarianceAdaptiveLearning2021","issued":{"date-parts":[["2021"]]},"title":"On the variance of the adaptive learning rate and beyond","type":"document","URL":"http://arxiv.org/abs/1908.03265"},
  {"id":"Lo_2002","author":[{"family":"Lo","given":"Andrew W."},{"family":"MacKinlay","given":"A. Craig"},{"family":"Zhang","given":"June"}],"citation-key":"Lo_2002","container-title":"Journal of Financial Economics","DOI":"10.1016/s0304-405x(02)00134-4","issued":{"date-parts":[["2002"]]},"PMID":"null","title":"Econometric models of limit-order executions","type":"article-journal"},
  {"id":"lonesHowAvoidMachine2022","accessed":{"date-parts":[["2022",11,6]]},"author":[{"family":"Lones","given":"Michael A."}],"citation-key":"lonesHowAvoidMachine2022","issued":{"date-parts":[["2022"]]},"title":"How to avoid machine learning pitfalls: a guide for academic researchers","type":"document","URL":"http://arxiv.org/abs/2108.02497"},
  {"id":"lopezdepradoAdvancesFinancialMachine2018","author":[{"family":"López de Prado","given":"Marcos"}],"citation-key":"lopezdepradoAdvancesFinancialMachine2018","event-place":"Hoboken, NJ, USA","issued":{"date-parts":[["2018"]]},"publisher":"Wiley","publisher-place":"Hoboken, NJ, USA","title":"Advances in financial machine learning","type":"book"},
  {"id":"loshchilovDecoupledWeightDecay2019","author":[{"family":"Loshchilov","given":"Ilya"},{"family":"Hutter","given":"Frank"}],"citation-key":"loshchilovDecoupledWeightDecay2019","container-title":"Proceedings of the 7th International Conference on Learning Representations","event-place":"New Orleans, LA, USA","issued":{"date-parts":[["2019"]]},"publisher-place":"New Orleans, LA, USA","title":"Decoupled weight decay regularization","type":"paper-conference"},
  {"id":"loshchilovSGDRStochasticGradient2017","author":[{"family":"Loshchilov","given":"Ilya"},{"family":"Hutter","given":"Frank"}],"citation-key":"loshchilovSGDRStochasticGradient2017","issued":{"date-parts":[["2017"]]},"title":"SGDR: stochastic gradient descent with warm restarts","type":"document"},
  {"id":"ludewigEvaluationSessionbasedRecommendation2018","accessed":{"date-parts":[["2021",4,22]]},"author":[{"family":"Ludewig","given":"Malte"},{"family":"Jannach","given":"Dietmar"}],"citation-key":"ludewigEvaluationSessionbasedRecommendation2018","container-title":"User Modeling and User-Adapted Interaction","DOI":"10.1007/s11257-018-9209-6","issue":"4–5","issued":{"date-parts":[["2018"]]},"page":"331–390","title":"Evaluation of session-based recommendation algorithms","type":"article-journal","volume":"28"},
  {"id":"lundbergConsistentIndividualizedFeature2019","author":[{"family":"Lundberg","given":"Scott M."},{"family":"Erion","given":"Gabriel G."},{"family":"Lee","given":"Su-In"}],"citation-key":"lundbergConsistentIndividualizedFeature2019","issued":{"date-parts":[["2019"]]},"title":"Consistent individualized feature attribution for tree ensembles","type":"document"},
  {"id":"lundbergUnifiedApproachInterpreting2017","author":[{"family":"Lundberg","given":"Scott M."},{"family":"Lee","given":"Su-In"}],"citation-key":"lundbergUnifiedApproachInterpreting2017","collection-title":"NeurIPS 2017","container-title":"Advances in Neural Information Processing Systems","event-place":"Long Beach, CA","issued":{"date-parts":[["2017"]]},"page":"4768–4777","publisher":"Curran Associates, Inc.","publisher-place":"Long Beach, CA","title":"A unified approach to interpreting model predictions","type":"paper-conference","volume":"31"},
  {"id":"luoCollaborativeSelfattentionNetwork2020","accessed":{"date-parts":[["2021",4,19]]},"author":[{"family":"Luo","given":"Anjing"},{"family":"Zhao","given":"Pengpeng"},{"family":"Liu","given":"Yanchi"},{"family":"Zhuang","given":"Fuzhen"},{"family":"Wang","given":"Deqing"},{"family":"Xu","given":"Jiajie"},{"family":"Fang","given":"Junhua"},{"family":"Sheng","given":"Victor S."}],"citation-key":"luoCollaborativeSelfattentionNetwork2020","container-title":"Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence","DOI":"10.24963/ijcai.2020/359","event-place":"Yokohama, Japan","issued":{"date-parts":[["2020"]]},"page":"2591–2597","publisher":"International Joint Conferences on Artificial Intelligence Organization","publisher-place":"Yokohama, Japan","title":"Collaborative self-attention network for session-based recommendation","type":"paper-conference"},
  {"id":"MachineLearningHow","accessed":{"date-parts":[["2021",8,14]]},"citation-key":"MachineLearningHow","title":"machine learning - how to intuitively explain what a kernel is?","type":"document","URL":"https://stats.stackexchange.com/questions/152897/how-to-intuitively-explain-what-a-kernel-is"},
  {"id":"maEra1bitLLMs2024","abstract":"Recent research, such as BitNet [WMD+23], is paving the way for a new era of 1bit Large Language Models (LLMs). In this work, we introduce a 1-bit LLM variant, namely BitNet b1.58, in which every single parameter (or weight) of the LLM is ternary {-1, 0, 1}. It matches the full-precision (i.e., FP16 or BF16) Transformer LLM with the same model size and training tokens in terms of both perplexity and end-task performance, while being significantly more cost-effective in terms of latency, memory, throughput, and energy consumption. More profoundly, the 1.58-bit LLM defines a new scaling law and recipe for training new generations of LLMs that are both high-performance and cost-effective. Furthermore, it enables a new computation paradigm and opens the door for designing specific hardware optimized for 1-bit LLMs.","accessed":{"date-parts":[["2024",11,28]]},"author":[{"family":"Ma","given":"Shuming"},{"family":"Wang","given":"Hongyu"},{"family":"Ma","given":"Lingxiao"},{"family":"Wang","given":"Lei"},{"family":"Wang","given":"Wenhui"},{"family":"Huang","given":"Shaohan"},{"family":"Dong","given":"Li"},{"family":"Wang","given":"Ruiping"},{"family":"Xue","given":"Jilong"},{"family":"Wei","given":"Furu"}],"citation-key":"maEra1bitLLMs2024","DOI":"10.48550/arXiv.2402.17764","issued":{"date-parts":[["2024",2,27]]},"language":"en","number":"arXiv:2402.17764","publisher":"arXiv","source":"arXiv.org","title":"The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits","title-short":"The Era of 1-bit LLMs","type":"article","URL":"http://arxiv.org/abs/2402.17764"},
  {"id":"malininUncertaintyGradientBoosting2021","author":[{"family":"Malinin","given":"Andrey"},{"family":"Prokhorenkova","given":"Liudmila"},{"family":"Ustimenko","given":"Aleksei"}],"citation-key":"malininUncertaintyGradientBoosting2021","issued":{"date-parts":[["2021"]]},"title":"Uncertainty in gradient boosting via ensembles","type":"document"},
  {"id":"mallapragadaSemiBoostBoostingSemiSupervised2009","accessed":{"date-parts":[["2023",4,23]]},"author":[{"family":"Mallapragada","given":"P.K."},{"literal":"Rong Jin"},{"family":"Jain","given":"A.K."},{"literal":"Yi Liu"}],"citation-key":"mallapragadaSemiBoostBoostingSemiSupervised2009","container-title":"IEEE Transactions on Pattern Analysis and Machine Intelligence","DOI":"10.1109/TPAMI.2008.235","issue":"11","issued":{"date-parts":[["2009"]]},"page":"2000–2014","title":"SemiBoost: boosting for semi-supervised learning","type":"article-journal","volume":"31"},
  {"id":"Manaster_1982","author":[{"family":"Manaster","given":"Steven"},{"family":"Rendleman","given":"Richard J."}],"citation-key":"Manaster_1982","container-title":"Journal of Finance","DOI":"10.1111/j.1540-6261.1982.tb03597.x","issued":{"date-parts":[["1982"]]},"PMID":"null","title":"Option prices as predictors of equilibrium stock prices","type":"article-journal"},
  {"id":"mankowitzFasterSortingAlgorithms","author":[{"family":"Mankowitz","given":"Daniel J"}],"citation-key":"mankowitzFasterSortingAlgorithms","title":"Faster sorting algorithms discovered using deep reinforcement learning","type":"article-journal"},
  {"id":"maraisDeepLearningTabular","author":[{"family":"Marais","given":"Jan André"}],"citation-key":"maraisDeepLearningTabular","page":"144","title":"Deep learning for tabular data: an exploratory study","type":"article-journal"},
  {"id":"martinEconometricModellingTime2012","accessed":{"date-parts":[["2020",12,12]]},"author":[{"family":"Martin","given":"Vance"},{"family":"Hurn","given":"Stan"},{"family":"Harris","given":"David"}],"citation-key":"martinEconometricModellingTime2012","DOI":"10.1017/CBO9781139043205","event-place":"Cambridge","issued":{"date-parts":[["2012"]]},"publisher":"Cambridge University Press","publisher-place":"Cambridge","title":"Econometric modelling with time series: specification, estimation and testing","type":"book"},
  {"id":"martinMarketEfficiencyAge2019","accessed":{"date-parts":[["2021",11,3]]},"author":[{"family":"Martin","given":"Ian"},{"family":"Nagel","given":"Stefan"}],"citation-key":"martinMarketEfficiencyAge2019","DOI":"10.3386/w26586","event-place":"Cambridge, MA","issued":{"date-parts":[["2019"]]},"number":"w26586","page":"w26586","publisher":"National Bureau of Economic Research","publisher-place":"Cambridge, MA","title":"Market efficiency in the age of big data","type":"report"},
  {"id":"martinWhatExpectedReturn2016","author":[{"family":"Martin","given":"Ian"}],"citation-key":"martinWhatExpectedReturn2016","container-title":"SSRN Electronic Journal","DOI":"10.2139/ssrn.2772101","issued":{"date-parts":[["2016"]]},"title":"What is the expected return on the market?","type":"article-journal"},
  {"id":"martinWhatExpectedReturn2019","author":[{"family":"Martin","given":"Ian"},{"family":"Wagner","given":"Christian"}],"citation-key":"martinWhatExpectedReturn2019","container-title":"The Journal of Finance","DOI":"10.1111/jofi.12778","issue":"4","issued":{"date-parts":[["2019"]]},"page":"1887–1929","title":"What is the expected return on a stock?","type":"article-journal","volume":"74"},
  {"id":"matthewsComparisonPredictedObserved1975","accessed":{"date-parts":[["2023",3,12]]},"author":[{"family":"Matthews","given":"B.W."}],"citation-key":"matthewsComparisonPredictedObserved1975","container-title":"Biochimica et Biophysica Acta (BBA) - Protein Structure","DOI":"10.1016/0005-2795(75)90109-9","issue":"2","issued":{"date-parts":[["1975"]]},"page":"442–451","title":"Comparison of the predicted and observed secondary structure of T4 phage lysozyme","type":"article-journal","volume":"405"},
  {"id":"mayhewCompetitionMarketStructure2002","accessed":{"date-parts":[["2023",6,22]]},"author":[{"family":"Mayhew","given":"Stewart"}],"citation-key":"mayhewCompetitionMarketStructure2002","container-title":"The Journal of Finance","DOI":"10.1111/1540-6261.00447","issue":"2","issued":{"date-parts":[["2002"]]},"page":"931–958","title":"Competition, Market Structure, and Bid-Ask Spreads in Stock Option Markets","type":"article-journal","volume":"57"},
  {"id":"mccoyBERTsFeatherNot2020","accessed":{"date-parts":[["2023",7,4]]},"author":[{"family":"McCoy","given":"R. Thomas"},{"family":"Min","given":"Junghyun"},{"family":"Linzen","given":"Tal"}],"citation-key":"mccoyBERTsFeatherNot2020","issued":{"date-parts":[["2020"]]},"title":"BERTs of a feather do not generalize together: Large variability in generalization across models with similar test set performance","type":"document","URL":"http://arxiv.org/abs/1911.02969"},
  {"id":"mcnemarNoteSamplingError1947","accessed":{"date-parts":[["2023",6,11]]},"author":[{"family":"McNemar","given":"Quinn"}],"citation-key":"mcnemarNoteSamplingError1947","container-title":"Psychometrika","DOI":"10.1007/BF02295996","issue":"2","issued":{"date-parts":[["1947"]]},"page":"153–157","title":"Note on the sampling error of the difference between correlated proportions or percentages","type":"article-journal","volume":"12"},
  {"id":"measeBoostedClassificationTrees","author":[{"family":"Mease","given":"David"},{"family":"Wyner","given":"Abraham J"},{"family":"Buja","given":"Andreas"}],"citation-key":"measeBoostedClassificationTrees","page":"31","title":"Boosted classification trees and class probability/quantile estimation","type":"article-journal"},
  {"id":"melisStateArtEvaluation2017","accessed":{"date-parts":[["2022",10,26]]},"author":[{"family":"Melis","given":"Gábor"},{"family":"Dyer","given":"Chris"},{"family":"Blunsom","given":"Phil"}],"citation-key":"melisStateArtEvaluation2017","issued":{"date-parts":[["2017"]]},"title":"On the state of the art of evaluation in neural language models","type":"document","URL":"http://arxiv.org/abs/1707.05589"},
  {"id":"merchantWhatHappensBERT2020","author":[{"family":"Merchant","given":"Amil"},{"family":"Rahimtoroghi","given":"Elahe"},{"family":"Pavlick","given":"Ellie"},{"family":"Tenney","given":"Ian"}],"citation-key":"merchantWhatHappensBERT2020","container-title":"Proceedings of the third BlackboxNLP workshop on analyzing and interpreting neural networks for NLP","DOI":"10.18653/v1/2020.blackboxnlp-1.4","event-place":"Online","issued":{"date-parts":[["2020"]]},"page":"33–44","publisher":"Association for Computational Linguistics","publisher-place":"Online","title":"What happens to BERT embeddings during fine-tuning?","type":"paper-conference"},
  {"id":"meyesAblationStudiesArtificial2019","accessed":{"date-parts":[["2022",12,15]]},"author":[{"family":"Meyes","given":"Richard"},{"family":"Lu","given":"Melanie"},{"family":"Puiseau","given":"Constantin Waubert","non-dropping-particle":"de"},{"family":"Meisen","given":"Tobias"}],"citation-key":"meyesAblationStudiesArtificial2019","issued":{"date-parts":[["2019"]]},"title":"Ablation studies in artificial neural networks","type":"document","URL":"http://arxiv.org/abs/1901.08644"},
  {"id":"michelAreSixteenHeads2019","author":[{"family":"Michel","given":"Paul"},{"family":"Levy","given":"Omer"},{"family":"Neubig","given":"Graham"}],"citation-key":"michelAreSixteenHeads2019","container-title":"Advances in Neural Information Processing Systems","event-place":"Vancouver, Canada","issued":{"date-parts":[["2019"]]},"page":"14014–14024","publisher":"Curran Associates, Inc.","publisher-place":"Vancouver, Canada","title":"Are sixteen heads really better than one?","type":"paper-conference","volume":"32"},
  {"id":"mikolovLinguisticRegularitiesContinuous2013","author":[{"family":"Mikolov","given":"Tomas"},{"family":"Yih","given":"Wen-tau"},{"family":"Zweig","given":"Geoffrey"}],"citation-key":"mikolovLinguisticRegularitiesContinuous2013","container-title":"Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies","event-place":"Atlanta, GE, USA","issued":{"date-parts":[["2013"]]},"page":"746–751","publisher":"Association for Computational Linguistics","publisher-place":"Atlanta, GE, USA","title":"Linguistic regularities in continuous space word representations","type":"paper-conference"},
  {"id":"millerAddingErrorBars2024","abstract":"Evaluations are critical for understanding the capabilities of large language models (LLMs). Fundamentally, evaluations are experiments; but the literature on evaluations has largely ignored the literature from other sciences on experiment analysis and planning. This article shows researchers with some training in statistics how to think about and analyze data from language model evaluations. Conceptualizing evaluation questions as having been drawn from an unseen super-population, we present formulas for analyzing evaluation data, measuring differences between two models, and planning an evaluation experiment. We make a number of specific recommendations for running language model evaluations and reporting experiment results in a way that minimizes statistical noise and maximizes informativeness.","accessed":{"date-parts":[["2025",11,17]]},"author":[{"family":"Miller","given":"Evan"}],"citation-key":"millerAddingErrorBars2024","DOI":"10.48550/arXiv.2411.00640","issued":{"date-parts":[["2024",11,1]]},"language":"en","number":"arXiv:2411.00640","publisher":"arXiv","source":"arXiv.org","title":"Adding Error Bars to Evals: A Statistical Approach to Language Model Evaluations","title-short":"Adding Error Bars to Evals","type":"article","URL":"http://arxiv.org/abs/2411.00640"},
  {"id":"mirzaeiHowUseDeepLearning2019","accessed":{"date-parts":[["2021",11,5]]},"author":[{"family":"Mirzaei","given":"Ali"}],"citation-key":"mirzaeiHowUseDeepLearning2019","issued":{"date-parts":[["2019"]]},"title":"How to use deep-learning for feature-selection, python, keras","type":"document","URL":"https://medium.com/@a.mirzaei69/how-to-use-deep-learning-for-feature-selection-python-keras-24a68bef1e33"},
  {"id":"mockusApplicationBayesianApproach1994","author":[{"family":"Mockus","given":"Jonas"}],"citation-key":"mockusApplicationBayesianApproach1994","container-title":"Journal of Global Optimization","DOI":"10.1007/BF01099263","issue":"4","issued":{"date-parts":[["1994"]]},"page":"347–365","title":"Application of bayesian approach to numerical methods of global and stochastic optimization","type":"article-journal","volume":"4"},
  {"id":"modelerSHAPNotAll2023","accessed":{"date-parts":[["2023",3,26]]},"author":[{"family":"Modeler","given":"Mindful"}],"citation-key":"modelerSHAPNotAll2023","issued":{"date-parts":[["2023"]]},"title":"SHAP is not all you need","type":"Substack newsletter","URL":"https://mindfulmodeler.substack.com/p/shap-is-not-all-you-need"},
  {"id":"mogharStockMarketPrediction2020","accessed":{"date-parts":[["2022",7,12]]},"author":[{"family":"Moghar","given":"Adil"},{"family":"Hamiche","given":"Mhamed"}],"citation-key":"mogharStockMarketPrediction2020","container-title":"Procedia Computer Science","DOI":"10.1016/j.procs.2020.03.049","issued":{"date-parts":[["2020"]]},"page":"1168–1173","title":"Stock market prediction using LSTM recurrent neural network","type":"article-journal","volume":"170"},
  {"id":"molnarRelatingPartialDependence2021","accessed":{"date-parts":[["2023",2,8]]},"author":[{"family":"Molnar","given":"Christoph"},{"family":"Freiesleben","given":"Timo"},{"family":"König","given":"Gunnar"},{"family":"Casalicchio","given":"Giuseppe"},{"family":"Wright","given":"Marvin N."},{"family":"Bischl","given":"Bernd"}],"citation-key":"molnarRelatingPartialDependence2021","issued":{"date-parts":[["2021"]]},"title":"Relating the partial dependence plot and permutation feature importance to the data generating process","type":"document","URL":"http://arxiv.org/abs/2109.01433"},
  {"id":"muravyevOptionsTradingCosts2020","author":[{"family":"Muravyev","given":"Dmitriy"},{"family":"Pearson","given":"Neil D"}],"citation-key":"muravyevOptionsTradingCosts2020","container-title":"The Review of Financial Studies","DOI":"10.1093/rfs/hhaa010","editor":[{"family":"Van Nieuwerburgh","given":"Stijn"}],"issue":"11","issued":{"date-parts":[["2020"]]},"page":"4973–5014","title":"Options trading costs are lower than you think","type":"article-journal","volume":"33"},
  {"id":"muravyevOrderFlowExpected2016","author":[{"family":"Muravyev","given":"Dmitriy"}],"citation-key":"muravyevOrderFlowExpected2016","container-title":"The Journal of Finance","DOI":"10.1111/jofi.12380","issue":"2","issued":{"date-parts":[["2016"]]},"page":"673–708","title":"Order flow and expected option returns: order flow and expected option returns","type":"article-journal","volume":"71"},
  {"id":"muravyevTherePriceDiscovery2013","accessed":{"date-parts":[["2023",6,26]]},"author":[{"family":"Muravyev","given":"Dmitriy"},{"family":"Pearson","given":"Neil D."},{"family":"Paul Broussard","given":"John"}],"citation-key":"muravyevTherePriceDiscovery2013","container-title":"Journal of Financial Economics","DOI":"10.1016/j.jfineco.2012.09.003","issue":"2","issued":{"date-parts":[["2013"]]},"page":"259–283","title":"Is there price discovery in equity options?","type":"article-journal","volume":"107"},
  {"id":"nabiNovelApproachStock2020","accessed":{"date-parts":[["2022",5,6]]},"author":[{"family":"Nabi","given":"Rebwar M."},{"family":"Ab. M. Saeed","given":"Soran"},{"family":"Harron","given":"Habibollah"}],"citation-key":"nabiNovelApproachStock2020","container-title":"Kurdistan Journal of Applied Research","DOI":"10.24017/science.2020.1.3","issue":"1","issued":{"date-parts":[["2020"]]},"page":"28–48","title":"A novel approach for stock price prediction using gradient boosting machine with feature engineering (GBM-wFE)","type":"article-journal","volume":"5"},
  {"id":"nagelMachineLearningAsset2021","author":[{"family":"Nagel","given":"Stefan"}],"citation-key":"nagelMachineLearningAsset2021","issued":{"date-parts":[["2021"]]},"title":"Machine learning in asset pricing","type":"book"},
  {"id":"narangTransformerModificationsTransfer2021","author":[{"family":"Narang","given":"Sharan"},{"family":"Chung","given":"Hyung Won"},{"family":"Tay","given":"Yi"},{"family":"Fedus","given":"William"},{"family":"Fevry","given":"Thibault"},{"family":"Matena","given":"Michael"},{"family":"Malkan","given":"Karishma"},{"family":"Fiedel","given":"Noah"},{"family":"Shazeer","given":"Noam"},{"family":"Lan","given":"Zhenzhong"},{"family":"Zhou","given":"Yanqi"},{"family":"Li","given":"Wei"},{"family":"Ding","given":"Nan"},{"family":"Marcus","given":"Jake"},{"family":"Roberts","given":"Adam"},{"family":"Raffel","given":"Colin"}],"citation-key":"narangTransformerModificationsTransfer2021","issued":{"date-parts":[["2021"]]},"title":"Do transformer modifications transfer across implementations and applications?","type":"document"},
  {"id":"nasdaqincFrequentlyAskedQuestions2017","accessed":{"date-parts":[["2023",3,3]]},"author":[{"literal":"NASDAQ Inc."}],"citation-key":"nasdaqincFrequentlyAskedQuestions2017","issued":{"date-parts":[["2017"]]},"title":"Frequently asked questions ise open/close trade profile gemx open/close trade profile","type":"document","URL":"https://www.nasdaqtrader.com/content/ProductsServices/DATAPRODUCTS/ISE/ISE-GEMX%20Consolidated%20Trade%20Profile%20FAQs%20v2.pdF"},
  {"id":"nassarSmolDoclingUltracompactVisionlanguage2025","abstract":"We introduce SmolDocling, an ultra-compact vision-language model targeting end-to-end document conversion. Our model comprehensively processes entire pages by generating DocTags, a new universal markup format that captures all page elements in their full context with location. Unlike existing approaches that rely on large foundational models, or ensemble solutions that rely on handcrafted pipelines of multiple specialized models, SmolDocling offers an end-to-end conversion for accurately capturing content, structure and spatial location of document elements in a 256M parameters vision-language model. SmolDocling exhibits robust performance in correctly reproducing document features such as code listings, tables, equations, charts, lists, and more across a diverse range of document types including business documents, academic papers, technical reports, patents, and forms — significantly extending beyond the commonly observed focus on scientific papers. Additionally, we contribute novel publicly sourced datasets for charts, tables, equations, and code recognition. Experimental results demonstrate that SmolDocling competes with other Vision Language Models that are up to 27 times larger in size, while reducing computational requirements substantially. The model is currently available, datasets will be publicly available soon.","accessed":{"date-parts":[["2025",4,13]]},"author":[{"family":"Nassar","given":"Ahmed"},{"family":"Marafioti","given":"Andres"},{"family":"Omenetti","given":"Matteo"},{"family":"Lysak","given":"Maksym"},{"family":"Livathinos","given":"Nikolaos"},{"family":"Auer","given":"Christoph"},{"family":"Morin","given":"Lucas"},{"family":"Lima","given":"Rafael Teixeira","dropping-particle":"de"},{"family":"Kim","given":"Yusik"},{"family":"Gurbuz","given":"A. Said"},{"family":"Dolfi","given":"Michele"},{"family":"Farré","given":"Miquel"},{"family":"Staar","given":"Peter W. J."}],"citation-key":"nassarSmolDoclingUltracompactVisionlanguage2025","DOI":"10.48550/arXiv.2503.11576","issued":{"date-parts":[["2025",3,14]]},"language":"en","number":"arXiv:2503.11576","publisher":"arXiv","source":"arXiv.org","title":"SmolDocling: An ultra-compact vision-language model for end-to-end multi-modal document conversion","title-short":"SmolDocling","type":"article","URL":"http://arxiv.org/abs/2503.11576"},
  {"id":"nelsonMachineLearningStrategic2023","accessed":{"date-parts":[["2022",12,29]]},"author":[{"family":"Nelson","given":"Christopher"}],"citation-key":"nelsonMachineLearningStrategic2023","collection-title":"Advanced Sciences and Technologies for Security Applications","container-title":"Methods of Strategic Trade Analysis: Data-Driven Approaches to Detect Illicit Dual-Use Trade","DOI":"10.1007/978-3-031-20036-6\\_10","editor":[{"family":"Nelson","given":"Christopher"}],"event-place":"Cham","issued":{"date-parts":[["2023"]]},"page":"113–146","publisher":"Springer International Publishing","publisher-place":"Cham","title":"Machine learning for strategic trade analysis","type":"chapter"},
  {"id":"NetflixUpdateTry","accessed":{"date-parts":[["2021",4,20]]},"citation-key":"NetflixUpdateTry","title":"Netflix update: try this at home","type":"document","URL":"https://sifter.org/~simon/journal/20061211.html"},
  {"id":"neumannMotivatingSupportingUser2007","accessed":{"date-parts":[["2021",3,21]]},"author":[{"family":"Neumann","given":"Andreas W."}],"citation-key":"neumannMotivatingSupportingUser2007","container-title":"Research and Advanced Technology for Digital Libraries","DOI":"10.1007/978-3-540-74851-9\\_36","editor":[{"family":"Kovács","given":"László"},{"family":"Fuhr","given":"Norbert"},{"family":"Meghini","given":"Carlo"}],"event-place":"Berlin, Heidelberg","issued":{"date-parts":[["2007"]]},"page":"428–439","publisher":"Springer Berlin Heidelberg","publisher-place":"Berlin, Heidelberg","title":"Motivating and supporting user interaction with recommender systems","type":"chapter","volume":"4675"},
  {"id":"NEURIPS2024_2ad2dffb","author":[{"family":"Hans","given":"Abhimanyu"},{"family":"Wen","given":"Yuxin"},{"family":"Jain","given":"Neel"},{"family":"Kirchenbauer","given":"John"},{"family":"Kazemi","given":"Hamid"},{"family":"Singhania","given":"Prajwal"},{"family":"Singh","given":"Siddharth"},{"family":"Somepalli","given":"Gowthami"},{"family":"Geiping","given":"Jonas"},{"family":"Bhatele","given":"Abhinav"},{"family":"Goldstein","given":"Tom"}],"citation-key":"NEURIPS2024_2ad2dffb","container-title":"Advances in neural information processing systems","DOI":"10.52202/079017-0757","editor":[{"family":"Globerson","given":"A."},{"family":"Mackey","given":"L."},{"family":"Belgrave","given":"D."},{"family":"Fan","given":"A."},{"family":"Paquet","given":"U."},{"family":"Tomczak","given":"J."},{"family":"Zhang","given":"C."}],"issued":{"date-parts":[["2024"]]},"page":"24022–24045","publisher":"Curran Associates, Inc.","title":"Be like a goldfish, dont memorize! Mitigating memorization in generative llms","type":"paper-conference","URL":"https://proceedings.neurips.cc/paper_files/paper/2024/file/2ad2dffba5079687651226ac8752df97-Paper-Conference.pdf","volume":"37"},
  {"id":"ngFeatureSelectionVs2004","accessed":{"date-parts":[["2023",1,28]]},"author":[{"family":"Ng","given":"Andrew Y."}],"citation-key":"ngFeatureSelectionVs2004","container-title":"Twenty-first international conference on Machine learning - ICML '04","DOI":"10.1145/1015330.1015435","event-place":"Banff, Alberta, Canada","issued":{"date-parts":[["2004"]]},"page":"78","publisher":"ACM Press","publisher-place":"Banff, Alberta, Canada","title":"Feature selection, $L_1$ vs. $L_2$ regularization, and rotational invariance","type":"paper-conference"},
  {"id":"nguyenTransformersTearsImproving2019","accessed":{"date-parts":[["2023",1,17]]},"author":[{"family":"Nguyen","given":"Toan Q."},{"family":"Salazar","given":"Julian"}],"citation-key":"nguyenTransformersTearsImproving2019","DOI":"10.5281/zenodo.3525484","issued":{"date-parts":[["2019"]]},"title":"Transformers without tears: improving the normalization of self-attention","type":"document"},
  {"id":"niDoesOptionTrading2021","accessed":{"date-parts":[["2023",6,23]]},"author":[{"family":"Ni","given":"Sophie X"},{"family":"Pearson","given":"Neil D"},{"family":"Poteshman","given":"Allen M"},{"family":"White","given":"Joshua"}],"citation-key":"niDoesOptionTrading2021","container-title":"The Review of Financial Studies","DOI":"10.1093/rfs/hhaa082","editor":[{"family":"Karolyi","given":"Andrew"}],"issue":"4","issued":{"date-parts":[["2021"]]},"page":"1952–1986","title":"Does Option Trading Have a Pervasive Impact on Underlying Stock Prices?","type":"article-journal","volume":"34"},
  {"id":"ningShapleyVariableImportance2022","accessed":{"date-parts":[["2023",5,22]]},"author":[{"family":"Ning","given":"Yilin"},{"family":"Ong","given":"Marcus Eng Hock"},{"family":"Chakraborty","given":"Bibhas"},{"family":"Goldstein","given":"Benjamin Alan"},{"family":"Ting","given":"Daniel Shu Wei"},{"family":"Vaughan","given":"Roger"},{"family":"Liu","given":"Nan"}],"citation-key":"ningShapleyVariableImportance2022","container-title":"Patterns","DOI":"10.1016/j.patter.2022.100452","issue":"4","issued":{"date-parts":[["2022"]]},"page":"100452","title":"Shapley variable importance cloud for interpretable machine learning","type":"article-journal","volume":"3"},
  {"id":"nisbetHandbookStatisticalAnalysis2009","author":[{"family":"Nisbet","given":"Robert"},{"family":"Elder","given":"John F."},{"family":"Miner","given":"Gary"}],"citation-key":"nisbetHandbookStatisticalAnalysis2009","event-place":"Amsterdam ; Boston","issued":{"date-parts":[["2009"]]},"publisher":"Academic Press/Elsevier","publisher-place":"Amsterdam ; Boston","title":"Handbook of statistical analysis and data mining applications","type":"book"},
  {"id":"niVolatilityInformationTrading2008","accessed":{"date-parts":[["2023",6,20]]},"author":[{"family":"Ni","given":"Sophie X."},{"family":"Pan","given":"Jun"},{"family":"Poteshman","given":"Allen M."}],"citation-key":"niVolatilityInformationTrading2008","container-title":"The Journal of Finance","DOI":"10.1111/j.1540-6261.2008.01352.x","issue":"3","issued":{"date-parts":[["2008"]]},"page":"1059–1091","title":"Volatility Information Trading in the Option Market","type":"article-journal","volume":"63"},
  {"id":"noriAccuracyInterpretabilityDifferential2021","accessed":{"date-parts":[["2022",12,3]]},"author":[{"family":"Nori","given":"Harsha"},{"family":"Caruana","given":"Rich"},{"family":"Bu","given":"Zhiqi"},{"family":"Shen","given":"Judy Hanwen"},{"family":"Kulkarni","given":"Janardhan"}],"citation-key":"noriAccuracyInterpretabilityDifferential2021","issued":{"date-parts":[["2021"]]},"title":"Accuracy, interpretability, and differential privacy via explainable boosting","type":"document","URL":"http://arxiv.org/abs/2106.09680"},
  {"id":"nothmanStopWordLists2018","accessed":{"date-parts":[["2021",4,24]]},"author":[{"family":"Nothman","given":"Joel"},{"family":"Qin","given":"Hanmin"},{"family":"Yurchak","given":"Roman"}],"citation-key":"nothmanStopWordLists2018","container-title":"Proceedings of Workshop for NLP Open Source Software (NLP-OSS)","DOI":"10.18653/v1/W18-2502","event-place":"Melbourne, Australia","issued":{"date-parts":[["2018"]]},"page":"7–12","publisher":"Association for Computational Linguistics","publisher-place":"Melbourne, Australia","title":"Stop word lists in free open-source software packages","type":"paper-conference"},
  {"id":"nowakAccuracyTradeClassification2020","accessed":{"date-parts":[["2023",2,1]]},"author":[{"family":"Nowak","given":"Sabina"}],"citation-key":"nowakAccuracyTradeClassification2020","container-title":"Contemporary Trends and Challenges in Finance","DOI":"10.1007/978-3-030-43078-8\\_6","editor":[{"family":"Jajuga","given":"Krzysztof"},{"family":"Locarek-Junge","given":"Hermann"},{"family":"Orlowski","given":"Lucjan T."},{"family":"Staehr","given":"Karsten"}],"event-place":"Cham","issued":{"date-parts":[["2020"]]},"page":"65–75","publisher":"Springer International Publishing","publisher-place":"Cham","title":"The accuracy of trade classification rules for the selected CEE stock exchanges","type":"chapter"},
  {"id":"ntakourisTimeSeriesTransformer2021","accessed":{"date-parts":[["2021",11,6]]},"author":[{"family":"Ntakouris","given":"Theodoros"}],"citation-key":"ntakourisTimeSeriesTransformer2021","issued":{"date-parts":[["2021"]]},"title":"The time series transformer","type":"document","URL":"https://towardsdatascience.com/the-time-series-transformer-2a521a0efad3"},
  {"id":"Ochama","accessed":{"date-parts":[["2023",2,17]]},"citation-key":"Ochama","title":"Ochama","type":"document","URL":"https://www.ochama.com/cart/"},
  {"id":"odders-whiteOccurrenceConsequencesInaccurate2000","author":[{"family":"Odders-White","given":"Elizabeth R"}],"citation-key":"odders-whiteOccurrenceConsequencesInaccurate2000","container-title":"Journal of Financial Markets","DOI":"10.1016/S1386-4181(00)00006-9","issue":"3","issued":{"date-parts":[["2000"]]},"page":"259–286","title":"On the occurrence and consequences of inaccurate trade classification","type":"article-journal","volume":"3"},
  {"id":"olbrysEvaluatingTradeSide2018","accessed":{"date-parts":[["2022",10,3]]},"author":[{"family":"Olbrys","given":"Joanna"},{"family":"Mursztyn","given":"Michał"}],"citation-key":"olbrysEvaluatingTradeSide2018","DOI":"10.5445/KSP/1000085951/20","issued":{"date-parts":[["2018"]]},"publisher":"Karlsruhe","title":"Evaluating trade side classification algorithms using intraday data from the warsaw stock exchange","type":"article-journal"},
  {"id":"oliverRealisticEvaluationDeep2019","accessed":{"date-parts":[["2022",10,30]]},"author":[{"family":"Oliver","given":"Avital"},{"family":"Odena","given":"Augustus"},{"family":"Raffel","given":"Colin"},{"family":"Cubuk","given":"Ekin D."},{"family":"Goodfellow","given":"Ian J."}],"citation-key":"oliverRealisticEvaluationDeep2019","issued":{"date-parts":[["2019"]]},"title":"Realistic evaluation of deep semi-supervised learning algorithms","type":"document","URL":"http://arxiv.org/abs/1804.09170"},
  {"id":"OptionTrades","accessed":{"date-parts":[["2022",11,8]]},"citation-key":"OptionTrades","title":"Option trades","type":"document","URL":"https://datashop.cboe.com/option-trades"},
  {"id":"owenHyperparameterTuningPython2022","author":[{"family":"Owen","given":"Louis"}],"citation-key":"owenHyperparameterTuningPython2022","event-place":"S.l.","issued":{"date-parts":[["2022"]]},"publisher":"PACKT PUBLISHING LIMITED","publisher-place":"S.l.","title":"Hyperparameter tuning with python","type":"book"},
  {"id":"panayidesBulkVolumeClassification2019","author":[{"family":"Panayides","given":"Marios A."},{"family":"Shohfi","given":"Thomas D."},{"family":"Smith","given":"Jared D."}],"citation-key":"panayidesBulkVolumeClassification2019","container-title":"Journal of Banking & Finance","DOI":"10.1016/j.jbankfin.2019.04.001","issued":{"date-parts":[["2019"]]},"page":"113–129","title":"Bulk volume classification and information detection","type":"article-journal","volume":"103"},
  {"id":"panayidesComparingTradeFlow2014","author":[{"family":"Panayides","given":"Marios A."},{"family":"Shohfi","given":"Thomas"},{"family":"Smith","given":"Jared D."}],"citation-key":"panayidesComparingTradeFlow2014","container-title":"SSRN Electronic Journal","DOI":"10.2139/ssrn.2503628","issued":{"date-parts":[["2014"]]},"title":"Comparing trade flow classification algorithms in the electronic era: the good, the bad, and the uninformative","type":"article-journal"},
  {"id":"panInformationOptionVolume2006","author":[{"family":"Pan","given":"Jun"},{"family":"Poteshman","given":"Allen M."}],"citation-key":"panInformationOptionVolume2006","container-title":"Review of Financial Studies","DOI":"10.1093/rfs/hhj024","issue":"3","issued":{"date-parts":[["2006"]]},"page":"871–908","title":"The information in option volume for future stock prices","type":"article-journal","volume":"19"},
  {"id":"parmarImageTransformer2018","author":[{"family":"Parmar","given":"Niki"},{"family":"Vaswani","given":"Ashish"},{"family":"Uszkoreit","given":"Jakob"},{"family":"Kaiser","given":"Łukasz"},{"family":"Shazeer","given":"Noam"},{"family":"Ku","given":"Alexander"},{"family":"Tran","given":"Dustin"}],"citation-key":"parmarImageTransformer2018","container-title":"Proceedings of the 35th International Conference on Machine Learning","issued":{"date-parts":[["2018"]]},"page":"4055–4064","publisher":"PMLR","title":"Image transformer","type":"paper-conference"},
  {"id":"paszkePyTorchImperativeStyle2019","author":[{"family":"Paszke","given":"Adam"},{"family":"Gross","given":"Sam"},{"family":"Massa","given":"Francisco"},{"family":"Lerer","given":"Adam"},{"family":"Bradbury","given":"James"},{"family":"Chanan","given":"Gregory"},{"family":"Killeen","given":"Trevor"},{"family":"Lin","given":"Zeming"},{"family":"Gimelshein","given":"Natalia"},{"family":"Antiga","given":"Luca"},{"family":"Desmaison","given":"Alban"},{"family":"Kopf","given":"Andreas"},{"family":"Yang","given":"Edward"},{"family":"DeVito","given":"Zachary"},{"family":"Raison","given":"Martin"},{"family":"Tejani","given":"Alykhan"},{"family":"Chilamkurthy","given":"Sasank"},{"family":"Steiner","given":"Benoit"},{"family":"Fang","given":"Lu"},{"family":"Bai","given":"Junjie"},{"family":"Chintala","given":"Soumith"}],"citation-key":"paszkePyTorchImperativeStyle2019","collection-title":"NeurIPS 2019","container-title":"Proceedings of the 33rd International Conference on Neural Information Processing Systems","event-place":"Red Hook, NY","issued":{"date-parts":[["2019"]]},"page":"8024–8035","publisher":"Curran Associates, Inc.","publisher-place":"Red Hook, NY","title":"PyTorch: an imperative style, high-performance deep learning library","type":"paper-conference","volume":"32"},
  {"id":"patrignaniWhyShouldAnyone2021","accessed":{"date-parts":[["2022",12,21]]},"author":[{"family":"Patrignani","given":"Marco"}],"citation-key":"patrignaniWhyShouldAnyone2021","issued":{"date-parts":[["2021"]]},"title":"Why should anyone use colours? or, syntax highlighting beyond code snippets","type":"document"},
  {"id":"pedregosaScikitlearnMachineLearning2018","accessed":{"date-parts":[["2022",10,13]]},"author":[{"family":"Pedregosa","given":"Fabian"},{"family":"Varoquaux","given":"Gaël"},{"family":"Gramfort","given":"Alexandre"},{"family":"Michel","given":"Vincent"},{"family":"Thirion","given":"Bertrand"},{"family":"Grisel","given":"Olivier"},{"family":"Blondel","given":"Mathieu"},{"family":"Müller","given":"Andreas"},{"family":"Nothman","given":"Joel"},{"family":"Louppe","given":"Gilles"},{"family":"Prettenhofer","given":"Peter"},{"family":"Weiss","given":"Ron"},{"family":"Dubourg","given":"Vincent"},{"family":"Vanderplas","given":"Jake"},{"family":"Passos","given":"Alexandre"},{"family":"Cournapeau","given":"David"},{"family":"Brucher","given":"Matthieu"},{"family":"Perrot","given":"Matthieu"},{"family":"Duchesnay","given":"Édouard"}],"citation-key":"pedregosaScikitlearnMachineLearning2018","issued":{"date-parts":[["2018"]]},"title":"Scikit-learn: machine learning in python","type":"document","URL":"http://arxiv.org/abs/1201.0490"},
  {"id":"perez-lebelBenchmarkingMissingvaluesApproaches2022","author":[{"family":"Perez-Lebel","given":"Alexandre"},{"family":"Varoquaux","given":"Gaël"},{"family":"Le Morvan","given":"Marine"},{"family":"Josse","given":"Julie"},{"family":"Poline","given":"Jean-Baptiste"}],"citation-key":"perez-lebelBenchmarkingMissingvaluesApproaches2022","container-title":"GigaScience","DOI":"10.1093/gigascience/giac013","issued":{"date-parts":[["2022"]]},"page":"giac013","title":"Benchmarking missing-values approaches for predictive models on health databases","type":"article-journal","volume":"11"},
  {"id":"perlinPerformanceTickTest2014","author":[{"family":"Perlin","given":"Marcelo"},{"family":"Brooks","given":"Chris"},{"family":"Dufour","given":"Alfonso"}],"citation-key":"perlinPerformanceTickTest2014","container-title":"The Quarterly Review of Economics and Finance","DOI":"10.1016/j.qref.2013.07.009","issue":"1","issued":{"date-parts":[["2014"]]},"page":"42–50","title":"On the performance of the tick test","type":"article-journal","volume":"54"},
  {"id":"petersenMatrixCookbook","author":[{"family":"Petersen","given":"Kaare Brandt"},{"family":"Pedersen","given":"Michael Syskind"}],"citation-key":"petersenMatrixCookbook","page":"72","title":"The matrix cookbook","type":"article-journal"},
  {"id":"petersenPostedEffectiveSpreads1994","accessed":{"date-parts":[["2023",2,24]]},"author":[{"family":"Petersen","given":"Mitchell A."},{"family":"Fialkowski","given":"David"}],"citation-key":"petersenPostedEffectiveSpreads1994","container-title":"Journal of Financial Economics","DOI":"10.1016/0304-405X(94)90034-5","issue":"3","issued":{"date-parts":[["1994"]]},"page":"269–292","title":"Posted versus effective spreads","type":"article-journal","volume":"35"},
  {"id":"petersonEvaluationBiasesExecution2003","author":[{"family":"Peterson","given":"Mark"},{"family":"Sirri","given":"Erik"}],"citation-key":"petersonEvaluationBiasesExecution2003","container-title":"Journal of Financial Markets","DOI":"10.1016/S1386-4181(02)00065-4","issue":"3","issued":{"date-parts":[["2003"]]},"page":"259–280","title":"Evaluation of the biases in execution cost estimation using trade and quote data","type":"article-journal","volume":"6"},
  {"id":"petersTuneNotTune2019","accessed":{"date-parts":[["2023",7,4]]},"author":[{"family":"Peters","given":"Matthew E."},{"family":"Ruder","given":"Sebastian"},{"family":"Smith","given":"Noah A."}],"citation-key":"petersTuneNotTune2019","issued":{"date-parts":[["2019"]]},"title":"To Tune or Not to Tune? Adapting Pretrained Representations to Diverse Tasks","type":"document","URL":"http://arxiv.org/abs/1903.05987"},
  {"id":"petitUNetTransformerSelf2021","accessed":{"date-parts":[["2023",1,20]]},"author":[{"family":"Petit","given":"Olivier"},{"family":"Thome","given":"Nicolas"},{"family":"Rambour","given":"Clement"},{"family":"Themyr","given":"Loic"},{"family":"Collins","given":"Toby"},{"family":"Soler","given":"Luc"}],"citation-key":"petitUNetTransformerSelf2021","container-title":"Machine Learning in Medical Imaging","DOI":"10.1007/978-3-030-87589-3\\_28","editor":[{"family":"Lian","given":"Chunfeng"},{"family":"Cao","given":"Xiaohuan"},{"family":"Rekik","given":"Islem"},{"family":"Xu","given":"Xuanang"},{"family":"Yan","given":"Pingkun"}],"event-place":"Cham","issued":{"date-parts":[["2021"]]},"page":"267–276","publisher":"Springer International Publishing","publisher-place":"Cham","title":"U-net transformer: self and cross attention for medical image segmentation","type":"chapter","volume":"12966"},
  {"id":"phuongFormalAlgorithmsTransformers2022","author":[{"family":"Phuong","given":"Mary"},{"family":"Hutter","given":"Marcus"}],"citation-key":"phuongFormalAlgorithmsTransformers2022","issued":{"date-parts":[["2022"]]},"title":"Formal algorithms for transformers","type":"document"},
  {"id":"Piwowar_2006","author":[{"family":"Piwowar","given":"Michael S."},{"family":"Wei","given":"Li"}],"citation-key":"Piwowar_2006","container-title":"Electronic Markets","DOI":"10.1080/10196780600643803","issued":{"date-parts":[["2006"]]},"title":"The sensitivity of effective spread estimates to trade–quote matching algorithms","type":"article-journal"},
  {"id":"popelTrainingTipsTransformer2018","accessed":{"date-parts":[["2022",12,31]]},"author":[{"family":"Popel","given":"Martin"},{"family":"Bojar","given":"Ondřej"}],"citation-key":"popelTrainingTipsTransformer2018","container-title":"The Prague Bulletin of Mathematical Linguistics","DOI":"10.2478/pralin-2018-0002","issue":"1","issued":{"date-parts":[["2018"]]},"page":"43–70","title":"Training tips for the transformer model","type":"article-journal","volume":"110"},
  {"id":"popovNeuralObliviousDecision2019","accessed":{"date-parts":[["2023",5,15]]},"author":[{"family":"Popov","given":"Sergei"},{"family":"Morozov","given":"Stanislav"},{"family":"Babenko","given":"Artem"}],"citation-key":"popovNeuralObliviousDecision2019","issued":{"date-parts":[["2019"]]},"title":"Neural Oblivious Decision Ensembles for Deep Learning on Tabular Data","type":"document","URL":"http://arxiv.org/abs/1909.06312"},
  {"id":"poppeSensitivityVPINChoice2016","author":[{"family":"Pöppe","given":"Thomas"},{"family":"Moos","given":"Sebastian"},{"family":"Schiereck","given":"Dirk"}],"citation-key":"poppeSensitivityVPINChoice2016","container-title":"Journal of Banking & Finance","DOI":"10.1016/j.jbankfin.2016.08.006","issued":{"date-parts":[["2016"]]},"page":"165–181","title":"The sensitivity of vpin to the choice of trade classification algorithm","type":"article-journal","volume":"73"},
  {"id":"porterProbabilityTradeAsk1992","accessed":{"date-parts":[["2023",2,1]]},"author":[{"family":"Porter","given":"David C."}],"citation-key":"porterProbabilityTradeAsk1992","container-title":"The Journal of Financial and Quantitative Analysis","DOI":"10.2307/2331368","issue":"2","issued":{"date-parts":[["1992"]]},"page":"209","title":"The probability of a trade at the ask: an examination of interday and intraday behavior","type":"article-journal","volume":"27"},
  {"id":"Potters_2003","author":[{"family":"Potters","given":"Marc"},{"family":"Bouchaud","given":"Jean-Philippe"},{"family":"Bouchaud","given":"Jean-Philippe"},{"family":"Bouchaud","given":"Jean-Philippe"}],"citation-key":"Potters_2003","container-title":"Physica A-statistical Mechanics and Its Applications","DOI":"10.1016/s0378-4371(02)01896-4","issued":{"date-parts":[["2003"]]},"PMID":"null","title":"More statistical properties of order books and price impact","type":"article-journal"},
  {"id":"powerGrokkingGeneralizationOverfitting2022","accessed":{"date-parts":[["2023",3,5]]},"author":[{"family":"Power","given":"Alethea"},{"family":"Burda","given":"Yuri"},{"family":"Edwards","given":"Harri"},{"family":"Babuschkin","given":"Igor"},{"family":"Misra","given":"Vedant"}],"citation-key":"powerGrokkingGeneralizationOverfitting2022","issued":{"date-parts":[["2022"]]},"title":"Grokking: generalization beyond overfitting on small algorithmic datasets","type":"document","URL":"http://arxiv.org/abs/2201.02177"},
  {"id":"pressImprovingTransformerModels2020","accessed":{"date-parts":[["2023",1,10]]},"author":[{"family":"Press","given":"Ofir"},{"family":"Smith","given":"Noah A."},{"family":"Levy","given":"Omer"}],"citation-key":"pressImprovingTransformerModels2020","issued":{"date-parts":[["2020"]]},"title":"Improving transformer models by reordering their sublayers","type":"document","URL":"http://arxiv.org/abs/1911.03864"},
  {"id":"prokhorenkovaCatBoostUnbiasedBoosting2018","author":[{"family":"Prokhorenkova","given":"Liudmila"},{"family":"Gusev","given":"Gleb"},{"family":"Vorobev","given":"Aleksandr"},{"family":"Dorogush","given":"Anna Veronika"},{"family":"Gulin","given":"Andrey"}],"citation-key":"prokhorenkovaCatBoostUnbiasedBoosting2018","collection-title":"NeurIPS 2018","container-title":"Advances in Neural Information Processing Systems","editor":[{"literal":"Bengio, Samy"},{"literal":"Wallach, Hanna M."},{"literal":"Grauman, Kristen"},{"literal":"Larochelle, Hugo"},{"literal":"Cesa-Bianchi, Nicolò"},{"literal":"Garnett, Roman"}],"event-place":"Red Hook, NY","issued":{"date-parts":[["2018"]]},"page":"6639–6649","publisher":"Curran Associates Inc.","publisher-place":"Red Hook, NY","title":"CatBoost: unbiased boosting with categorical features","type":"paper-conference","volume":"32"},
  {"id":"prollochsNegationScopeDetection2020","accessed":{"date-parts":[["2023",5,1]]},"author":[{"family":"Pröllochs","given":"Nicolas"},{"family":"Feuerriegel","given":"Stefan"},{"family":"Lutz","given":"Bernhard"},{"family":"Neumann","given":"Dirk"}],"citation-key":"prollochsNegationScopeDetection2020","container-title":"Information Sciences","DOI":"10.1016/j.ins.2020.05.022","issued":{"date-parts":[["2020"]]},"page":"205–221","title":"Negation scope detection for sentiment analysis: a reinforcement learning framework for replicating human interpretations","type":"article-journal","volume":"536"},
  {"id":"provostTreeInductionProbabilityBased","author":[{"family":"Provost","given":"Foster"}],"citation-key":"provostTreeInductionProbabilityBased","page":"17","title":"Tree induction for probability-based ranking","type":"article-journal"},
  {"id":"pulugundlaAttentionbasedNeuralBeamforming2021","accessed":{"date-parts":[["2023",1,16]]},"author":[{"family":"Pulugundla","given":"Bhargav"},{"family":"Gao","given":"Yang"},{"family":"King","given":"Brian"},{"family":"Keskin","given":"Gokce"},{"family":"Mallidi","given":"Harish"},{"family":"Wu","given":"Minhua"},{"family":"Droppo","given":"Jasha"},{"family":"Maas","given":"Roland"}],"citation-key":"pulugundlaAttentionbasedNeuralBeamforming2021","issued":{"date-parts":[["2021"]]},"title":"Attention-based neural beamforming layers for multi-channel speech recognition","type":"document","URL":"http://arxiv.org/abs/2105.05920"},
  {"id":"qinScalingLawsSynthetic2025","abstract":"Large language models (LLMs) achieve strong performance across diverse tasks, driven by high-quality web data used in pre-training. However, recent studies indicate web data is rapidly depleting. Synthetic data emerges as a promising alternative, but it remains unclear whether synthetic datasets exhibit predictable scalability comparable to raw pre-training data. In this work, we systematically investigate scaling laws of synthetic data by introducing SYNTHLLM, a scalable framework that transforms pre-training corpora into diverse, high-quality synthetic datasets. Our approach achieves this by automatically extracting and recombining high-level concepts across multiple documents using a graph algorithm. Key findings from our experiments with SYNTHLLM on math domain include: (1) SYNTHLLM generates synthetic data that reliably adheres to rectified scaling law across various model sizes; (2) Performance gains gradually diminish near 300B tokens; and (3) Larger models approach optimal performance with fewer training tokens. For instance, an 8B model peaks at 1T tokens, while a 3B model requires 4T. Moreover, comparisons with existing synthetic data generation and augmentation methods demonstrate that SYNTHLLM achieves superior performance and scalability. Our findings highlight synthetic data as a scalable and reliable alternative to raw pre-training data, offering a viable path toward continued improvement in model performance.","accessed":{"date-parts":[["2025",11,12]]},"author":[{"family":"Qin","given":"Zeyu"},{"family":"Dong","given":"Qingxiu"},{"family":"Zhang","given":"Xingxing"},{"family":"Dong","given":"Li"},{"family":"Huang","given":"Xiaolong"},{"family":"Yang","given":"Ziyi"},{"family":"Khademi","given":"Mahmoud"},{"family":"Zhang","given":"Dongdong"},{"family":"Awadalla","given":"Hany Hassan"},{"family":"Fung","given":"Yi R."},{"family":"Chen","given":"Weizhu"},{"family":"Cheng","given":"Minhao"},{"family":"Wei","given":"Furu"}],"citation-key":"qinScalingLawsSynthetic2025","DOI":"10.48550/arXiv.2503.19551","issued":{"date-parts":[["2025",10,7]]},"language":"en","number":"arXiv:2503.19551","publisher":"arXiv","source":"arXiv.org","title":"Scaling Laws of Synthetic Data for Language Models","type":"article","URL":"http://arxiv.org/abs/2503.19551"},
  {"id":"radfordImprovingLanguageUnderstanding","author":[{"family":"Radford","given":"Alec"},{"family":"Narasimhan","given":"Karthik"},{"family":"Salimans","given":"Tim"},{"family":"Sutskever","given":"Ilya"}],"citation-key":"radfordImprovingLanguageUnderstanding","title":"Improving language understanding by generative pre-training","type":"article-journal"},
  {"id":"raeScalingLanguageModels2022","author":[{"family":"Rae","given":"Jack W."},{"family":"Borgeaud","given":"Sebastian"},{"family":"Cai","given":"Trevor"},{"family":"Millican","given":"Katie"},{"family":"Hoffmann","given":"Jordan"},{"family":"Song","given":"Francis"},{"family":"Aslanides","given":"John"},{"family":"Henderson","given":"Sarah"},{"family":"Ring","given":"Roman"},{"family":"Young","given":"Susannah"},{"family":"Rutherford","given":"Eliza"},{"family":"Hennigan","given":"Tom"},{"family":"Menick","given":"Jacob"},{"family":"Cassirer","given":"Albin"},{"family":"Powell","given":"Richard"},{"family":"Driessche","given":"George","dropping-particle":"van den"},{"family":"Hendricks","given":"Lisa Anne"},{"family":"Rauh","given":"Maribeth"},{"family":"Huang","given":"Po-Sen"},{"family":"Glaese","given":"Amelia"},{"family":"Welbl","given":"Johannes"},{"family":"Dathathri","given":"Sumanth"},{"family":"Huang","given":"Saffron"},{"family":"Uesato","given":"Jonathan"},{"family":"Mellor","given":"John"},{"family":"Higgins","given":"Irina"},{"family":"Creswell","given":"Antonia"},{"family":"McAleese","given":"Nat"},{"family":"Wu","given":"Amy"},{"family":"Elsen","given":"Erich"},{"family":"Jayakumar","given":"Siddhant"},{"family":"Buchatskaya","given":"Elena"},{"family":"Budden","given":"David"},{"family":"Sutherland","given":"Esme"},{"family":"Simonyan","given":"Karen"},{"family":"Paganini","given":"Michela"},{"family":"Sifre","given":"Laurent"},{"family":"Martens","given":"Lena"},{"family":"Li","given":"Xiang Lorraine"},{"family":"Kuncoro","given":"Adhiguna"},{"family":"Nematzadeh","given":"Aida"},{"family":"Gribovskaya","given":"Elena"},{"family":"Donato","given":"Domenic"},{"family":"Lazaridou","given":"Angeliki"},{"family":"Mensch","given":"Arthur"},{"family":"Lespiau","given":"Jean-Baptiste"},{"family":"Tsimpoukelli","given":"Maria"},{"family":"Grigorev","given":"Nikolai"},{"family":"Fritz","given":"Doug"},{"family":"Sottiaux","given":"Thibault"},{"family":"Pajarskas","given":"Mantas"},{"family":"Pohlen","given":"Toby"},{"family":"Gong","given":"Zhitao"},{"family":"Toyama","given":"Daniel"},{"family":"Autume","given":"Cyprien de Masson","non-dropping-particle":"d'"},{"family":"Li","given":"Yujia"},{"family":"Terzi","given":"Tayfun"},{"family":"Mikulik","given":"Vladimir"},{"family":"Babuschkin","given":"Igor"},{"family":"Clark","given":"Aidan"},{"family":"Casas","given":"Diego de Las"},{"family":"Guy","given":"Aurelia"},{"family":"Jones","given":"Chris"},{"family":"Bradbury","given":"James"},{"family":"Johnson","given":"Matthew"},{"family":"Hechtman","given":"Blake"},{"family":"Weidinger","given":"Laura"},{"family":"Gabriel","given":"Iason"},{"family":"Isaac","given":"William"},{"family":"Lockhart","given":"Ed"},{"family":"Osindero","given":"Simon"},{"family":"Rimell","given":"Laura"},{"family":"Dyer","given":"Chris"},{"family":"Vinyals","given":"Oriol"},{"family":"Ayoub","given":"Kareem"},{"family":"Stanway","given":"Jeff"},{"family":"Bennett","given":"Lorrayne"},{"family":"Hassabis","given":"Demis"},{"family":"Kavukcuoglu","given":"Koray"},{"family":"Irving","given":"Geoffrey"}],"citation-key":"raeScalingLanguageModels2022","issued":{"date-parts":[["2022"]]},"title":"Scaling language models: methods, analysis & insights from training gopher","type":"document"},
  {"id":"raffelExploringLimitsTransfer2020","author":[{"family":"Raffel","given":"Colin"},{"family":"Shazeer","given":"Noam"},{"family":"Roberts","given":"Adam"},{"family":"Lee","given":"Katherine"},{"family":"Narang","given":"Sharan"},{"family":"Matena","given":"Michael"},{"family":"Zhou","given":"Yanqi"},{"family":"Li","given":"Wei"},{"family":"Liu","given":"Peter J."}],"citation-key":"raffelExploringLimitsTransfer2020","container-title":"Journal of Machine Learning Research","issue":"140","issued":{"date-parts":[["2020"]]},"page":"1–67","title":"Exploring the limits of transfer learning with a unified text-to-text transformer","type":"article-journal","volume":"21"},
  {"id":"raffelExploringLimitsTransfer2023","abstract":"Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts all text-based language problems into a text-to-text format. Our systematic study compares pre-training objectives, architectures, unlabeled data sets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new ``Colossal Clean Crawled Corpus'', we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our data set, pre-trained models, and code.","accessed":{"date-parts":[["2024",11,29]]},"author":[{"family":"Raffel","given":"Colin"},{"family":"Shazeer","given":"Noam"},{"family":"Roberts","given":"Adam"},{"family":"Lee","given":"Katherine"},{"family":"Narang","given":"Sharan"},{"family":"Matena","given":"Michael"},{"family":"Zhou","given":"Yanqi"},{"family":"Li","given":"Wei"},{"family":"Liu","given":"Peter J."}],"citation-key":"raffelExploringLimitsTransfer2023","DOI":"10.48550/arXiv.1910.10683","issued":{"date-parts":[["2023",9,19]]},"language":"en","number":"arXiv:1910.10683","publisher":"arXiv","source":"arXiv.org","title":"Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer","type":"article","URL":"http://arxiv.org/abs/1910.10683"},
  {"id":"raschkaIntroductionLatestTechniques2021","author":[{"family":"Raschka","given":"Sebastian"}],"citation-key":"raschkaIntroductionLatestTechniques2021","issued":{"date-parts":[["2021"]]},"page":"52","title":"An introduction to the latest techniques","type":"article-journal"},
  {"id":"raschkaMachineLearningPyTorch2022","author":[{"family":"Raschka","given":"Sebastian"},{"family":"Liu","given":"Yuxi"},{"family":"Mirjalili","given":"Vahid"},{"family":"Dzhulgakov","given":"Dmytro"}],"citation-key":"raschkaMachineLearningPyTorch2022","event-place":"Birmingham","issued":{"date-parts":[["2022"]]},"publisher":"Packt Publishing","publisher-place":"Birmingham","title":"Machine learning with PyTorch and scikit-learn: develop machine learning and deep learning models with python","type":"book"},
  {"id":"raschkaModelEvaluationModel2020","accessed":{"date-parts":[["2023",1,16]]},"author":[{"family":"Raschka","given":"Sebastian"}],"citation-key":"raschkaModelEvaluationModel2020","issued":{"date-parts":[["2020"]]},"title":"Model evaluation, model selection, and algorithm selection in machine learning","type":"document","URL":"http://arxiv.org/abs/1811.12808"},
  {"id":"raschkaRecentTrendsTechnologies2021","author":[{"family":"Raschka","given":"Sebastian"}],"citation-key":"raschkaRecentTrendsTechnologies2021","issued":{"date-parts":[["2021"]]},"page":"54","title":"Recent trends, technologies, and challenges","type":"article-journal"},
  {"id":"RecipeTrainingNeural","accessed":{"date-parts":[["2021",12,3]]},"citation-key":"RecipeTrainingNeural","title":"A recipe for training neural networks","type":"document","URL":"http://karpathy.github.io/2019/04/25/recipe/"},
  {"id":"ribeiroEnsembleApproachBased2020","author":[{"family":"Ribeiro","given":"Matheus Henrique Dal Molin"},{"family":"Santos Coelho","given":"Leandro","non-dropping-particle":"dos"}],"citation-key":"ribeiroEnsembleApproachBased2020","container-title":"Applied Soft Computing","DOI":"10.1016/j.asoc.2019.105837","issued":{"date-parts":[["2020"]]},"page":"105837","title":"Ensemble approach based on bagging, boosting and stacking for short-term prediction in agribusiness time series","type":"article-journal","volume":"86"},
  {"id":"rogersPrimerBERTologyWhat2020","accessed":{"date-parts":[["2023",6,17]]},"author":[{"family":"Rogers","given":"Anna"},{"family":"Kovaleva","given":"Olga"},{"family":"Rumshisky","given":"Anna"}],"citation-key":"rogersPrimerBERTologyWhat2020","container-title":"Transactions of the Association for Computational Linguistics","DOI":"10.1162/tacl\\_a\\_00349","issued":{"date-parts":[["2020"]]},"page":"842–866","title":"A Primer in BERTology: What We Know About How BERT Works","type":"article-journal","volume":"8"},
  {"id":"ronenMachineLearningTrade2022","author":[{"family":"Fedenia","given":"Mark A."},{"family":"Ronen","given":"Tavy"},{"family":"Nam","given":"Seunghan"}],"citation-key":"ronenMachineLearningTrade2022","DOI":"10.2139/ssrn.4213313","issued":{"date-parts":[["2022"]]},"title":"Machine learning and trade direction classification: insights from the corporate bond market","type":"document"},
  {"id":"rosenthalModelingTradeDirection2012","author":[{"family":"Rosenthal","given":"Dale W. R."}],"citation-key":"rosenthalModelingTradeDirection2012","container-title":"Journal of Financial Econometrics","DOI":"10.1093/jjfinec/nbr014","issue":"2","issued":{"date-parts":[["2012"]]},"page":"390–415","title":"Modeling trade direction","type":"article-journal","volume":"10"},
  {"id":"rossiMachineLearning","author":[{"family":"Rossi","given":"Alberto"}],"citation-key":"rossiMachineLearning","container-title":"Unpublished Working Paper","issued":{"date-parts":[["2018"]]},"page":"44","title":"Predicting stock market returns with machine learning","type":"article-journal"},
  {"id":"rothmanTransformersNaturalLanguage2021","author":[{"family":"Rothman","given":"Denis"}],"citation-key":"rothmanTransformersNaturalLanguage2021","event-place":"Birmingham","issued":{"date-parts":[["2021"]]},"publisher":"Packt Publishing","publisher-place":"Birmingham","title":"Transformers for natural language processing","type":"book"},
  {"id":"rozemberczkiShapleyValueMachine2022","accessed":{"date-parts":[["2022",10,27]]},"author":[{"family":"Rozemberczki","given":"Benedek"},{"family":"Watson","given":"Lauren"},{"family":"Bayer","given":"Péter"},{"family":"Yang","given":"Hao-Tsung"},{"family":"Kiss","given":"Olivér"},{"family":"Nilsson","given":"Sebastian"},{"family":"Sarkar","given":"Rik"}],"citation-key":"rozemberczkiShapleyValueMachine2022","issued":{"date-parts":[["2022"]]},"title":"The shapley value in machine learning","type":"document","URL":"http://arxiv.org/abs/2202.05594"},
  {"id":"rubachevRevisitingPretrainingObjectives2022","author":[{"family":"Rubachev","given":"Ivan"},{"family":"Alekberov","given":"Artem"},{"family":"Gorishniy","given":"Yury"},{"family":"Babenko","given":"Artem"}],"citation-key":"rubachevRevisitingPretrainingObjectives2022","issued":{"date-parts":[["2022"]]},"title":"Revisiting pretraining objectives for tabular deep learning","type":"document"},
  {"id":"rubinBayesianBootstrap1981","accessed":{"date-parts":[["2023",6,30]]},"author":[{"family":"Rubin","given":"Donald B."}],"citation-key":"rubinBayesianBootstrap1981","container-title":"The Annals of Statistics","DOI":"10.1214/aos/1176345338","issue":"1","issued":{"date-parts":[["1981"]]},"page":"130–134","title":"The bayesian bootstrap","type":"article-journal","volume":"9"},
  {"id":"rubinInferenceMissingData1976","accessed":{"date-parts":[["2022",11,28]]},"author":[{"family":"Rubin","given":"Donald B."}],"citation-key":"rubinInferenceMissingData1976","container-title":"Biometrika","DOI":"10.1093/biomet/63.3.581","issue":"3","issued":{"date-parts":[["1976"]]},"page":"581–592","title":"Inference and missing data","type":"article-journal","volume":"63"},
  {"id":"rubinsteinRelationBinomialTrinomial2000","accessed":{"date-parts":[["2021",7,4]]},"author":[{"family":"Rubinstein","given":"Mark"}],"citation-key":"rubinsteinRelationBinomialTrinomial2000","container-title":"The Journal of Derivatives","DOI":"10.3905/jod.2000.319149","issue":"2","issued":{"date-parts":[["2000"]]},"page":"47–50","title":"On the relation between binomial and trinomial option pricing models","type":"article-journal","volume":"8"},
  {"id":"sametFoundationsMultidimensionalMetric","author":[{"family":"Samet","given":"Hanan"}],"citation-key":"sametFoundationsMultidimensionalMetric","page":"1022","title":"Foundations of multidimensional and metric data structures","type":"article-journal"},
  {"id":"sandersSequentialParallelAlgorithms2019","accessed":{"date-parts":[["2020",10,31]]},"author":[{"family":"Sanders","given":"Peter"},{"family":"Mehlhorn","given":"Kurt"},{"family":"Dietzfelbinger","given":"Martin"},{"family":"Dementiev","given":"Roman"}],"citation-key":"sandersSequentialParallelAlgorithms2019","DOI":"10.1007/978-3-030-25209-0","event-place":"Cham","issued":{"date-parts":[["2019"]]},"publisher":"Springer International Publishing","publisher-place":"Cham","title":"Sequential and parallel algorithms and data structures: the basic toolbox","type":"book"},
  {"id":"sarkarMarketSidednessInsights2023","author":[{"family":"Sarkar","given":"Asani"},{"family":"Schwartz","given":"Robert A"}],"citation-key":"sarkarMarketSidednessInsights2023","issued":{"date-parts":[["2023"]]},"title":"Market sidedness: insights into motives for trade initiation","type":"article-journal"},
  {"id":"savickasInferringDirectionOption2003","author":[{"family":"Savickas","given":"Robert"},{"family":"Wilson","given":"Arthur J"}],"citation-key":"savickasInferringDirectionOption2003","container-title":"Journal of Financial and Quantitative Analysis","DOI":"10.2307/4126747","issued":{"date-parts":[["2003"]]},"page":"881–902","title":"On inferring the direction of option trades","type":"article-journal","volume":"38"},
  {"id":"schaferRecommenderSystemsEcommerce1999","author":[{"family":"Schafer","given":"J Ben"},{"family":"Konstan","given":"Joseph"},{"family":"Riedl","given":"John"}],"citation-key":"schaferRecommenderSystemsEcommerce1999","DOI":"10.1145/336992.337035","issued":{"date-parts":[["1999"]]},"page":"9","title":"Recommender systems in E-commerce","type":"article-journal"},
  {"id":"schapireBoostingMarginNew1998","author":[{"family":"Schapire","given":"Robert E."},{"family":"Bartlett","given":"Peter"},{"family":"Freund","given":"Yoav"},{"family":"Lee","given":"Wee Sun"}],"citation-key":"schapireBoostingMarginNew1998","container-title":"The Annals of Statistics","DOI":"10.1214/aos/1024691352","issue":"5","issued":{"date-parts":[["1998"]]},"title":"Boosting the margin: a new explanation for the effectiveness of voting methods","type":"article-journal","volume":"26"},
  {"id":"schapireStrengthWeakLearnability1990","accessed":{"date-parts":[["2022",12,14]]},"author":[{"family":"Schapire","given":"Robert E."}],"citation-key":"schapireStrengthWeakLearnability1990","container-title":"Machine Learning","DOI":"10.1007/BF00116037","issue":"2","issued":{"date-parts":[["1990"]]},"page":"197–227","title":"The strength of weak learnability","type":"article-journal","volume":"5"},
  {"id":"schroffFaceNetUnifiedEmbedding2015","accessed":{"date-parts":[["2023",6,26]]},"author":[{"family":"Schroff","given":"Florian"},{"family":"Kalenichenko","given":"Dmitry"},{"family":"Philbin","given":"James"}],"citation-key":"schroffFaceNetUnifiedEmbedding2015","container-title":"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)","DOI":"10.1109/CVPR.2015.7298682","event-place":"Boston, MA, USA","issued":{"date-parts":[["2015"]]},"page":"815–823","publisher":"IEEE","publisher-place":"Boston, MA, USA","title":"FaceNet: A unified embedding for face recognition and clustering","type":"paper-conference"},
  {"id":"securitiesandexchangecommissionReportConcerningExaminations2007","accessed":{"date-parts":[["2023",6,26]]},"author":[{"literal":"Securities and Exchange Commission"}],"citation-key":"securitiesandexchangecommissionReportConcerningExaminations2007","issued":{"date-parts":[["2007"]]},"publisher":"Securities and Exchange Commission","title":"Report concerning examinations of options order routing and execution","type":"report","URL":"https://www.sec.gov/files/optionsroutingreport.pdf"},
  {"id":"shahriariTakingHumanOut2016","author":[{"family":"Shahriari","given":"Bobak"},{"family":"Swersky","given":"Kevin"},{"family":"Wang","given":"Ziyu"},{"family":"Adams","given":"Ryan P."},{"family":"Freitas","given":"Nando","non-dropping-particle":"de"}],"citation-key":"shahriariTakingHumanOut2016","container-title":"Proceedings of the IEEE","DOI":"10.1109/JPROC.2015.2494218","issue":"1","issued":{"date-parts":[["2016"]]},"page":"148–175","title":"Taking the human out of the loop: a review of bayesian optimization","type":"article-journal","volume":"104"},
  {"id":"shallueMeasuringEffectsData","author":[{"family":"Shallue","given":"Christopher J"},{"family":"Lee","given":"Jaehoon"},{"family":"Antognini","given":"Joseph"},{"family":"Sohl-Dickstein","given":"Jascha"},{"family":"Frostig","given":"Roy"},{"family":"Dahl","given":"George E"}],"citation-key":"shallueMeasuringEffectsData","title":"Measuring the effects of data parallelism on neural network training","type":"article-journal"},
  {"id":"shaniEvaluatingRecommendationSystems","author":[{"family":"Shani","given":"Guy"},{"family":"Gunawardana","given":"Asela"}],"citation-key":"shaniEvaluatingRecommendationSystems","DOI":"10.1007/978-0-387-85820-3\\_8","page":"43","title":"Evaluating recommendation systems","type":"article-journal"},
  {"id":"shapleyValueNpersonGames1953","author":[{"family":"Shapley","given":"L. S."}],"citation-key":"shapleyValueNpersonGames1953","container-title":"Contributions to the Theory of Games (AM-28), Volume II","DOI":"10.1515/9781400881970-018","editor":[{"family":"Kuhn","given":"Harold William"},{"family":"Tucker","given":"Albert William"}],"issued":{"date-parts":[["1953"]]},"page":"307–318","publisher":"Princeton University Press","title":"A value for n-person games","type":"chapter"},
  {"id":"shavittRegularizationLearningNetworks2018","author":[{"family":"Shavitt","given":"Ira"},{"family":"Segal","given":"Eran"}],"citation-key":"shavittRegularizationLearningNetworks2018","container-title":"32nd Conference on Neural Information Processing Systems","event-place":"Montréal","issued":{"date-parts":[["2018"]]},"page":"11","publisher-place":"Montréal","title":"Regularization learning networks: deep learning for tabular datasets","type":"paper-conference"},
  {"id":"shazeerAdafactorAdaptiveLearning2018","accessed":{"date-parts":[["2023",1,19]]},"author":[{"family":"Shazeer","given":"Noam"},{"family":"Stern","given":"Mitchell"}],"citation-key":"shazeerAdafactorAdaptiveLearning2018","issued":{"date-parts":[["2018"]]},"title":"Adafactor: adaptive learning rates with sublinear memory cost","type":"document","URL":"http://arxiv.org/abs/1804.04235"},
  {"id":"shazeerGLUVariantsImprove2020","author":[{"family":"Shazeer","given":"Noam"}],"citation-key":"shazeerGLUVariantsImprove2020","issued":{"date-parts":[["2020"]]},"title":"GLU variants improve transformer","type":"document"},
  {"id":"shiQuantizedTrainingGradient","author":[{"family":"Shi","given":"Yu"},{"family":"Ke","given":"Guolin"},{"family":"Chen","given":"Zhuoming"},{"family":"Zheng","given":"Shuxin"},{"family":"Liu","given":"Tie-Yan"}],"citation-key":"shiQuantizedTrainingGradient","title":"Quantized training of gradient boosting decision trees","type":"article-journal"},
  {"id":"shumwayDelistingBiasCRSP1997","accessed":{"date-parts":[["2021",10,29]]},"author":[{"family":"Shumway","given":"Tyler"}],"citation-key":"shumwayDelistingBiasCRSP1997","container-title":"The Journal of Finance","DOI":"10.1111/j.1540-6261.1997.tb03818.x","issue":"1","issued":{"date-parts":[["1997"]]},"page":"327–340","title":"The delisting bias in CRSP data","type":"article-journal","volume":"52"},
  {"id":"shwartz-zivTabularDataDeep2021","accessed":{"date-parts":[["2022",10,5]]},"author":[{"family":"Shwartz-Ziv","given":"Ravid"},{"family":"Armon","given":"Amitai"}],"citation-key":"shwartz-zivTabularDataDeep2021","issued":{"date-parts":[["2021"]]},"title":"Tabular data: deep learning is not all you need","type":"document","URL":"http://arxiv.org/abs/2106.03253"},
  {"id":"smiejaProcessingMissingData2018","accessed":{"date-parts":[["2022",11,28]]},"author":[{"family":"Śmieja","given":"Marek"},{"family":"Struski","given":"Łukasz"},{"family":"Tabor","given":"Jacek"},{"family":"Zieliński","given":"Bartosz"},{"family":"Spurek","given":"Przemysław"}],"citation-key":"smiejaProcessingMissingData2018","container-title":"Advances in Neural Information Processing Systems","issued":{"date-parts":[["2018"]]},"publisher":"Curran Associates, Inc.","title":"Processing of missing data by neural networks","type":"paper-conference","URL":"https://proceedings.neurips.cc/paper/2018/hash/411ae1bf081d1674ca6091f8c59a266f-Abstract.html","volume":"31"},
  {"id":"smilkovSmoothGradRemovingNoise2017","accessed":{"date-parts":[["2022",12,17]]},"author":[{"family":"Smilkov","given":"Daniel"},{"family":"Thorat","given":"Nikhil"},{"family":"Kim","given":"Been"},{"family":"Viégas","given":"Fernanda"},{"family":"Wattenberg","given":"Martin"}],"citation-key":"smilkovSmoothGradRemovingNoise2017","DOI":"10.48550/arXiv.1706.03825","issued":{"date-parts":[["2017"]]},"title":"SmoothGrad: removing noise by adding noise","type":"document"},
  {"id":"smithAperiodicMonotile2023","accessed":{"date-parts":[["2023",5,15]]},"author":[{"family":"Smith","given":"David"},{"family":"Myers","given":"Joseph Samuel"},{"family":"Kaplan","given":"Craig S."},{"family":"Goodman-Strauss","given":"Chaim"}],"citation-key":"smithAperiodicMonotile2023","issued":{"date-parts":[["2023"]]},"title":"An aperiodic monotile","type":"document","URL":"http://arxiv.org/abs/2303.10798"},
  {"id":"smithCyclicalLearningRates2017","author":[{"family":"Smith","given":"Leslie N."}],"citation-key":"smithCyclicalLearningRates2017","issued":{"date-parts":[["2017"]]},"title":"Cyclical learning rates for training neural networks","type":"document"},
  {"id":"smithDonDecayLearning2018","accessed":{"date-parts":[["2022",12,20]]},"author":[{"family":"Smith","given":"Samuel L."},{"family":"Kindermans","given":"Pieter-Jan"},{"family":"Ying","given":"Chris"},{"family":"Le","given":"Quoc V."}],"citation-key":"smithDonDecayLearning2018","issued":{"date-parts":[["2018"]]},"title":"Don't decay the learning rate, increase the batch size","type":"document","URL":"http://arxiv.org/abs/1711.00489"},
  {"id":"smithSuperConvergenceVeryFast2018","abstract":"In this paper, we describe a phenomenon, which we named \"super-convergence\", where neural networks can be trained an order of magnitude faster than with standard training methods. The existence of super-convergence is relevant to understanding why deep networks generalize well. One of the key elements of super-convergence is training with one learning rate cycle and a large maximum learning rate. A primary insight that allows super-convergence training is that large learning rates regularize the training, hence requiring a reduction of all other forms of regularization in order to preserve an optimal regularization balance. We also derive a simplification of the Hessian Free optimization method to compute an estimate of the optimal learning rate. Experiments demonstrate super-convergence for Cifar-10/100, MNIST and Imagenet datasets, and resnet, wide-resnet, densenet, and inception architectures. In addition, we show that super-convergence provides a greater boost in performance relative to standard training when the amount of labeled training data is limited. The architectures and code to replicate the figures in this paper are available at github.com/lnsmith54/super-convergence. See http://www.fast.ai/2018/04/30/dawnbench-fastai/ for an application of super-convergence to win the DAWNBench challenge (see https://dawn.cs.stanford.edu/benchmark/).","accessed":{"date-parts":[["2024",11,24]]},"author":[{"family":"Smith","given":"Leslie N."},{"family":"Topin","given":"Nicholay"}],"citation-key":"smithSuperConvergenceVeryFast2018","DOI":"10.48550/arXiv.1708.07120","issued":{"date-parts":[["2018",5,17]]},"number":"arXiv:1708.07120","publisher":"arXiv","source":"arXiv.org","title":"Super-Convergence: Very Fast Training of Neural Networks Using Large Learning Rates","title-short":"Super-Convergence","type":"article","URL":"http://arxiv.org/abs/1708.07120"},
  {"id":"SmolDoclingUltracompactVisionlanguage","accessed":{"date-parts":[["2025",4,13]]},"citation-key":"SmolDoclingUltracompactVisionlanguage","title":"SmolDocling: An ultra-compact vision-language model for end-to-end multi-modal document conversion","type":"webpage","URL":"https://arxiv.org/html/2503.11576v1"},
  {"id":"snoekPracticalBayesianOptimization2012","accessed":{"date-parts":[["2022",11,1]]},"author":[{"family":"Snoek","given":"Jasper"},{"family":"Larochelle","given":"Hugo"},{"family":"Adams","given":"Ryan P"}],"citation-key":"snoekPracticalBayesianOptimization2012","container-title":"Advances in Neural Information Processing Systems","issued":{"date-parts":[["2012"]]},"publisher":"Curran Associates, Inc.","title":"Practical bayesian optimization of machine learning algorithms","type":"paper-conference","URL":"https://papers.nips.cc/paper/2012/hash/05311655a15b75fab86956663e1819cd-Abstract.html","volume":"25"},
  {"id":"somepalliSaintImprovedNeural2021","accessed":{"date-parts":[["2022",10,4]]},"author":[{"family":"Somepalli","given":"Gowthami"},{"family":"Goldblum","given":"Micah"},{"family":"Schwarzschild","given":"Avi"},{"family":"Bruss","given":"C. Bayan"},{"family":"Goldstein","given":"Tom"}],"citation-key":"somepalliSaintImprovedNeural2021","issued":{"date-parts":[["2021"]]},"title":"SAINT: improved neural networks for tabular data via row attention and contrastive pre-training","type":"document"},
  {"id":"songAutoIntAutomaticFeature2019","author":[{"family":"Song","given":"Weiping"},{"family":"Shi","given":"Chence"},{"family":"Xiao","given":"Zhiping"},{"family":"Duan","given":"Zhijian"},{"family":"Xu","given":"Yewen"},{"family":"Zhang","given":"Ming"},{"family":"Tang","given":"Jian"}],"citation-key":"songAutoIntAutomaticFeature2019","container-title":"Proceedings of the 28th ACM International Conference on Information and Knowledge Management","DOI":"10.1145/3357384.3357925","issued":{"date-parts":[["2019"]]},"page":"1161–1170","title":"AutoInt: automatic feature interaction learning via self-attentive neural networks","type":"paper-conference"},
  {"id":"SparseAutoencodersUsing2020","accessed":{"date-parts":[["2021",11,15]]},"citation-key":"SparseAutoencodersUsing2020","issued":{"date-parts":[["2020"]]},"title":"Sparse autoencoders using l1 regularization with PyTorch","type":"document","URL":"https://debuggercafe.com/sparse-autoencoders-using-l1-regularization-with-pytorch/"},
  {"id":"srivastavaDropoutSimpleWay","author":[{"family":"Srivastava","given":"Nitish"},{"family":"Hinton","given":"Geoffrey"},{"family":"Krizhevsky","given":"Alex"},{"family":"Sutskever","given":"Ilya"},{"family":"Salakhutdinov","given":"Ruslan"}],"citation-key":"srivastavaDropoutSimpleWay","container-title":"Journal of Machine Learning Research","issue":"56","issued":{"date-parts":[["2014"]]},"page":"1929–1958","title":"Dropout: a simple way to prevent neural networks from overfitting","type":"article-journal","volume":"15"},
  {"id":"statquestwithjoshstarmerGradientBoostPart2019","accessed":{"date-parts":[["2021",12,25]]},"author":[{"literal":"StatQuest with Josh Starmer"}],"citation-key":"statquestwithjoshstarmerGradientBoostPart2019","issued":{"date-parts":[["2019"]]},"title":"Gradient boost part 2 (of 4): regression details","type":"document","URL":"https://www.youtube.com/watch?v=2xudPOBz-vs"},
  {"id":"steckCosineSimilarityEmbeddingsReally2024","abstract":"Cosine-similarity is the cosine of the angle between two vectors, or equivalently the dot product between their normalizations. A popular application is to quantify semantic similarity between high-dimensional objects by applying cosine-similarity to a learned low-dimensional feature embedding. This can work better but sometimes also worse than the unnormalized dot-product between embedded vectors in practice. To gain insight into this empirical observation, we study embeddings derived from regularized linear models, where closed-form solutions facilitate analytical insights. We derive analytically how cosine-similarity can yield arbitrary and therefore meaningless ‘similarities.’ For some linear models the similarities are not even unique, while for others they are implicitly controlled by the regularization. We discuss implications beyond linear models: a combination of different regularizations are employed when learning deep models; these have implicit and unintended effects when taking cosinesimilarities of the resulting embeddings, rendering results opaque and possibly arbitrary. Based on these insights, we caution against blindly using cosine-similarity and outline alternatives.","accessed":{"date-parts":[["2024",11,28]]},"author":[{"family":"Steck","given":"Harald"},{"family":"Ekanadham","given":"Chaitanya"},{"family":"Kallus","given":"Nathan"}],"citation-key":"steckCosineSimilarityEmbeddingsReally2024","container-title":"Companion Proceedings of the ACM Web Conference 2024","DOI":"10.1145/3589335.3651526","issued":{"date-parts":[["2024",5,13]]},"language":"en","page":"887–890","source":"arXiv.org","title":"Is Cosine-Similarity of Embeddings Really About Similarity?","type":"paper-conference","URL":"http://arxiv.org/abs/2403.05440"},
  {"id":"stewartCalculusEarlyTranscendentals2016","author":[{"family":"Stewart","given":"James"}],"citation-key":"stewartCalculusEarlyTranscendentals2016","edition":"Eighth edition","event-place":"Boston, MA, USA","issued":{"date-parts":[["2016"]]},"publisher":"Cengage Learning","publisher-place":"Boston, MA, USA","title":"Calculus: early transcendentals","type":"book"},
  {"id":"strangIntroductionLinearAlgebra2016","author":[{"family":"Strang","given":"Gilbert"}],"citation-key":"strangIntroductionLinearAlgebra2016","edition":"5th edition","event-place":"Wellesley","issued":{"date-parts":[["2016"]]},"publisher":"Cambridge press","publisher-place":"Wellesley","title":"Introduction to linear algebra","type":"book"},
  {"id":"strangLinearAlgebraLearning","author":[{"family":"Strang","given":"Gilbert"}],"citation-key":"strangLinearAlgebraLearning","language":"en","source":"Zotero","title":"Linear Algebra and Learning from Data","type":"article-journal"},
  {"id":"stroblConditionalVariableImportance2008","accessed":{"date-parts":[["2023",4,11]]},"author":[{"family":"Strobl","given":"Carolin"},{"family":"Boulesteix","given":"Anne-Laure"},{"family":"Kneib","given":"Thomas"},{"family":"Augustin","given":"Thomas"},{"family":"Zeileis","given":"Achim"}],"citation-key":"stroblConditionalVariableImportance2008","container-title":"BMC Bioinformatics","DOI":"10.1186/1471-2105-9-307","issue":"1","issued":{"date-parts":[["2008"]]},"page":"307","title":"Conditional variable importance for random forests","type":"article-journal","volume":"9"},
  {"id":"stutzUnderstandingImprovingRobustness","author":[{"family":"Stutz","given":"David"}],"citation-key":"stutzUnderstandingImprovingRobustness","page":"74","title":"Understanding and improving robustness and uncertainty estimation in deep learning","type":"article-journal"},
  {"id":"sukhbaatarAugmentingSelfattentionPersistent2019","author":[{"family":"Sukhbaatar","given":"Sainbayar"},{"family":"Grave","given":"Edouard"},{"family":"Lample","given":"Guillaume"},{"family":"Jegou","given":"Herve"},{"family":"Joulin","given":"Armand"}],"citation-key":"sukhbaatarAugmentingSelfattentionPersistent2019","issued":{"date-parts":[["2019"]]},"title":"Augmenting self-attention with persistent memory","type":"document"},
  {"id":"sunAdaBoostLSTMEnsembleLearning2018","author":[{"family":"Sun","given":"Shaolong"},{"family":"Wei","given":"Yunjie"},{"family":"Wang","given":"Shouyang"}],"citation-key":"sunAdaBoostLSTMEnsembleLearning2018","container-title":"Computational Science – ICCS 2018","DOI":"10.1007/978-3-319-93713-7\\_55","editor":[{"family":"Shi","given":"Yong"},{"family":"Fu","given":"Haohuan"},{"family":"Tian","given":"Yingjie"},{"family":"Krzhizhanovskaya","given":"Valeria V."},{"family":"Lees","given":"Michael Harold"},{"family":"Dongarra","given":"Jack"},{"family":"Sloot","given":"Peter M. A."}],"event-place":"Cham","issued":{"date-parts":[["2018"]]},"page":"590–597","publisher":"Springer International Publishing","publisher-place":"Cham","title":"AdaBoost-LSTM ensemble learning for financial time series forecasting","type":"chapter","volume":"10862"},
  {"id":"suRoFormerEnhancedTransformer2022","accessed":{"date-parts":[["2023",4,14]]},"author":[{"family":"Su","given":"Jianlin"},{"family":"Lu","given":"Yu"},{"family":"Pan","given":"Shengfeng"},{"family":"Murtadha","given":"Ahmed"},{"family":"Wen","given":"Bo"},{"family":"Liu","given":"Yunfeng"}],"citation-key":"suRoFormerEnhancedTransformer2022","issued":{"date-parts":[["2022"]]},"title":"RoFormer: enhanced transformer with rotary position embedding","type":"document","URL":"http://arxiv.org/abs/2104.09864"},
  {"id":"sutskeverSequenceSequenceLearning2014","author":[{"family":"Sutskever","given":"Ilya"},{"family":"Vinyals","given":"Oriol"},{"family":"Le","given":"Quoc V."}],"citation-key":"sutskeverSequenceSequenceLearning2014","container-title":"Advances in Neural Information Processing Systems","event-place":"Montreal, QC, Canada","issued":{"date-parts":[["2014"]]},"page":"3104–3112","publisher":"MIT Press","publisher-place":"Montreal, QC, Canada","title":"Sequence to sequence learning with neural networks","type":"paper-conference","volume":"27"},
  {"id":"szegedyRethinkingInceptionArchitecture2016","author":[{"family":"Szegedy","given":"Christian"},{"family":"Vanhoucke","given":"Vincent"},{"family":"Ioffe","given":"Sergey"},{"family":"Shlens","given":"Jon"},{"family":"Wojna","given":"Zbigniew"}],"citation-key":"szegedyRethinkingInceptionArchitecture2016","container-title":"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)","DOI":"10.1109/CVPR.2016.308","event-place":"Las Vegas, NV, USA","issued":{"date-parts":[["2016"]]},"page":"2818–2826","publisher":"IEEE","publisher-place":"Las Vegas, NV, USA","title":"Rethinking the inception architecture for computer vision","type":"paper-conference"},
  {"id":"takaseLayerNormalizationsResidual2022","accessed":{"date-parts":[["2023",1,19]]},"author":[{"family":"Takase","given":"Sho"},{"family":"Kiyono","given":"Shun"},{"family":"Kobayashi","given":"Sosuke"},{"family":"Suzuki","given":"Jun"}],"citation-key":"takaseLayerNormalizationsResidual2022","issued":{"date-parts":[["2022"]]},"title":"On layer normalizations and residual connections in transformers","type":"document","URL":"http://arxiv.org/abs/2206.00330"},
  {"id":"tangAnalysisAttentionMechanisms2018","accessed":{"date-parts":[["2023",1,4]]},"author":[{"family":"Tang","given":"Gongbo"},{"family":"Sennrich","given":"Rico"},{"family":"Nivre","given":"Joakim"}],"citation-key":"tangAnalysisAttentionMechanisms2018","container-title":"Proceedings of the Third Conference on Machine Translation: Research Papers","DOI":"10.18653/v1/W18-6304","event-place":"Brussels, Belgium","issued":{"date-parts":[["2018"]]},"page":"26–35","publisher":"Association for Computational Linguistics","publisher-place":"Brussels, Belgium","title":"An analysis of attention mechanisms: the case of word sense disambiguation in neural machine translation","type":"paper-conference"},
  {"id":"tanhaSemisupervisedSelftrainingDecision2017","author":[{"family":"Tanha","given":"Jafar"},{"family":"Someren","given":"Maarten","non-dropping-particle":"van"},{"family":"Afsarmanesh","given":"Hamideh"}],"citation-key":"tanhaSemisupervisedSelftrainingDecision2017","container-title":"International Journal of Machine Learning and Cybernetics","DOI":"10.1007/s13042-015-0328-7","issue":"1","issued":{"date-parts":[["2017"]]},"page":"355–370","title":"Semi-supervised self-training for decision tree classifiers","type":"article-journal","volume":"8"},
  {"id":"tayEfficientTransformersSurvey2022","author":[{"family":"Tay","given":"Yi"},{"family":"Dehghani","given":"Mostafa"},{"family":"Bahri","given":"Dara"},{"family":"Metzler","given":"Donald"}],"citation-key":"tayEfficientTransformersSurvey2022","issued":{"date-parts":[["2022"]]},"title":"Efficient transformers: a survey","type":"document"},
  {"id":"taylorGalacticaLargeLanguage2022","accessed":{"date-parts":[["2023",5,3]]},"author":[{"family":"Taylor","given":"Ross"},{"family":"Kardas","given":"Marcin"},{"family":"Cucurull","given":"Guillem"},{"family":"Scialom","given":"Thomas"},{"family":"Hartshorn","given":"Anthony"},{"family":"Saravia","given":"Elvis"},{"family":"Poulton","given":"Andrew"},{"family":"Kerkez","given":"Viktor"},{"family":"Stojnic","given":"Robert"}],"citation-key":"taylorGalacticaLargeLanguage2022","issued":{"date-parts":[["2022"]]},"title":"Galactica: a large language model for science","type":"document","URL":"http://arxiv.org/abs/2211.09085"},
  {"id":"tenneyBERTRediscoversClassical2019","author":[{"family":"Tenney","given":"Ian"},{"family":"Das","given":"Dipanjan"},{"family":"Pavlick","given":"Ellie"}],"citation-key":"tenneyBERTRediscoversClassical2019","container-title":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics","DOI":"10.18653/v1/P19-1452","event-place":"Florence, Italy","issued":{"date-parts":[["2019"]]},"page":"4593–4601","publisher":"Association for Computational Linguistics","publisher-place":"Florence, Italy","title":"BERT rediscovers the classical NLP pipeline","type":"paper-conference"},
  {"id":"theissenTestAccuracyLee2001","author":[{"family":"Theissen","given":"Erik"}],"citation-key":"theissenTestAccuracyLee2001","container-title":"Journal of International Financial Markets, Institutions and Money","DOI":"10.1016/s1042-4431(00)00048-2","issue":"2","issued":{"date-parts":[["2001"]]},"page":"147–165","title":"A test of the accuracy of the Lee/Ready trade classification algorithm","type":"article-journal","volume":"11"},
  {"id":"thoppilanLaMDALanguageModels2022","accessed":{"date-parts":[["2023",1,31]]},"author":[{"family":"Thoppilan","given":"Romal"},{"family":"De Freitas","given":"Daniel"},{"family":"Hall","given":"Jamie"},{"family":"Shazeer","given":"Noam"},{"family":"Kulshreshtha","given":"Apoorv"},{"family":"Cheng","given":"Heng-Tze"},{"family":"Jin","given":"Alicia"},{"family":"Bos","given":"Taylor"},{"family":"Baker","given":"Leslie"},{"family":"Du","given":"Yu"},{"family":"Li","given":"YaGuang"},{"family":"Lee","given":"Hongrae"},{"family":"Zheng","given":"Huaixiu Steven"},{"family":"Ghafouri","given":"Amin"},{"family":"Menegali","given":"Marcelo"},{"family":"Huang","given":"Yanping"},{"family":"Krikun","given":"Maxim"},{"family":"Lepikhin","given":"Dmitry"},{"family":"Qin","given":"James"},{"family":"Chen","given":"Dehao"},{"family":"Xu","given":"Yuanzhong"},{"family":"Chen","given":"Zhifeng"},{"family":"Roberts","given":"Adam"},{"family":"Bosma","given":"Maarten"},{"family":"Zhao","given":"Vincent"},{"family":"Zhou","given":"Yanqi"},{"family":"Chang","given":"Chung-Ching"},{"family":"Krivokon","given":"Igor"},{"family":"Rusch","given":"Will"},{"family":"Pickett","given":"Marc"},{"family":"Srinivasan","given":"Pranesh"},{"family":"Man","given":"Laichee"},{"family":"Meier-Hellstern","given":"Kathleen"},{"family":"Morris","given":"Meredith Ringel"},{"family":"Doshi","given":"Tulsee"},{"family":"Santos","given":"Renelito Delos"},{"family":"Duke","given":"Toju"},{"family":"Soraker","given":"Johnny"},{"family":"Zevenbergen","given":"Ben"},{"family":"Prabhakaran","given":"Vinodkumar"},{"family":"Diaz","given":"Mark"},{"family":"Hutchinson","given":"Ben"},{"family":"Olson","given":"Kristen"},{"family":"Molina","given":"Alejandra"},{"family":"Hoffman-John","given":"Erin"},{"family":"Lee","given":"Josh"},{"family":"Aroyo","given":"Lora"},{"family":"Rajakumar","given":"Ravi"},{"family":"Butryna","given":"Alena"},{"family":"Lamm","given":"Matthew"},{"family":"Kuzmina","given":"Viktoriya"},{"family":"Fenton","given":"Joe"},{"family":"Cohen","given":"Aaron"},{"family":"Bernstein","given":"Rachel"},{"family":"Kurzweil","given":"Ray"},{"family":"Aguera-Arcas","given":"Blaise"},{"family":"Cui","given":"Claire"},{"family":"Croak","given":"Marian"},{"family":"Chi","given":"Ed"},{"family":"Le","given":"Quoc"}],"citation-key":"thoppilanLaMDALanguageModels2022","issued":{"date-parts":[["2022"]]},"title":"LaMDA: language models for dialog applications","type":"document","URL":"http://arxiv.org/abs/2201.08239"},
  {"id":"tianVisualAutoregressiveModeling2024","abstract":"We present Visual AutoRegressive modeling (VAR), a new generation paradigm that redefines the autoregressive learning on images as coarse-to-fine “next-scale prediction” or “next-resolution prediction”, diverging from the standard raster-scan “next-token prediction”. This simple, intuitive methodology allows autoregressive (AR) transformers to learn visual distributions fast and can generalize well: VAR, for the first time, makes GPT-style AR models surpass diffusion transformers in image generation. On ImageNet 256×256 benchmark, VAR significantly improve AR baseline by improving Fréchet inception distance (FID) from 18.65 to 1.73, inception score (IS) from 80.4 to 350.2, with 20× faster inference speed. It is also empirically verified that VAR outperforms the Diffusion Transformer (DiT) in multiple dimensions including image quality, inference speed, data efficiency, and scalability. Scaling up VAR models exhibits clear power-law scaling laws similar to those observed in LLMs, with linear correlation coefficients near −0.998 as solid evidence. VAR further showcases zero-shot generalization ability in downstream tasks including image in-painting, out-painting, and editing. These results suggest VAR has initially emulated the two important properties of LLMs: Scaling Laws and zero-shot generalization. We have released all models and codes to promote the exploration of AR/VAR models for visual generation and unified learning.","accessed":{"date-parts":[["2025",4,5]]},"author":[{"family":"Tian","given":"Keyu"},{"family":"Jiang","given":"Yi"},{"family":"Yuan","given":"Zehuan"},{"family":"Peng","given":"Bingyue"},{"family":"Wang","given":"Liwei"}],"citation-key":"tianVisualAutoregressiveModeling2024","DOI":"10.48550/arXiv.2404.02905","issued":{"date-parts":[["2024",6,10]]},"language":"en","number":"arXiv:2404.02905","publisher":"arXiv","source":"arXiv.org","title":"Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction","title-short":"Visual Autoregressive Modeling","type":"article","URL":"http://arxiv.org/abs/2404.02905"},
  {"id":"tobekDoesSourceFundamental","author":[{"family":"Tobek","given":"Ondrej"},{"family":"Hronec","given":"Martin"}],"citation-key":"tobekDoesSourceFundamental","DOI":"10.2139/ssrn.3150654","page":"78","title":"Does the source of fundamental data matter?","type":"article-journal"},
  {"id":"touvronLLaMAOpenEfficient2023","accessed":{"date-parts":[["2023",4,29]]},"author":[{"family":"Touvron","given":"Hugo"},{"family":"Lavril","given":"Thibaut"},{"family":"Izacard","given":"Gautier"},{"family":"Martinet","given":"Xavier"},{"family":"Lachaux","given":"Marie-Anne"},{"family":"Lacroix","given":"Timothée"},{"family":"Rozière","given":"Baptiste"},{"family":"Goyal","given":"Naman"},{"family":"Hambro","given":"Eric"},{"family":"Azhar","given":"Faisal"},{"family":"Rodriguez","given":"Aurelien"},{"family":"Joulin","given":"Armand"},{"family":"Grave","given":"Edouard"},{"family":"Lample","given":"Guillaume"}],"citation-key":"touvronLLaMAOpenEfficient2023","issued":{"date-parts":[["2023"]]},"title":"LLaMA: open and efficient foundation language models","type":"document","URL":"http://arxiv.org/abs/2302.13971"},
  {"id":"TransformerArchitecturePositional","accessed":{"date-parts":[["2021",12,28]]},"citation-key":"TransformerArchitecturePositional","title":"Transformer architecture: the positional encoding - amirhossein kazemnejad's blog","type":"document","URL":"https://kazemnejad.com/blog/transformer_architecture_positional_encoding/"},
  {"id":"TransformersLucasBeyer","accessed":{"date-parts":[["2022",10,27]]},"citation-key":"TransformersLucasBeyer","title":"Transformers with lucas beyer, google brain - YouTube","type":"document","URL":"https://www.youtube.com/watch?v=EixI6t5oif0"},
  {"id":"tsaiPredictingStockReturns2011","author":[{"family":"Tsai","given":"Chih-Fong"},{"family":"Lin","given":"Yuah-Chiao"},{"family":"Yen","given":"David C."},{"family":"Chen","given":"Yan-Min"}],"citation-key":"tsaiPredictingStockReturns2011","container-title":"Applied Soft Computing","DOI":"10.1016/j.asoc.2010.10.001","issue":"2","issued":{"date-parts":[["2011"]]},"page":"2452–2459","title":"Predicting stock returns by classifier ensembles","type":"article-journal","volume":"11"},
  {"id":"tuningplaybookgithub","accessed":{"date-parts":[["2023",6,1]]},"author":[{"family":"Godbole","given":"Varun"},{"family":"Dahl","given":"George E."},{"family":"Gilmer","given":"Justin"},{"family":"Shallue","given":"Christopher J."},{"family":"Nado","given":"Zachary"}],"citation-key":"tuningplaybookgithub","issued":{"date-parts":[["2023"]]},"title":"Deep learning tuning playbook","type":"document","URL":"http://github.com/google-research/tuning_playbook"},
  {"id":"tunstallNaturalLanguageProcessing2022","author":[{"family":"Tunstall","given":"Lewis"}],"citation-key":"tunstallNaturalLanguageProcessing2022","issued":{"date-parts":[["2022"]]},"page":"409","title":"Natural language processing with transformers","type":"article-journal"},
  {"id":"turnerBayesianOptimizationSuperior2021","author":[{"family":"Turner","given":"Ryan"},{"family":"Eriksson","given":"David"},{"family":"McCourt","given":"Michael"},{"family":"Kiili","given":"Juha"},{"family":"Laaksonen","given":"Eero"},{"family":"Xu","given":"Zhen"},{"family":"Guyon","given":"Isabelle"}],"citation-key":"turnerBayesianOptimizationSuperior2021","issued":{"date-parts":[["2021"]]},"title":"Bayesian optimization is superior to random search for machine learning hyperparameter tuning: analysis of the black-box optimization challenge 2020","type":"document"},
  {"id":"twalaGoodMethodsCoping2008","author":[{"family":"Twala","given":"B.E.T.H."},{"family":"Jones","given":"M.C."},{"family":"Hand","given":"D.J."}],"citation-key":"twalaGoodMethodsCoping2008","container-title":"Pattern Recognition Letters","DOI":"10.1016/j.patrec.2008.01.010","issue":"7","issued":{"date-parts":[["2008"]]},"page":"950–956","title":"Good methods for coping with missing data in decision trees","type":"article-journal","volume":"29"},
  {"id":"ucarSubTabSubsettingFeatures2021","accessed":{"date-parts":[["2022",10,27]]},"author":[{"family":"Ucar","given":"Talip"},{"family":"Hajiramezanali","given":"Ehsan"},{"family":"Edwards","given":"Lindsay"}],"citation-key":"ucarSubTabSubsettingFeatures2021","container-title":"Advances in Neural Information Processing Systems","issued":{"date-parts":[["2021"]]},"page":"18853–18865","publisher":"Curran Associates, Inc.","title":"SubTab: subsetting features of tabular data for self-supervised representation learning","type":"paper-conference","URL":"https://proceedings.neurips.cc/paper/2021/hash/9c8661befae6dbcd08304dbf4dcaf0db-Abstract.html","volume":"34"},
  {"id":"universityoftechnologysydneyaustraliaLiquidityMotivatedAlgorithm2008","accessed":{"date-parts":[["2023",4,5]]},"author":[{"literal":"University of Technology Sydney, Australia"},{"family":"Hasan","given":"David"},{"family":"Prather","given":"Laurie"},{"literal":"Bond University, Australia"}],"citation-key":"universityoftechnologysydneyaustraliaLiquidityMotivatedAlgorithm2008","container-title":"Multinational Finance Journal","DOI":"10.17578/12-1/2-3","issue":"1/2","issued":{"date-parts":[["2008"]]},"page":"45–66","title":"A liquidity motivated algorithm for discerning trade direction","type":"article-journal","volume":"12"},
  {"id":"vanbreugelCanYouRely","abstract":"Evaluating the performance of machine learning models on diverse and underrepresented subgroups is essential for ensuring fairness and reliability in real-world applications. However, accurately assessing model performance becomes challenging due to two main issues: (1) a scarcity of test data, especially for small subgroups, and (2) possible distributional shifts in the model’s deployment setting, which may not align with the available test data. In this work, we introduce 3S Testing, a deep generative modeling framework to facilitate model evaluation by generating synthetic test sets for small subgroups and simulating distributional shifts. Our experiments demonstrate that 3S Testing outperforms traditional baselines—including real test data alone—in estimating model performance on minority subgroups and under plausible distributional shifts. In addition, 3S offers intervals around its performance estimates, exhibiting superior coverage of the ground truth compared to existing approaches. Overall, these results raise the question of whether we need a paradigm shift away from limited real test data towards synthetic test data.","author":[{"family":"Breugel","given":"Boris","non-dropping-particle":"van"},{"family":"Seedat","given":"Nabeel"},{"family":"Imrie","given":"Fergus"}],"citation-key":"vanbreugelCanYouRely","language":"en","source":"Zotero","title":"Can You Rely on Your Model Evaluation? Improving Model Evaluation with Synthetic Test Data","type":"article-journal"},
  {"id":"vanbreugelSyntheticDataReal","abstract":"Generating synthetic data through generative models is gaining interest in the ML community and beyond, promising a future where datasets can be tailored to individual needs. Unfortunately, synthetic data is usually not perfect, resulting in potential errors in downstream tasks. In this work we explore how the generative process affects the downstream ML task. We show that the naive synthetic data approach—using synthetic data as if it is real—leads to downstream models and analyses that do not generalize well to real data. As a first step towards better ML in the synthetic data regime, we introduce Deep Generative Ensemble (DGE)—a framework inspired by Deep Ensembles that aims to implicitly approximate the posterior distribution over the generative process model parameters. DGE improves downstream model training, evaluation, and uncertainty quantification, vastly outperforming the naive approach on average. The largest improvements are achieved for minority classes and low-density regions of the original data, for which the generative uncertainty is largest.","author":[{"family":"Breugel","given":"Boris","non-dropping-particle":"van"},{"family":"Qian","given":"Zhaozhi"}],"citation-key":"vanbreugelSyntheticDataReal","language":"en","source":"Zotero","title":"Synthetic Data, Real Errors: How (Not) to Publish and Use Synthetic Data","type":"article-journal"},
  {"id":"vandermaatenVisualizingDataUsing2008","author":[{"family":"Maaten","given":"Laurens","non-dropping-particle":"van der"},{"family":"Hinton","given":"Geoffrey"}],"citation-key":"vandermaatenVisualizingDataUsing2008","container-title":"Journal of Machine Learning Research","issue":"86","issued":{"date-parts":[["2008"]]},"page":"2579–2605","title":"Visualizing data using t-SNE","type":"article-journal","volume":"9"},
  {"id":"vanengelenSurveySemisupervisedLearning2020","author":[{"family":"Engelen","given":"Jesper E.","non-dropping-particle":"van"},{"family":"Hoos","given":"Holger H."}],"citation-key":"vanengelenSurveySemisupervisedLearning2020","container-title":"Machine Learning","DOI":"10.1007/s10994-019-05855-6","issue":"2","issued":{"date-parts":[["2020"]]},"page":"373–440","title":"A survey on semi-supervised learning","type":"article-journal","volume":"109"},
  {"id":"vasuImprovedOneMillisecond2022","accessed":{"date-parts":[["2022",7,28]]},"author":[{"family":"Vasu","given":"Pavan Kumar Anasosalu"},{"family":"Gabriel","given":"James"},{"family":"Zhu","given":"Jeff"},{"family":"Tuzel","given":"Oncel"},{"family":"Ranjan","given":"Anurag"}],"citation-key":"vasuImprovedOneMillisecond2022","issued":{"date-parts":[["2022"]]},"title":"An improved one millisecond mobile backbone","type":"document","URL":"http://arxiv.org/abs/2206.04040"},
  {"id":"vaswaniAttentionAllYou2017","author":[{"family":"Vaswani","given":"Ashish"},{"family":"Shazeer","given":"Noam"},{"family":"Parmar","given":"Niki"},{"family":"Uszkoreit","given":"Jakob"},{"family":"Jones","given":"Llion"},{"family":"Gomez","given":"Aidan N."},{"family":"Kaiser","given":"Łukasz"},{"family":"Polosukhin","given":"Illia"}],"citation-key":"vaswaniAttentionAllYou2017","collection-title":"NeurIPS 2017","container-title":"Advances in Neural Information Processing Systems","event-place":"Long Beach, CA","issued":{"date-parts":[["2017"]]},"page":"6000–6010","publisher":"Curran Associates, Inc.","publisher-place":"Long Beach, CA","title":"Attention is all you need","type":"paper-conference","volume":"30"},
  {"id":"verscheldeGPUAccelerationNewton2014","accessed":{"date-parts":[["2021",4,18]]},"author":[{"family":"Verschelde","given":"Jan"},{"family":"Yu","given":"Xiangcheng"}],"citation-key":"verscheldeGPUAccelerationNewton2014","container-title":"2014 IEEE Intl Conf on High Performance Computing and Communications, 2014 IEEE 6th Intl Symp on Cyberspace Safety and Security, 2014 IEEE 11th Intl Conf on Embedded Software and Syst (HPCC,CSS,ICESS)","DOI":"10.1109/HPCC.2014.31","event-place":"Paris, France","issued":{"date-parts":[["2014"]]},"page":"161–164","publisher":"IEEE","publisher-place":"Paris, France","title":"GPU acceleration of newton's method for large systems of polynomial equations in double double and quad double arithmetic","type":"paper-conference"},
  {"id":"vigInvestigatingGenderBias2020","accessed":{"date-parts":[["2023",1,29]]},"author":[{"family":"Vig","given":"Jesse"},{"family":"Gehrmann","given":"Sebastian"},{"family":"Belinkov","given":"Yonatan"},{"family":"Qian","given":"Sharon"},{"family":"Nevo","given":"Daniel"},{"family":"Singer","given":"Yaron"},{"family":"Shieber","given":"Stuart"}],"citation-key":"vigInvestigatingGenderBias2020","container-title":"Advances in Neural Information Processing Systems","issued":{"date-parts":[["2020"]]},"page":"12388–12401","publisher":"Curran Associates, Inc.","title":"Investigating gender bias in language models using causal mediation analysis","type":"paper-conference","URL":"https://proceedings.neurips.cc/paper/2020/hash/92650b2e92217715fe312e6fa7b90d82-Abstract.html","volume":"33"},
  {"id":"Vijh_1990","author":[{"family":"Vijh","given":"Anand M."}],"citation-key":"Vijh_1990","container-title":"Journal of Finance","DOI":"10.1111/j.1540-6261.1990.tb02431.x","issued":{"date-parts":[["1990"]]},"PMID":"null","title":"Liquidity of the CBOE equity options","type":"article-journal"},
  {"id":"vijhStockClosingPrice2020","accessed":{"date-parts":[["2022",7,12]]},"author":[{"family":"Vijh","given":"Mehar"},{"family":"Chandola","given":"Deeksha"},{"family":"Tikkiwal","given":"Vinay Anand"},{"family":"Kumar","given":"Arun"}],"citation-key":"vijhStockClosingPrice2020","container-title":"Procedia Computer Science","DOI":"10.1016/j.procs.2020.03.326","issued":{"date-parts":[["2020"]]},"page":"599–606","title":"Stock closing price prediction using machine learning techniques","type":"article-journal","volume":"167"},
  {"id":"voitaAnalyzingMultiHeadSelfAttention2019","author":[{"family":"Voita","given":"Elena"},{"family":"Talbot","given":"David"},{"family":"Moiseev","given":"Fedor"},{"family":"Sennrich","given":"Rico"},{"family":"Titov","given":"Ivan"}],"citation-key":"voitaAnalyzingMultiHeadSelfAttention2019","container-title":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics","DOI":"10.18653/v1/P19-1580","event-place":"Florence","issued":{"date-parts":[["2019"]]},"page":"5797–5808","publisher":"Association for Computational Linguistics","publisher-place":"Florence","title":"Analyzing multi-head self-attention: specialized heads do the heavy lifting, the rest can be pruned","type":"paper-conference"},
  {"id":"wangAcceleratingPhi2CodeLlama","abstract":"Improvements with ONNX Runtime for inferencing popular Gen AI models","accessed":{"date-parts":[["2024",11,26]]},"author":[{"family":"Wang","given":"Parinita Rahi","suffix":"Sunghoon Choi, Yufeng Li, Kshama Pawar, Ashwini Khade, Ye"}],"citation-key":"wangAcceleratingPhi2CodeLlama","language":"en","title":"Accelerating Phi-2, CodeLlama, Gemma and other Gen AI models with ONNX Runtime","type":"webpage","URL":"https://onnxruntime.ai/blogs/accelerating-phi-2"},
  {"id":"wangAttentionbasedTransactionalContext","author":[{"family":"Wang","given":"Shoujin"},{"family":"Hu","given":"Liang"},{"family":"Cao","given":"Longbing"},{"family":"Huang","given":"Xiaoshui"},{"family":"Lian","given":"Defu"},{"family":"Liu","given":"Wei"}],"citation-key":"wangAttentionbasedTransactionalContext","DOI":"10.1609/aaai.v32i1.11851","page":"8","title":"Attention-based transactional context embedding for next-item recommendation","type":"article-journal"},
  {"id":"wangForecastingMethodStock2020","accessed":{"date-parts":[["2022",7,12]]},"author":[{"family":"Wang","given":"Yan"},{"family":"Guo","given":"Yuankai"}],"citation-key":"wangForecastingMethodStock2020","container-title":"China Communications","DOI":"10.23919/JCC.2020.03.017","issue":"3","issued":{"date-parts":[["2020"]]},"page":"205–221","title":"Forecasting method of stock market volatility in time series data based on mixed model of ARIMA and xgboost","type":"article-journal","volume":"17"},
  {"id":"wangKernelFalconAutonomousGPU","accessed":{"date-parts":[["2025",11,12]]},"author":[{"family":"Wang","given":"Laura"},{"family":"Meta","given":"the PyTorch Team","dropping-particle":"at"}],"citation-key":"wangKernelFalconAutonomousGPU","language":"en-US","title":"KernelFalcon: Autonomous GPU Kernel Generation via Deep Agents – PyTorch","title-short":"KernelFalcon","type":"post-weblog","URL":"https://pytorch.org/blog/kernelfalcon-autonomous-gpu-kernel-generation-via-deep-agents/"},
  {"id":"wangLearningDeepTransformer2019","author":[{"family":"Wang","given":"Qiang"},{"family":"Li","given":"Bei"},{"family":"Xiao","given":"Tong"},{"family":"Zhu","given":"Jingbo"},{"family":"Li","given":"Changliang"},{"family":"Wong","given":"Derek F."},{"family":"Chao","given":"Lidia S."}],"citation-key":"wangLearningDeepTransformer2019","container-title":"Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics","DOI":"10.18653/v1/P19-1176","event-place":"Florence, Italy","issued":{"date-parts":[["2019"]]},"page":"1810–1822","publisher":"Association for Computational Linguistics","publisher-place":"Florence, Italy","title":"Learning deep transformer models for machine translation","type":"paper-conference"},
  {"id":"wangLinformerSelfattentionLinear2020","accessed":{"date-parts":[["2022",12,10]]},"author":[{"family":"Wang","given":"Sinong"},{"family":"Li","given":"Belinda Z."},{"family":"Khabsa","given":"Madian"},{"family":"Fang","given":"Han"},{"family":"Ma","given":"Hao"}],"citation-key":"wangLinformerSelfattentionLinear2020","issued":{"date-parts":[["2020"]]},"title":"Linformer: self-attention with linear complexity","type":"document","URL":"http://arxiv.org/abs/2006.04768"},
  {"id":"wangNonuniformNegativeSampling2021","abstract":"We investigate the issue of parameter estimation with nonuniform negative sampling for imbalanced data. We ﬁrst prove that, with imbalanced data, the available information about unknown parameters is only tied to the relatively small number of positive instances, which justiﬁes the usage of negative sampling. However, if the negative instances are subsampled to the same level of the positive cases, there is information loss. To maintain more information, we derive the asymptotic distribution of a general inverse probability weighted (IPW) estimator and obtain the optimal sampling probability that minimizes its variance. To further improve the estimation efﬁciency over the IPW method, we propose a likelihood-based estimator by correcting log odds for the sampled data and prove that the improved estimator has the smallest asymptotic variance among a large class of estimators. It is also more robust to pilot misspeciﬁcation. We validate our approach on simulated data as well as a real click-through rate dataset with more than 0.3 trillion instances, collected over a period of a month. Both theoretical and empirical results demonstrate the effectiveness of our method.","accessed":{"date-parts":[["2025",11,13]]},"author":[{"family":"Wang","given":"HaiYing"},{"family":"Zhang","given":"Aonan"},{"family":"Wang","given":"Chong"}],"citation-key":"wangNonuniformNegativeSampling2021","DOI":"10.48550/arXiv.2110.13048","issued":{"date-parts":[["2021",10,26]]},"language":"en","number":"arXiv:2110.13048","publisher":"arXiv","source":"arXiv.org","title":"Nonuniform Negative Sampling and Log Odds Correction with Rare Events Data","type":"article","URL":"http://arxiv.org/abs/2110.13048"},
  {"id":"wangPerceivingNextChoice2017","accessed":{"date-parts":[["2021",5,4]]},"author":[{"family":"Wang","given":"Shoujin"},{"family":"Hu","given":"Liang"},{"family":"Cao","given":"Longbing"}],"citation-key":"wangPerceivingNextChoice2017","container-title":"Machine Learning and Knowledge Discovery in Databases","DOI":"10.1007/978-3-319-71246-8\\_18","editor":[{"family":"Ceci","given":"Michelangelo"},{"family":"Hollmén","given":"Jaakko"},{"family":"Todorovski","given":"Ljupčo"},{"family":"Vens","given":"Celine"},{"family":"Džeroski","given":"Sašo"}],"event-place":"Cham","issued":{"date-parts":[["2017"]]},"page":"285–302","publisher":"Springer International Publishing","publisher-place":"Cham","title":"Perceiving the next choice with comprehensive transaction embeddings for online recommendation","type":"chapter","volume":"10535"},
  {"id":"wangSurveyDataSynthesis2024","abstract":"The success of Large Language Models (LLMs) is inherently linked to the availability of vast, diverse, and high-quality data for training and evaluation. However, the growth rate of high-quality data is significantly outpaced by the expansion of training datasets, leading to a looming data exhaustion crisis. This underscores the urgent need to enhance data efficiency and explore new data sources. In this context, synthetic data has emerged as a promising solution. Currently, data generation primarily consists of two major approaches: data augmentation and synthesis. This paper comprehensively reviews and summarizes data generation techniques throughout the lifecycle of LLMs, including data preparation, pre-training, fine-tuning, instruction-tuning, preference alignment, and applications. Furthermore, We discuss the current constraints faced by these methods and investigate potential pathways for future development and research. Our aspiration is to equip researchers with a clear understanding of these methodologies, enabling them to swiftly identify appropriate data generation strategies in the construction of LLMs, while providing valuable insights for future exploration.","accessed":{"date-parts":[["2024",11,26]]},"author":[{"family":"Wang","given":"Ke"},{"family":"Zhu","given":"Jiahui"},{"family":"Ren","given":"Minjie"},{"family":"Liu","given":"Zeming"},{"family":"Li","given":"Shiwei"},{"family":"Zhang","given":"Zongye"},{"family":"Zhang","given":"Chenkai"},{"family":"Wu","given":"Xiaoyu"},{"family":"Zhan","given":"Qiqi"},{"family":"Liu","given":"Qingjie"},{"family":"Wang","given":"Yunhong"}],"citation-key":"wangSurveyDataSynthesis2024","DOI":"10.48550/arXiv.2410.12896","issued":{"date-parts":[["2024",10,16]]},"language":"en","number":"arXiv:2410.12896","publisher":"arXiv","source":"arXiv.org","title":"A Survey on Data Synthesis and Augmentation for Large Language Models","type":"article","URL":"http://arxiv.org/abs/2410.12896"},
  {"id":"wangSurveySessionbasedRecommender2020","accessed":{"date-parts":[["2021",4,22]]},"author":[{"family":"Wang","given":"Shoujin"},{"family":"Cao","given":"Longbing"},{"family":"Wang","given":"Yan"},{"family":"Sheng","given":"Quan Z."},{"family":"Orgun","given":"Mehmet"},{"family":"Lian","given":"Defu"}],"citation-key":"wangSurveySessionbasedRecommender2020","issued":{"date-parts":[["2020"]]},"title":"A survey on session-based recommender systems","type":"document","URL":"http://arxiv.org/abs/1902.04864"},
  {"id":"wangTransTabLearningTransferable","author":[{"family":"Wang","given":"Zifeng"},{"family":"Sun","given":"Jimeng"}],"citation-key":"wangTransTabLearningTransferable","title":"TransTab: learning transferable tabular transformers across tables","type":"article-journal"},
  {"id":"wangWizMapScalableInteractive2023","accessed":{"date-parts":[["2023",6,26]]},"author":[{"family":"Wang","given":"Zijie J."},{"family":"Hohman","given":"Fred"},{"family":"Chau","given":"Duen Horng"}],"citation-key":"wangWizMapScalableInteractive2023","issued":{"date-parts":[["2023"]]},"title":"WizMap: Scalable Interactive Visualization for Exploring Large Machine Learning Embeddings","type":"document","URL":"http://arxiv.org/abs/2306.09328"},
  {"id":"waszczukAssemblingInternationalEquity2014","accessed":{"date-parts":[["2021",10,29]]},"author":[{"family":"Waszczuk","given":"Antonina"}],"citation-key":"waszczukAssemblingInternationalEquity2014","container-title":"Procedia Economics and Finance","DOI":"10.1016/S2212-5671(14)00631-5","issued":{"date-parts":[["2014"]]},"page":"1603–1612","title":"Assembling international equity datasets – review of studies on the cross-section of returns","type":"article-journal","volume":"15"},
  {"id":"WaybackMachine2023","accessed":{"date-parts":[["2024",11,28]]},"citation-key":"WaybackMachine2023","issued":{"date-parts":[["2023",3,23]]},"title":"Wayback Machine","type":"webpage","URL":"https://web.archive.org/web/20230323002555/https://tnq177.github.io/data/transformers_without_tears.pdf"},
  {"id":"weiTheoreticalAnalysisSelfTraining2022","accessed":{"date-parts":[["2023",3,31]]},"author":[{"family":"Wei","given":"Colin"},{"family":"Shen","given":"Kendrick"},{"family":"Chen","given":"Yining"},{"family":"Ma","given":"Tengyu"}],"citation-key":"weiTheoreticalAnalysisSelfTraining2022","issued":{"date-parts":[["2022"]]},"title":"Theoretical analysis of self-training with deep networks on unlabeled data","type":"document","URL":"http://arxiv.org/abs/2010.03622"},
  {"id":"welchComprehensiveLookEmpirical2008","author":[{"family":"Welch","given":"Ivo"},{"family":"Goyal","given":"Amit"}],"citation-key":"welchComprehensiveLookEmpirical2008","container-title":"Review of Financial Studies","DOI":"10.1093/rfs/hhm014","issue":"4","issued":{"date-parts":[["2008"]]},"page":"1455–1508","title":"A comprehensive look at the empirical performance of equity premium prediction","type":"article-journal","volume":"21"},
  {"id":"wengLearningNotEnough2021","accessed":{"date-parts":[["2022",10,13]]},"author":[{"family":"Weng","given":"Lilian"}],"citation-key":"wengLearningNotEnough2021","issued":{"date-parts":[["2021"]]},"section":"posts","title":"Learning with not enough data part 1: semi-supervised learning","type":"document","URL":"https://lilianweng.github.io/posts/2021-12-05-semi-supervised/"},
  {"id":"WhenMachinesTrade","accessed":{"date-parts":[["2023",5,1]]},"citation-key":"WhenMachinesTrade","DOI":"10.1016/j.dss.2022.113892","title":"When machines trade on corporate disclosures: using text analytics for investment strategies | elsevier enhanced reader","type":"document"},
  {"id":"wiegreffeAttentionNotNot2019","author":[{"family":"Wiegreffe","given":"Sarah"},{"family":"Pinter","given":"Yuval"}],"citation-key":"wiegreffeAttentionNotNot2019","container-title":"Proceedings of the 2019 conference on empirical methods in natural language processing and the 9th international joint conference on natural language processing (EMNLP-IJCNLP)","DOI":"10.18653/v1/D19-1002","event-place":"Hong Kong, China","issued":{"date-parts":[["2019"]]},"page":"11–20","publisher":"Association for Computational Linguistics","publisher-place":"Hong Kong, China","title":"Attention is not not explanation","type":"paper-conference"},
  {"id":"wilkeFundamentalsDataVisualization2019","abstract":"Cover -- Copyright -- Table of Contents -- Preface -- Chapter 1. Introduction -- Part I. From Data to Visualization -- Chapter 2. Visualizing Data: Mapping Data onto Aesthetics -- Chapter 3. Coordinate Systems and Axes -- Chapter 4. Color Scales -- Chapter 5. Directory of Visualizations -- Chapter 6. Visualizing Amounts -- Chapter 7. Visualizing Distributions: Histograms and Density Plots -- Chapter 8. Visualizing Distributions: Empirical Cumulative Distribution Functions and Q-Q Plots -- Chapter 9. Visualizing Many Distributions at Once -- Chapter 10. Visualizing Proportions -- Chapter 11. Visualizing Nested Proportions -- Chapter 12. Visualizing Associations Among Two or More Quantitative Variables -- Chapter 13. Visualizing Time Series and Other Functions of an Independent Variable -- Chapter 14. Visualizing Trends -- Chapter 15. Visualizing Geospatial Data -- Chapter 16. Visualizing Uncertainty -- Part II. Principles of Figure Design -- Chapter 17. The Principle of Proportional Ink -- Chapter 18. Handling Overlapping Points -- Chapter 19. Common Pitfalls of Color Use -- Chapter 20. Redundant Coding -- Chapter 21. Multipanel Figures -- Chapter 22. Titles, Captions, and Tables -- Chapter 23. Balance the Data and the Context -- Chapter 24. Use Larger Axis Labels -- Chapter 25. Avoid Line Drawings -- Chapter 26. Don't Go 3D -- Part III. Miscellaneous Topics -- Chapter 27. Understanding the Most Commonly Used Image File Formats -- Chapter 28. Choosing the Right Visualization Software -- Chapter 29. Telling a Story and Making a Point -- Annotated Bibliography -- Technical Notes -- References -- Index -- About the Author -- Colophon","author":[{"family":"Wilke","given":"Claus"}],"citation-key":"wilkeFundamentalsDataVisualization2019","edition":"First edition","event-place":"Beijing Boston Farnham Sebastopol Tokyo","ISBN":"978-1-4920-3108-6 978-1-4920-3103-1","issued":{"date-parts":[["2019"]]},"language":"eng","number-of-pages":"1","publisher":"O'Reilly","publisher-place":"Beijing Boston Farnham Sebastopol Tokyo","source":"K10plus ISBN","title":"Fundamentals of data visualization: a primer on making informative and compelling figures","title-short":"Fundamentals of data visualization","type":"book"},
  {"id":"wuMemorizingTransformers2022","accessed":{"date-parts":[["2023",1,17]]},"author":[{"family":"Wu","given":"Yuhuai"},{"family":"Rabe","given":"Markus N."},{"family":"Hutchins","given":"DeLesley"},{"family":"Szegedy","given":"Christian"}],"citation-key":"wuMemorizingTransformers2022","issued":{"date-parts":[["2022"]]},"title":"Memorizing transformers","type":"document","URL":"http://arxiv.org/abs/2203.08913"},
  {"id":"xiongLayerNormalizationTransformer2020","author":[{"family":"Xiong","given":"Ruibin"},{"family":"Yang","given":"Yunchang"},{"family":"He","given":"Di"},{"family":"Zheng","given":"Kai"},{"family":"Zheng","given":"Shuxin"},{"family":"Xing","given":"Chen"},{"family":"Zhang","given":"Huishuai"},{"family":"Lan","given":"Yanyan"},{"family":"Wang","given":"Liwei"},{"family":"Liu","given":"Tie-Yan"}],"citation-key":"xiongLayerNormalizationTransformer2020","container-title":"Proceedings of the 37th international conference on machine learning","event-place":"Online","issued":{"date-parts":[["2020"]]},"page":"10524–10533","publisher":"PMLR","publisher-place":"Online","title":"On layer normalization in the transformer architecture","type":"paper-conference","volume":"21"},
  {"id":"yangStockPricePrediction2021","accessed":{"date-parts":[["2022",7,12]]},"author":[{"family":"Yang","given":"Yue"},{"family":"Wu","given":"Yang"},{"family":"Wang","given":"Peikun"},{"family":"Jiali","given":"Xu"}],"citation-key":"yangStockPricePrediction2021","container-title":"E3S Web of Conferences","DOI":"10.1051/e3sconf/202127501040","editor":[{"family":"Wen","given":"F."},{"family":"Ziaei","given":"S.M."}],"issued":{"date-parts":[["2021"]]},"page":"01040","title":"Stock price prediction based on xgboost and LightGBM","type":"article-journal","volume":"275"},
  {"id":"yanMachineLearningStock2007","accessed":{"date-parts":[["2021",11,3]]},"author":[{"family":"Yan","given":"Robert J."},{"family":"Ling","given":"Charles X."}],"citation-key":"yanMachineLearningStock2007","container-title":"Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining - KDD '07","DOI":"10.1145/1281192.1281307","event-place":"San Jose, California, USA","issued":{"date-parts":[["2007"]]},"page":"1038","publisher":"ACM Press","publisher-place":"San Jose, California, USA","title":"Machine learning for stock selection","type":"paper-conference"},
  {"id":"yaoZeroQuantEfficientAffordable2022","accessed":{"date-parts":[["2022",11,23]]},"author":[{"family":"Yao","given":"Zhewei"},{"family":"Aminabadi","given":"Reza Yazdani"},{"family":"Zhang","given":"Minjia"},{"family":"Wu","given":"Xiaoxia"},{"family":"Li","given":"Conglong"},{"family":"He","given":"Yuxiong"}],"citation-key":"yaoZeroQuantEfficientAffordable2022","DOI":"10.48550/arXiv.2206.01861","issued":{"date-parts":[["2022"]]},"title":"ZeroQuant: efficient and affordable post-training quantization for large-scale transformers","type":"document"},
  {"id":"yarowskyUnsupervisedWordSense1995","author":[{"family":"Yarowsky","given":"David"}],"citation-key":"yarowskyUnsupervisedWordSense1995","container-title":"Proceedings of the 33rd annual meeting on Association for Computational Linguistics","DOI":"10.3115/981658.981684","event-place":"Cambridge, MA","issued":{"date-parts":[["1995"]]},"page":"189–196","publisher":"Association for Computational Linguistics","publisher-place":"Cambridge, MA","title":"Unsupervised word sense disambiguation rivaling supervised methods","type":"paper-conference"},
  {"id":"yinTaBERTPretrainingJoint2020","accessed":{"date-parts":[["2023",1,24]]},"author":[{"family":"Yin","given":"Pengcheng"},{"family":"Neubig","given":"Graham"},{"family":"Yih","given":"Wen-tau"},{"family":"Riedel","given":"Sebastian"}],"citation-key":"yinTaBERTPretrainingJoint2020","container-title":"Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics","DOI":"10.18653/v1/2020.acl-main.745","event-place":"Online","issued":{"date-parts":[["2020"]]},"page":"8413–8426","publisher":"Association for Computational Linguistics","publisher-place":"Online","title":"TaBERT: pretraining for joint understanding of textual and tabular data","type":"paper-conference"},
  {"id":"yiWhyNotUse2020","author":[{"family":"Yi","given":"Joonyoung"},{"family":"Lee","given":"Juhyuk"},{"family":"Kim","given":"Kwang Joon"},{"family":"Hwang","given":"Sung Ju"},{"family":"Yang","given":"Eunho"}],"citation-key":"yiWhyNotUse2020","issued":{"date-parts":[["2020"]]},"page":"27","title":"Why not to use zero imputation? Correcting sparsity bias in training neural networks","type":"article-journal"},
  {"id":"yoonVIMEExtendingSuccess2020","author":[{"family":"Yoon","given":"Jinsung"},{"family":"Zhang","given":"Yao"},{"family":"Jordon","given":"James"},{"family":"Schaar","given":"Mihaela","non-dropping-particle":"van der"}],"citation-key":"yoonVIMEExtendingSuccess2020","collection-title":"NeurIPS 2020","container-title":"Advances in Neural Information Processing Systems","event-place":"Red Hook, NY","issued":{"date-parts":[["2020"]]},"page":"11033–11043","publisher":"Curran Associates, Inc.","publisher-place":"Red Hook, NY","title":"Vime: extending the success of self- and semi-supervised learning to tabular domain","type":"paper-conference","volume":"33"},
  {"id":"zengAreTransformersEffective2022","accessed":{"date-parts":[["2022",12,24]]},"author":[{"family":"Zeng","given":"Ailing"},{"family":"Chen","given":"Muxi"},{"family":"Zhang","given":"Lei"},{"family":"Xu","given":"Qiang"}],"citation-key":"zengAreTransformersEffective2022","issued":{"date-parts":[["2022"]]},"title":"Are transformers effective for time series forecasting?","type":"document","URL":"http://arxiv.org/abs/2205.13504"},
  {"id":"zhaiDirectBoostingApproach","author":[{"family":"Zhai","given":"Shaodan"},{"family":"Xia","given":"Tian"},{"family":"Li","given":"Zhongliang"},{"family":"Wang","given":"Shaojun"}],"citation-key":"zhaiDirectBoostingApproach","title":"A direct boosting approach for semi-supervised classification","type":"article-journal"},
  {"id":"zhangDiveDeepLearning2021","author":[{"family":"Zhang","given":"Aston"},{"family":"Lipton","given":"Zachary C"},{"family":"Li","given":"Mu"},{"family":"Smola","given":"Alexander J"}],"citation-key":"zhangDiveDeepLearning2021","issued":{"date-parts":[["2021"]]},"title":"Dive into deep learning","type":"document"},
  {"id":"zhangUptodateComparisonStateoftheart2017","accessed":{"date-parts":[["2022",7,11]]},"author":[{"family":"Zhang","given":"Chongsheng"},{"family":"Liu","given":"Changchang"},{"family":"Zhang","given":"Xiangliang"},{"family":"Almpanidis","given":"George"}],"citation-key":"zhangUptodateComparisonStateoftheart2017","container-title":"Expert Systems with Applications","DOI":"10.1016/j.eswa.2017.04.003","issued":{"date-parts":[["2017"]]},"page":"128–150","title":"An up-to-date comparison of state-of-the-art classification algorithms","type":"article-journal","volume":"82"},
  {"id":"zhengFeatureEngineeringMachine","author":[{"family":"Zheng","given":"Alice"},{"family":"Casari","given":"Amanda"}],"citation-key":"zhengFeatureEngineeringMachine","page":"217","title":"Feature engineering for machine learning","type":"article-journal"},
  {"id":"zhuClusteringStructureMicrostructure2021","author":[{"family":"Zhu","given":"Liao"},{"family":"Sun","given":"Ningning"},{"family":"Wells","given":"Martin T."}],"citation-key":"zhuClusteringStructureMicrostructure2021","issued":{"date-parts":[["2021"]]},"title":"Clustering structure of microstructure measures","type":"document"},
  {"id":"zhuSemiSupervisedLearningLiterature","author":[{"family":"Zhu","given":"Xiaojin"}],"citation-key":"zhuSemiSupervisedLearningLiterature","page":"60","title":"Semi-supervised learning literature survey","type":"article-journal"},
  {"id":"zophRethinkingPretrainingSelftraining2020","author":[{"family":"Zoph","given":"Barret"},{"family":"Ghiasi","given":"Golnaz"},{"family":"Lin","given":"Tsung-Yi"},{"family":"Cui","given":"Yin"},{"family":"Liu","given":"Hanxiao"},{"family":"Cubuk","given":"Ekin Dogus"},{"family":"Le","given":"Quoc"}],"citation-key":"zophRethinkingPretrainingSelftraining2020","container-title":"Advances in Neural Information Processing Systems","issued":{"date-parts":[["2020"]]},"page":"3833–3845","publisher":"Curran Associates, Inc.","title":"Rethinking pre-training and self-training","type":"paper-conference","volume":"33"},
  {"id":"zouStockMarketPrediction2022","accessed":{"date-parts":[["2022",12,29]]},"author":[{"family":"Zou","given":"Jinan"},{"family":"Zhao","given":"Qingying"},{"family":"Jiao","given":"Yang"},{"family":"Cao","given":"Haiyao"},{"family":"Liu","given":"Yanxi"},{"family":"Yan","given":"Qingsen"},{"family":"Abbasnejad","given":"Ehsan"},{"family":"Liu","given":"Lingqiao"},{"family":"Shi","given":"Javen Qinfeng"}],"citation-key":"zouStockMarketPrediction2022","issued":{"date-parts":[["2022"]]},"title":"Stock market prediction via deep learning techniques: a survey","type":"document","URL":"http://arxiv.org/abs/2212.12717"}
]
